{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astrapi69/DroidBallet/blob/master/NLP_D1_2_E1_Similarity_Content_Recommenders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Q0'></a>\n",
        "<center><a target=\"_blank\" href=\"https://learning.constructor.org/\"><img src=\"https://drive.google.com/uc?id=1RNy-ds7KWXFs7YheGo9OQwO3OnpvRSU1\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "\n",
        "_____\n",
        "\n",
        "<center> <h1> Movie Recommendations with Document Similarity </h1> </center>\n",
        "\n",
        "<p style=\"margin-bottom:1cm;\"></p>\n",
        "\n",
        "_____\n",
        "\n",
        "<center>Constructor Academy, 2024</center>\n"
      ],
      "metadata": {
        "id": "SIdlrX7jWOSN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGdpBKaHXuoc"
      },
      "source": [
        "# Movie Recommendations with Document Similarity\n",
        "\n",
        "Recommender systems are one of the popular and most adopted applications of machine learning. They are typically used to recommend entities to users and these entites can be anything like products, movies, services and so on.\n",
        "\n",
        "Popular examples of recommendations include,\n",
        "- Amazon suggesting products on its website\n",
        "- Amazon Prime, Netflix, Hotstar recommending movies\\shows\n",
        "- YouTube recommending videos to watch\n",
        "\n",
        "Typically recommender systems can be implemented in three ways:\n",
        "\n",
        "- Simple Rule-based Recommenders: Typically based on specific global metrics and thresholds like movie popularity, global ratings etc.\n",
        "- Content-based Recommenders: This is based on providing similar entities based on a specific entity of interest. Content metadata can be used here like movie descriptions, genre, cast, director and so on\n",
        "- Collaborative filtering Recommenders: Here we don't need metadata but we try to predict recommendations and ratings based on past ratings of different users and specific items.\n",
        "\n",
        "We will be building a movie recommendation system here where based on data\\metadata pertaining to different movies, we try and recommend similar movies of interest!\n",
        "\n",
        "![](https://i.imgur.com/c7Go7d3.png)\n",
        "\n",
        "Since our focus in not really recommendation engines but NLP, we will be leveraging the text-based metadata for each movie to try and recommend similar movies based on specific movies of interest. This falls under content-based recommenders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2lYDs1RjvRn"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U-mW8t5YDFH"
      },
      "source": [
        "!pip install textsearch\n",
        "!pip install contractions\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_de4c8pjvRr"
      },
      "source": [
        "# Load and View Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctP-qx30YUyC"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2010%20-%20Project%208%20-%20Movie%20Recommendations%20with%20Document%20Similarity/tmdb_5000_movies.csv.gz', compression='gzip')\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frQbM_zrZC2D"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLQJoC19jwD4"
      },
      "source": [
        "## Let's focus on only the tagline and overview fields\n",
        "\n",
        "__Your Task:__ Concatenate the `tagline` and `overview` fields and create a new column called description in the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lURVWdjZGHL"
      },
      "source": [
        "df = df[['title', 'tagline', 'overview', 'popularity']]\n",
        "df.tagline.fillna('', inplace=True)\n",
        "\n",
        "df['description'] = <YOUR CODE HERE>\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df = df.sort_values(by=['popularity'], ascending=False)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfwvf3UgZJK6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wDHsF6qZWNv"
      },
      "source": [
        "# Build a Movie Recommender System\n",
        "\n",
        "Here you will build your own movie recommender system. We will use the following pipeline:\n",
        "- Text pre-processing\n",
        "- Feature Engineering\n",
        "- Document Similarity Computation\n",
        "- Find top similar movies\n",
        "- Build a movie recommendation function\n",
        "\n",
        "\n",
        "## Document Similarity\n",
        "\n",
        "Recommendations are about understanding the underlying features which make us favour one choice over the other. Similarity between items(in this case movies) is one way to understanding why we choose one movie over another. There are different ways to calculate similarity between two items. One of the most widely used measures is __cosine similarity__ which we have already used in the previous unit.\n",
        "\n",
        "### Cosine Similarity\n",
        "\n",
        "Cosine Similarity is used to calculate a numeric score to denote the similarity between two text documents. Mathematically, it is defined as follows:\n",
        "\n",
        "$$ cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjLTJDE9ZXSj"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "import contractions\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # fix contractions\n",
        "    doc = <YOUR CODE HERE>\n",
        "    # remove special characters\n",
        "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, flags=re.I|re.A)\n",
        "    # lower case\n",
        "    doc = <YOUR CODE HERE>\n",
        "    # strip whitespaces\n",
        "    doc = <YOUR CODE HERE>\n",
        "    # tokenize document\n",
        "    tokens = <YOUR CODE HERE>\n",
        "    #filter stopwords out of document\n",
        "    filtered_tokens = <YOUR CODE HERE>\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "normalize_corpus = np.vectorize(normalize_document)\n",
        "\n",
        "norm_corpus = normalize_corpus(list(df['description']))\n",
        "len(norm_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNiwar7saOuj"
      },
      "source": [
        "## Extract TF-IDF Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZkWolSnaRkd"
      },
      "source": [
        "<YOUR CODE HERE>\n",
        "\n",
        "tfidf_matrix = <YOUR CODE HERE>\n",
        "tfidf_matrix.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIyXn448aXnt"
      },
      "source": [
        "## Compute Pairwise Document Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKYgrUc4aUHm"
      },
      "source": [
        "<YOUR CODE HERE>\n",
        "\n",
        "doc_sim = <YOUR CODE HERE>\n",
        "doc_sim_df = pd.DataFrame(doc_sim)\n",
        "doc_sim_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h08MqvY9adgt"
      },
      "source": [
        "## Get List of Movie Titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWr6lgqTaZsJ"
      },
      "source": [
        "movies_list = df['title'].values\n",
        "movies_list, movies_list.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69SKx3ZTaftu"
      },
      "source": [
        "## Find Top Similar Movies for a Sample Movie\n",
        "\n",
        "Let's take __Minions__ the most popular movie the the dataframe above and try and find the most similar movies which can be recommended"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT3tw7Wka6B0"
      },
      "source": [
        "#### Find movie ID for 'Minions'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmAUpmxWa-Kv"
      },
      "source": [
        "movie_idx = <YOUR CODE HERE>\n",
        "movie_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IO3VhLka_vi"
      },
      "source": [
        "#### Get movie similarities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shbop-mDbDSS"
      },
      "source": [
        "movie_similarities = <YOUR CODE HERE>\n",
        "movie_similarities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjMx8FqtbE4O"
      },
      "source": [
        "#### Get top 5 similar movie IDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgmQgy8QbHDF"
      },
      "source": [
        "similar_movie_idxs = <YOUR CODE HERE>\n",
        "similar_movie_idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Fzp3qcbJv3"
      },
      "source": [
        "#### Get top 5 similar movies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4o7WpNlbNlT"
      },
      "source": [
        "similar_movies = <YOUR CODE HERE>\n",
        "similar_movies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5lpIbnMcnOx"
      },
      "source": [
        "### Build a movie recommender function to recommend top 5 similar movies for any movie\n",
        "\n",
        "The movie title, movie title list and document similarity matrix dataframe will be given as inputs to the function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOL8nLbacpXq"
      },
      "source": [
        "def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df):\n",
        "    # find movie id\n",
        "    movie_idx = <YOUR CODE HERE>\n",
        "    # get movie similarities\n",
        "    movie_similarities = <YOUR CODE HERE>\n",
        "    # get top 5 similar movie IDs\n",
        "    similar_movie_idxs = <YOUR CODE HERE>\n",
        "    # get top 5 movies\n",
        "    similar_movies = <YOUR CODE HERE>\n",
        "    # return the top 5 movies\n",
        "    return similar_movies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4t4wBWwceFA"
      },
      "source": [
        "# Get popular Movie Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V4EpMgAbPYY"
      },
      "source": [
        "popular_movies = ['Minions', 'Interstellar', 'Deadpool', 'Jurassic World', 'Pirates of the Caribbean: The Curse of the Black Pearl',\n",
        "              'Dawn of the Planet of the Apes', 'The Hunger Games: Mockingjay - Part 1', 'Terminator Genisys',\n",
        "              'Captain America: Civil War', 'The Dark Knight', 'The Martian', 'Batman v Superman: Dawn of Justice',\n",
        "              'Pulp Fiction', 'The Godfather', 'The Shawshank Redemption', 'The Lord of the Rings: The Fellowship of the Ring',\n",
        "              'Harry Potter and the Chamber of Secrets', 'Star Wars', 'The Hobbit: The Battle of the Five Armies',\n",
        "              'Iron Man']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ky8g-Ichp6"
      },
      "source": [
        "for movie in popular_movies:\n",
        "    print('Movie:', movie)\n",
        "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7PezLIojvSQ"
      },
      "source": [
        "# Movie Recommendation with Embeddings\n",
        "\n",
        "We used count based normalized features in the previous section. Can we use word embeddings and then compute movie similarity? We definitely can! Here we will use the FastText model and train it on our corpus.\n",
        "\n",
        "The FastText model was first introduced by Facebook in 2016 as an extension and supposedly improvement of the vanilla Word2Vec model. Based on the original paper titled ‘Enriching Word Vectors with Subword Information’ by Mikolov et al. which is an excellent read to gain an in-depth understanding of how this model works. Overall, FastText is a framework for learning word representations and also performing robust, fast and accurate text classification. The framework is open-sourced by Facebook on GitHub and claims to have the following.\n",
        "- Recent state-of-the-art English word vectors.\n",
        "- Word vectors for 157 languages trained on Wikipedia and Crawl.\n",
        "- Models for language identification and various supervised tasks.\n",
        "\n",
        "Though I haven’t implemented this model from scratch, based on the research paper, following is what I learnt about how the model works. In general, predictive models like the Word2Vec model typically considers each word as a distinct entity (e.g. `where`) and generates a dense embedding for the word. However this poses to be a serious limitation with languages having massive vocabularies and many rare words which may not occur a lot in different corpora. The Word2Vec model typically ignores the morphological structure of each word and considers a word as a single entity. The FastText model considers each word as a Bag of Character n-grams. This is also called as a subword model in the paper.\n",
        "\n",
        "We add special boundary symbols < and > at the beginning and end of words. This enables us to distinguish prefixes and suffixes from other character sequences. We also include the word w itself in the set of its n-grams, to learn a representation for each word (in addition to its character n-grams). Taking the word `where` and n=3 (tri-grams) as an example, it will be represented by the character n-grams: `<wh, whe, her, ere, re>` and the special sequence `<where>` representing the whole word. Note that the sequence , corresponding to the word `<her>` is different from the tri-gram `her` from the word `where`.\n",
        "\n",
        "Here we leverage `gensim` to build our embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thOsbtsvkb70"
      },
      "source": [
        "## Build the FastText embedding model here\n",
        "\n",
        "Remember more the iterations usually better the embeddings but the more time it will take depending on your system CPU\n",
        "\n",
        "50 iterations might take 15-20 mins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-uTK-ovctOw"
      },
      "source": [
        "<YOUR CODE HERE>\n",
        "\n",
        "tokenized_docs = <YOUR CODE HERE>\n",
        "# ideal config params size: 300, window: 30, min_count=2 or more, iter=50 or more (use 10 if it takes too much time)\n",
        "ft_model = <YOUR CODE HERE>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyx0yxV_jvSS"
      },
      "source": [
        "# Generate document level embeddings\n",
        "\n",
        "Word embedding models give us an embedding for each word, how can we use it for downstream ML\\DL tasks? one way is to flatten it or use sequential models. A simpler approach is to average all word embeddings for words in a document and generate a fixed-length document level emebdding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te0xZdxFfXkK"
      },
      "source": [
        "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
        "    <YOUR CODE HERE>\n",
        "    return np.array(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhYLq48zf9mq"
      },
      "source": [
        "doc_vecs_ft = <YOUR CODE HERE>\n",
        "doc_vecs_ft.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taowG-dijvSV"
      },
      "source": [
        "# Get Movie Recommendations\n",
        "\n",
        "We will leverage cosine similarity again to generate recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RQYRBoChXLb"
      },
      "source": [
        "doc_sim = <YOUR CODE HERE>\n",
        "doc_sim_df = pd.DataFrame(doc_sim)\n",
        "doc_sim_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM-fGDVvgcuX"
      },
      "source": [
        "for movie in popular_movies:\n",
        "    print('Movie:', movie)\n",
        "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f483d7076ed04c0e9314d2fea81d3345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07f7cfc0b28743bb90b1638389305113",
              "IPY_MODEL_49e0a0a117234445ab06b8bd388d5663",
              "IPY_MODEL_c9592f6f6f5f454384de95a06574bb00"
            ],
            "layout": "IPY_MODEL_5f9244b0c43b4f60851c75d3f8e5349c"
          }
        },
        "07f7cfc0b28743bb90b1638389305113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045eb5a4444f461faa4ea132e250afdf",
            "placeholder": "​",
            "style": "IPY_MODEL_2ace64977bf7488da85bd7547b3b8917",
            "value": "Optimization Progress: 100%"
          }
        },
        "49e0a0a117234445ab06b8bd388d5663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e3a720489842acbeb7e1945a48f08e",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a05a663c54164ebe822302df313008bc",
            "value": 100
          }
        },
        "c9592f6f6f5f454384de95a06574bb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b73f273224034580af606c0da8f6e51e",
            "placeholder": "​",
            "style": "IPY_MODEL_f5dac09667b5414f95ca0886b913a307",
            "value": " 398/400 [04:54&lt;00:01,  1.17pipeline/s]"
          }
        },
        "5f9244b0c43b4f60851c75d3f8e5349c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045eb5a4444f461faa4ea132e250afdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ace64977bf7488da85bd7547b3b8917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e3a720489842acbeb7e1945a48f08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a05a663c54164ebe822302df313008bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b73f273224034580af606c0da8f6e51e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5dac09667b5414f95ca0886b913a307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astrapi69/DroidBallet/blob/master/MLG_D6_LC2_Auto_ML_for_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBZ8thbXmi_R"
      },
      "source": [
        "<a id='Q0'></a>\n",
        "<center><a target=\"_blank\" href=\"https://academy.constructor.org/\"><img src=\"https://jobtracker.ai/static/media/constructor_academy_colour.b86fa87f.png\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "\n",
        "_____\n",
        "\n",
        "<center> <h1> Auto ML for Machine Learning (Live coding) </h1> </center>\n",
        "\n",
        "<p style=\"margin-bottom:1cm;\"></p>\n",
        "\n",
        "_____\n",
        "\n",
        "<center>Constructor Academy, 2024</center>\n",
        "\n",
        "\n",
        "We will look at how to solve a classification problem using a variety of Auto-ML methods and libraries:\n",
        "\n",
        "- H2O\n",
        "- TPOT\n",
        "- FLAML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto ML for Machine Learning (Live coding)"
      ],
      "metadata": {
        "id": "CC6q-55ryrtr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMFGMBu8vFpR"
      },
      "source": [
        "## Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rmso8fs02dT",
        "outputId": "b3a6996b-41bd-4484-bc5f-e264987ee023"
      },
      "source": [
        "!pip install h2o"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h2o\n",
            "  Downloading h2o-3.44.0.2.tar.gz (265.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.3/265.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2023.11.17)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.44.0.2-py2.py3-none-any.whl size=265363806 sha256=8f8d4a7e7cd00b685c8236ac81b966898431f6c5be8d31c3e36a230439eaef79\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/ea/ab/889709967692e30c57c46137edd2cae6b2768bb65ec7cb8aa5\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "Successfully installed h2o-3.44.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OSPpCKA9uFY",
        "outputId": "856c0965-e41d-47f4-c979-1e8750310167"
      },
      "source": [
        "!pip install tpot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tpot\n",
            "  Downloading TPOT-0.12.1-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m700.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.2.2)\n",
            "Collecting deap>=1.2 (from tpot)\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting update-checker>=0.16 (from tpot)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from tpot) (4.66.1)\n",
            "Collecting stopit>=1.1.1 (from tpot)\n",
            "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.5.3)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.3.2)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tpot) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->tpot) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->tpot) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update-checker>=0.16->tpot) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->tpot) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2023.11.17)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11937 sha256=b336d5f3a1d53be29762237950c118ceab7c41f68384111614eaa4c06d40ef53\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/f9/87/bf5b3d565c2a007b4dae9d8142dccc85a9f164e517062dd519\n",
            "Successfully built stopit\n",
            "Installing collected packages: stopit, deap, update-checker, tpot\n",
            "Successfully installed deap-1.4.1 stopit-1.1.2 tpot-0.12.1 update-checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeesnKp8LZql",
        "outputId": "aa1ec3e6-ed62-4f42-81bd-3af869934e61"
      },
      "source": [
        "!pip install flaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-2.1.1-py3-none-any.whl (295 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/295.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/295.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.10/dist-packages (from flaml) (1.23.5)\n",
            "Installing collected packages: flaml\n",
            "Successfully installed flaml-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remember to Restart Runtime on Colab before proceeding"
      ],
      "metadata": {
        "id": "_KjaI7iNefZu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLqoAmWFiL3l"
      },
      "source": [
        "#### Install Check\n",
        "\n",
        "Scikit Learn should be >= 1.2 at least"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvN8BF490qng",
        "outputId": "da51adb2-f9e9-4eb2-ada9-5ea9e2192e7f"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL_GZaNbFdRo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR0aqUN9FdRp"
      },
      "source": [
        "## Data Generation\n",
        "\n",
        "We will be using the standard Boston Housing Dataset as a classification problem\n",
        "\n",
        "Boston Houses Classification\n",
        "\n",
        "- Price > \\$ 30K is Class Label 1\n",
        "\n",
        "- Price <= \\$ 30K is Class Label 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boston.csv\n",
        "data_file='https://drive.google.com/uc?export=download&id=1cnIxAAqXnG9vHO59EuRBbnit_3rM_UOT'\n",
        "df = pd.read_csv(data_file)\n",
        "df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "df.columns = df.columns.str.upper()\n",
        "df.rename(columns={'BLACK': 'B', 'MEDV': 'Price'}, inplace=True)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "cwlyQ-7O2BSF",
        "outputId": "8ead8b35-9986-4889-aa99-cbf3b057e312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(506, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
              "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
              "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
              "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
              "\n",
              "        B  LSTAT  Price  \n",
              "0  396.90   4.98   24.0  \n",
              "1  396.90   9.14   21.6  \n",
              "2  392.83   4.03   34.7  \n",
              "3  394.63   2.94   33.4  \n",
              "4  396.90   5.33   36.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-104c9b26-7884-48d9-a315-4e994587e2e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-104c9b26-7884-48d9-a315-4e994587e2e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-104c9b26-7884-48d9-a315-4e994587e2e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-104c9b26-7884-48d9-a315-4e994587e2e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e112a2af-be71-4d9f-b72d-c21036fd13cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e112a2af-be71-4d9f-b72d-c21036fd13cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e112a2af-be71-4d9f-b72d-c21036fd13cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Price'] = df['Price'].apply(lambda x: 1 if x > 30 else 0)"
      ],
      "metadata": {
        "id": "WF1vfeD-lqin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Price', axis=1).copy()\n",
        "y = df['Price']\n",
        "y.head()"
      ],
      "metadata": {
        "id": "95CkkTK5B1Ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456bd648-3fef-487c-9be6-c46b5f32b8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "Name: Price, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pD2QZ1bFdRp",
        "outputId": "cfd71c03-28b5-4a94-c47e-8146e3b08a65"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (102, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BsJTCybnnJ8Y",
        "outputId": "c5309c51-9bc5-4043-bfde-abc8dc33a891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS  RAD  TAX  \\\n",
              "477  15.02340   0.0  18.10     0  0.6140  5.304  97.3  2.1007   24  666   \n",
              "15    0.62739   0.0   8.14     0  0.5380  5.834  56.5  4.4986    4  307   \n",
              "332   0.03466  35.0   6.06     0  0.4379  6.031  23.3  6.6407    1  304   \n",
              "423   7.05042   0.0  18.10     0  0.6140  6.103  85.1  2.0218   24  666   \n",
              "19    0.72580   0.0   8.14     0  0.5380  5.727  69.5  3.7965    4  307   \n",
              "\n",
              "     PTRATIO       B  LSTAT  \n",
              "477     20.2  349.48  24.91  \n",
              "15      21.0  395.62   8.47  \n",
              "332     16.9  362.25   7.83  \n",
              "423     20.2    2.52  23.29  \n",
              "19      21.0  390.95  11.28  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af23af2a-fbd8-4db7-87fe-03bd711dcad4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>15.02340</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6140</td>\n",
              "      <td>5.304</td>\n",
              "      <td>97.3</td>\n",
              "      <td>2.1007</td>\n",
              "      <td>24</td>\n",
              "      <td>666</td>\n",
              "      <td>20.2</td>\n",
              "      <td>349.48</td>\n",
              "      <td>24.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.62739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5380</td>\n",
              "      <td>5.834</td>\n",
              "      <td>56.5</td>\n",
              "      <td>4.4986</td>\n",
              "      <td>4</td>\n",
              "      <td>307</td>\n",
              "      <td>21.0</td>\n",
              "      <td>395.62</td>\n",
              "      <td>8.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>0.03466</td>\n",
              "      <td>35.0</td>\n",
              "      <td>6.06</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4379</td>\n",
              "      <td>6.031</td>\n",
              "      <td>23.3</td>\n",
              "      <td>6.6407</td>\n",
              "      <td>1</td>\n",
              "      <td>304</td>\n",
              "      <td>16.9</td>\n",
              "      <td>362.25</td>\n",
              "      <td>7.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>7.05042</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6140</td>\n",
              "      <td>6.103</td>\n",
              "      <td>85.1</td>\n",
              "      <td>2.0218</td>\n",
              "      <td>24</td>\n",
              "      <td>666</td>\n",
              "      <td>20.2</td>\n",
              "      <td>2.52</td>\n",
              "      <td>23.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.72580</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5380</td>\n",
              "      <td>5.727</td>\n",
              "      <td>69.5</td>\n",
              "      <td>3.7965</td>\n",
              "      <td>4</td>\n",
              "      <td>307</td>\n",
              "      <td>21.0</td>\n",
              "      <td>390.95</td>\n",
              "      <td>11.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af23af2a-fbd8-4db7-87fe-03bd711dcad4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af23af2a-fbd8-4db7-87fe-03bd711dcad4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af23af2a-fbd8-4db7-87fe-03bd711dcad4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b59fd60-bbc1-4138-b5d4-a1f0054cfbba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b59fd60-bbc1-4138-b5d4-a1f0054cfbba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b59fd60-bbc1-4138-b5d4-a1f0054cfbba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjKzPazTiYdh"
      },
      "source": [
        "## H2O AutoML: Automatic Machine Learning\n",
        "\n",
        "Here we will use the `h2o` library to build classification models. Do check out the [package documentation](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html#) when needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BblEAAIFixUn"
      },
      "source": [
        "### Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrgLfNyc0ahO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "2e8f16f3-29f6-4de8-c602-c01adc98cd7c"
      },
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "\n",
        "# Start the H2O cluster (locally)\n",
        "h2o.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.21\" 2023-10-17; OpenJDK Runtime Environment (build 11.0.21+9-post-Ubuntu-0ubuntu122.04); OpenJDK 64-Bit Server VM (build 11.0.21+9-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.10/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpmjfb0o90\n",
            "  JVM stdout: /tmp/tmpmjfb0o90/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpmjfb0o90/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         05 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.44.0.2\n",
              "H2O_cluster_version_age:    1 month and 9 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_cyfl41\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.170 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.10.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>05 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.44.0.2</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 9 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_cyfl41</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.170 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.10.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "train_data = h2o.H2OFrame.from_python(train_data)\n",
        "train_data['Price'] = train_data['Price'].asfactor()\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "oOUZFD7UJZ2q",
        "outputId": "f9e30f65-85ab-4a66-8b62-545e47fc4c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    CRIM    ZN    INDUS    CHAS     NOX     RM    AGE     DIS    RAD    TAX    PTRATIO       B    LSTAT    Price\n",
              "--------  ----  -------  ------  ------  -----  -----  ------  -----  -----  ---------  ------  -------  -------\n",
              "15.0234      0    18.1        0  0.614   5.304   97.3  2.1007     24    666       20.2  349.48    24.91        0\n",
              " 0.62739     0     8.14       0  0.538   5.834   56.5  4.4986      4    307       21    395.62     8.47        0\n",
              " 0.03466    35     6.06       0  0.4379  6.031   23.3  6.6407      1    304       16.9  362.25     7.83        0\n",
              " 7.05042     0    18.1        0  0.614   6.103   85.1  2.0218     24    666       20.2    2.52    23.29        0\n",
              " 0.7258      0     8.14       0  0.538   5.727   69.5  3.7965      4    307       21    390.95    11.28        0\n",
              " 0.19186     0     7.38       0  0.493   6.431   14.7  5.4159      5    287       19.6  393.68     5.08        0\n",
              " 0.03961     0     5.19       0  0.515   6.037   34.5  5.9853      5    224       20.2  396.9      8.01        0\n",
              " 0.02055    85     0.74       0  0.41    6.383   35.7  9.1876      2    313       17.3  396.9      5.77        0\n",
              "15.1772      0    18.1        0  0.74    6.152  100    1.9142     24    666       20.2    9.32    26.45        0\n",
              "14.4383      0    18.1        0  0.597   6.852  100    1.4655     24    666       20.2  179.36    19.78        0\n",
              "[10 rows x 14 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th style=\"text-align: right;\">    CRIM</th><th style=\"text-align: right;\">  ZN</th><th style=\"text-align: right;\">  INDUS</th><th style=\"text-align: right;\">  CHAS</th><th style=\"text-align: right;\">   NOX</th><th style=\"text-align: right;\">   RM</th><th style=\"text-align: right;\">  AGE</th><th style=\"text-align: right;\">   DIS</th><th style=\"text-align: right;\">  RAD</th><th style=\"text-align: right;\">  TAX</th><th style=\"text-align: right;\">  PTRATIO</th><th style=\"text-align: right;\">     B</th><th style=\"text-align: right;\">  LSTAT</th><th style=\"text-align: right;\">  Price</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td style=\"text-align: right;\">15.0234 </td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">  18.1 </td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.614 </td><td style=\"text-align: right;\">5.304</td><td style=\"text-align: right;\"> 97.3</td><td style=\"text-align: right;\">2.1007</td><td style=\"text-align: right;\">   24</td><td style=\"text-align: right;\">  666</td><td style=\"text-align: right;\">     20.2</td><td style=\"text-align: right;\">349.48</td><td style=\"text-align: right;\">  24.91</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\"> 0.62739</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   8.14</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.538 </td><td style=\"text-align: right;\">5.834</td><td style=\"text-align: right;\"> 56.5</td><td style=\"text-align: right;\">4.4986</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">  307</td><td style=\"text-align: right;\">     21  </td><td style=\"text-align: right;\">395.62</td><td style=\"text-align: right;\">   8.47</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\"> 0.03466</td><td style=\"text-align: right;\">  35</td><td style=\"text-align: right;\">   6.06</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.4379</td><td style=\"text-align: right;\">6.031</td><td style=\"text-align: right;\"> 23.3</td><td style=\"text-align: right;\">6.6407</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">  304</td><td style=\"text-align: right;\">     16.9</td><td style=\"text-align: right;\">362.25</td><td style=\"text-align: right;\">   7.83</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\"> 7.05042</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">  18.1 </td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.614 </td><td style=\"text-align: right;\">6.103</td><td style=\"text-align: right;\"> 85.1</td><td style=\"text-align: right;\">2.0218</td><td style=\"text-align: right;\">   24</td><td style=\"text-align: right;\">  666</td><td style=\"text-align: right;\">     20.2</td><td style=\"text-align: right;\">  2.52</td><td style=\"text-align: right;\">  23.29</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\"> 0.7258 </td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   8.14</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.538 </td><td style=\"text-align: right;\">5.727</td><td style=\"text-align: right;\"> 69.5</td><td style=\"text-align: right;\">3.7965</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">  307</td><td style=\"text-align: right;\">     21  </td><td style=\"text-align: right;\">390.95</td><td style=\"text-align: right;\">  11.28</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\"> 0.19186</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   7.38</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.493 </td><td style=\"text-align: right;\">6.431</td><td style=\"text-align: right;\"> 14.7</td><td style=\"text-align: right;\">5.4159</td><td style=\"text-align: right;\">    5</td><td style=\"text-align: right;\">  287</td><td style=\"text-align: right;\">     19.6</td><td style=\"text-align: right;\">393.68</td><td style=\"text-align: right;\">   5.08</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\"> 0.03961</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">   5.19</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.515 </td><td style=\"text-align: right;\">6.037</td><td style=\"text-align: right;\"> 34.5</td><td style=\"text-align: right;\">5.9853</td><td style=\"text-align: right;\">    5</td><td style=\"text-align: right;\">  224</td><td style=\"text-align: right;\">     20.2</td><td style=\"text-align: right;\">396.9 </td><td style=\"text-align: right;\">   8.01</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\"> 0.02055</td><td style=\"text-align: right;\">  85</td><td style=\"text-align: right;\">   0.74</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.41  </td><td style=\"text-align: right;\">6.383</td><td style=\"text-align: right;\"> 35.7</td><td style=\"text-align: right;\">9.1876</td><td style=\"text-align: right;\">    2</td><td style=\"text-align: right;\">  313</td><td style=\"text-align: right;\">     17.3</td><td style=\"text-align: right;\">396.9 </td><td style=\"text-align: right;\">   5.77</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\">15.1772 </td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">  18.1 </td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.74  </td><td style=\"text-align: right;\">6.152</td><td style=\"text-align: right;\">100  </td><td style=\"text-align: right;\">1.9142</td><td style=\"text-align: right;\">   24</td><td style=\"text-align: right;\">  666</td><td style=\"text-align: right;\">     20.2</td><td style=\"text-align: right;\">  9.32</td><td style=\"text-align: right;\">  26.45</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "<tr><td style=\"text-align: right;\">14.4383 </td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">  18.1 </td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.597 </td><td style=\"text-align: right;\">6.852</td><td style=\"text-align: right;\">100  </td><td style=\"text-align: right;\">1.4655</td><td style=\"text-align: right;\">   24</td><td style=\"text-align: right;\">  666</td><td style=\"text-align: right;\">     20.2</td><td style=\"text-align: right;\">179.36</td><td style=\"text-align: right;\">  19.78</td><td style=\"text-align: right;\">      0</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 14 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.types"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaa7S-RCLxWb",
        "outputId": "83b60c60-fb06-49fb-86c0-195bb9117bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CRIM': 'real',\n",
              " 'ZN': 'real',\n",
              " 'INDUS': 'real',\n",
              " 'CHAS': 'int',\n",
              " 'NOX': 'real',\n",
              " 'RM': 'real',\n",
              " 'AGE': 'real',\n",
              " 'DIS': 'real',\n",
              " 'RAD': 'int',\n",
              " 'TAX': 'int',\n",
              " 'PTRATIO': 'real',\n",
              " 'B': 'real',\n",
              " 'LSTAT': 'real',\n",
              " 'Price': 'enum'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84oPXySVizlQ"
      },
      "source": [
        "### Create Auto-ML Modeling Strategy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aml = H2OAutoML(max_models=30, # hard total models experimented limit\n",
        "                max_runtime_secs=300, # try to run as many models in 5 mins\n",
        "                max_runtime_secs_per_model=30, # max training time for a model <= 30 s else move to next model\n",
        "                seed=1)\n",
        "aml.train(x=X_train.columns.tolist(), y=y_train.name, training_frame=train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hf80y5WwL6Ot",
        "outputId": "c5bca1e8-fe53-4698-ea53-35c0fe79d160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_2_20231217_191212\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    38                 38                          12632                  5            10           7.63158       14            31            21.7895\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.03280278799891183\n",
              "RMSE: 0.18111539967355572\n",
              "LogLoss: 0.1885614069896225\n",
              "Mean Per-Class Error: 0.05166990853784712\n",
              "AUC: 0.9831974506476845\n",
              "AUCPR: 0.9506248365037563\n",
              "Gini: 0.966394901295369\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      324  7    0.0211   (7.0/331.0)\n",
              "1      6    67   0.0822   (6.0/73.0)\n",
              "Total  330  74   0.0322   (13.0/404.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.5          0.911565  39\n",
              "max f2                       0.368421     0.92246   46\n",
              "max f0point5                 0.545455     0.913043  36\n",
              "max accuracy                 0.5          0.967822  39\n",
              "max precision                1            1         0\n",
              "max recall                   0            1         78\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.5          0.891929  39\n",
              "max min_per_class_accuracy   0.368421     0.945205  46\n",
              "max mean_per_class_accuracy  0.222222     0.953069  55\n",
              "max tns                      1            331       0\n",
              "max fns                      1            60        0\n",
              "max fps                      0            331       78\n",
              "max tps                      0            73        78\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.821918  0\n",
              "max fpr                      0            1         78\n",
              "max tpr                      0            1         78\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 18.07 %, avg score: 17.77 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0321782                   1                  5.53425   5.53425            1                1           1                           1                   0.178082        0.178082                   453.425   453.425            0.178082\n",
              "2        0.0321782                   0.9995             0         5.53425            0                0           1                           1                   0               0.178082                   -100      453.425            0.178082\n",
              "3        0.0420792                   0.943611           5.53425   5.53425            1                0.963889    1                           0.991503            0.0547945       0.232877                   453.425   453.425            0.232877\n",
              "4        0.0569307                   0.933333           5.53425   5.53425            1                0.934028    1                           0.97651             0.0821918       0.315068                   453.425   453.425            0.315068\n",
              "5        0.101485                    0.821925           5.22679   5.39926            0.944444         0.878367    0.97561                     0.933423            0.232877        0.547945                   422.679   439.926            0.544924\n",
              "6        0.153465                    0.625              4.74364   5.1772             0.857143         0.718908    0.935484                    0.860764            0.246575        0.794521                   374.364   417.72             0.782436\n",
              "7        0.200495                    0.374899           2.91276   4.64603            0.526316         0.501048    0.839506                    0.776386            0.136986        0.931507                   191.276   364.603            0.892232\n",
              "8        0.30198                     0.0833333          0.539926  3.26611            0.097561         0.189766    0.590164                    0.579244            0.0547945       0.986301                   -46.0074  226.611            0.835244\n",
              "9        1                           0                  0.019625  1                  0.0035461        0.00400296  0.180693                    0.177714            0.0136986       1                          -98.0375  0                  0\n",
              "\n",
              "ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.03374480241669449\n",
              "RMSE: 0.18369758413407208\n",
              "LogLoss: 0.11789329584194869\n",
              "Mean Per-Class Error: 0.06536853867483342\n",
              "AUC: 0.9901916152795597\n",
              "AUCPR: 0.9601222919027211\n",
              "Gini: 0.9803832305591194\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48750000000000004\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      324  7    0.0211   (7.0/331.0)\n",
              "1      8    65   0.1096   (8.0/73.0)\n",
              "Total  332  72   0.0371   (15.0/404.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.4875       0.896552  47\n",
              "max f2                       0.3          0.929319  57\n",
              "max f0point5                 0.55         0.919881  42\n",
              "max accuracy                 0.55         0.962871  42\n",
              "max precision                1            1         0\n",
              "max recall                   0.1          1         74\n",
              "max specificity              1            1         0\n",
              "max absolute_mcc             0.4875       0.873959  47\n",
              "max min_per_class_accuracy   0.325        0.94864   56\n",
              "max mean_per_class_accuracy  0.3          0.9576    57\n",
              "max tns                      1            331       0\n",
              "max fns                      1            72        0\n",
              "max fps                      0            331       92\n",
              "max tps                      0.1          73        74\n",
              "max tnr                      1            1         0\n",
              "max fnr                      1            0.986301  0\n",
              "max fpr                      0            1         92\n",
              "max tpr                      0.1          1         74\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 18.07 %, avg score: 17.42 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0123762                   0.979725           5.53425   5.53425            1                0.988333    1                           0.988333            0.0684932       0.0684932                  453.425   453.425            0.0684932\n",
              "2        0.0222772                   0.949411           5.53425   5.53425            1                0.96128     1                           0.97631             0.0547945       0.123288                   453.425   453.425            0.123288\n",
              "3        0.0321782                   0.932133           5.53425   5.53425            1                0.936711    1                           0.964125            0.0547945       0.178082                   453.425   453.425            0.178082\n",
              "4        0.0519802                   0.9                5.53425   5.53425            1                0.907188    1                           0.942435            0.109589        0.287671                   453.425   453.425            0.287671\n",
              "5        0.0519802                   0.899625           0         5.53425            0                0           1                           0.942435            0               0.287671                   -100      453.425            0.287671\n",
              "6        0.101485                    0.738              5.25753   5.39926            0.95             0.825064    0.97561                     0.885181            0.260274        0.547945                   425.753   439.926            0.544924\n",
              "7        0.153465                    0.6                5.00718   5.26646            0.904762         0.65754     0.951613                    0.808077            0.260274        0.808219                   400.718   426.646            0.799156\n",
              "8        0.200495                    0.42               2.33021   4.57771            0.421053         0.491418    0.82716                     0.733799            0.109589        0.917808                   133.021   357.771            0.875512\n",
              "9        0.314356                    0.1                0.721858  3.1811             0.130435         0.188664    0.574803                    0.536348            0.0821918       1                          -27.8142  218.11             0.836858\n",
              "10       0.415842                    0.025              0         2.40476            0                0.0460796   0.434524                    0.416699            0               1                          -100      140.476            0.712991\n",
              "11       1                           0                  0         1                  0                0.00155548  0.180693                    0.17419             0               1                          -100      0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
              "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
              "accuracy                 0.977747   0.0160733   1             0.962963      0.975309      0.962963      0.9875\n",
              "auc                      0.993502   0.00561545  1             0.991379      0.991268      0.986425      0.998435\n",
              "err                      0.0222531  0.0160733   0             0.037037      0.0246914     0.037037      0.0125\n",
              "err_count                1.8        1.30384     0             3             2             3             1\n",
              "f0point5                 0.925256   0.0470732   1             0.92437       0.913979      0.869565      0.918367\n",
              "f1                       0.943374   0.0395099   1             0.93617       0.944444      0.888889      0.947368\n",
              "f2                       0.962528   0.0350717   1             0.948276      0.977012      0.909091      0.978261\n",
              "lift_top_group           6.15395    2.10996     7.36364       3.52174       4.76471       6.23077       8.88889\n",
              "logloss                  0.117012   0.0529606   0.0865601     0.190492      0.122095      0.136022      0.0498897\n",
              "max_per_class_error      0.0331472  0.0295329   0             0.0434783     0.03125       0.0769231     0.0140845\n",
              "mcc                      0.930211   0.0482777   1             0.910509      0.931008      0.86756       0.941979\n",
              "mean_per_class_accuracy  0.977037   0.0223801   1             0.96102       0.984375      0.946833      0.992958\n",
              "mean_per_class_error     0.022963   0.0223801   0             0.0389805     0.015625      0.0531674     0.00704225\n",
              "mse                      0.0328747  0.0186715   0.0195267     0.0585185     0.0359781     0.0398469     0.0105033\n",
              "pr_auc                   0.977558   0.0184836   1             0.981042      0.964867      0.953589      0.988293\n",
              "precision                0.913709   0.0529209   1             0.916667      0.894737      0.857143      0.9\n",
              "r2                       0.785582   0.0809986   0.833617      0.712189      0.78304       0.704258      0.894803\n",
              "recall                   0.97592    0.0350294   1             0.956522      1             0.923077      1\n",
              "rmse                     0.174685   0.0543119   0.139738      0.241906      0.189679      0.199617      0.102486\n",
              "specificity              0.978154   0.014516    1             0.965517      0.96875       0.970588      0.985915\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------\n",
              "    2023-12-17 19:12:34  2.457 sec   0                  nan              nan                 nan             nan                nan              nan\n",
              "    2023-12-17 19:12:35  2.483 sec   5                  0.202858         0.63615             0.963594        0.879931           5.1293           0.0412088\n",
              "    2023-12-17 19:12:35  2.513 sec   10                 0.205819         0.517934            0.963594        0.885518           5.22679          0.0522388\n",
              "    2023-12-17 19:12:35  2.546 sec   15                 0.211288         0.450953            0.966914        0.867945           5.09151          0.0496278\n",
              "    2023-12-17 19:12:35  2.578 sec   20                 0.204131         0.44414             0.970575        0.884067           5.05301          0.0470297\n",
              "    2023-12-17 19:12:35  2.613 sec   25                 0.196887         0.279115            0.972934        0.926001           5.53425          0.0445545\n",
              "    2023-12-17 19:12:35  2.646 sec   30                 0.189209         0.193712            0.98119         0.939299           5.53425          0.0420792\n",
              "    2023-12-17 19:12:35  2.673 sec   35                 0.184334         0.190922            0.982494        0.947278           5.53425          0.0346535\n",
              "    2023-12-17 19:12:35  2.691 sec   38                 0.181115         0.188561            0.983197        0.950625           5.53425          0.0321782\n",
              "\n",
              "Variable Importances: \n",
              "variable    relative_importance    scaled_importance    percentage\n",
              "----------  ---------------------  -------------------  ------------\n",
              "RM          613.393                1                    0.374294\n",
              "LSTAT       301.59                 0.491675             0.184031\n",
              "INDUS       214.529                0.349742             0.130906\n",
              "PTRATIO     132.367                0.215795             0.0807708\n",
              "TAX         69.7306                0.11368              0.0425499\n",
              "DIS         54.7674                0.0892861            0.0334193\n",
              "AGE         54.1241                0.0882373            0.0330267\n",
              "ZN          53.5468                0.0872961            0.0326744\n",
              "NOX         42.5103                0.0693036            0.0259399\n",
              "RAD         31.6423                0.0515857            0.0193082\n",
              "CRIM        29.9899                0.0488918            0.0182999\n",
              "B           23.7604                0.0387361            0.0144987\n",
              "CHAS        16.8481                0.0274671            0.0102808\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2ORandomForestEstimator : Distributed Random Forest\n",
              "Model Key: DRF_1_AutoML_2_20231217_191212\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>38.0</td>\n",
              "<td>38.0</td>\n",
              "<td>12632.0</td>\n",
              "<td>5.0</td>\n",
              "<td>10.0</td>\n",
              "<td>7.631579</td>\n",
              "<td>14.0</td>\n",
              "<td>31.0</td>\n",
              "<td>21.789474</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.03280278799891183\n",
              "RMSE: 0.18111539967355572\n",
              "LogLoss: 0.1885614069896225\n",
              "Mean Per-Class Error: 0.05166990853784712\n",
              "AUC: 0.9831974506476845\n",
              "AUCPR: 0.9506248365037563\n",
              "Gini: 0.966394901295369</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-3.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-3 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-3 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-3 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table th,\n",
              "#h2o-table-3 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>324.0</td>\n",
              "<td>7.0</td>\n",
              "<td>0.0211</td>\n",
              "<td> (7.0/331.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>6.0</td>\n",
              "<td>67.0</td>\n",
              "<td>0.0822</td>\n",
              "<td> (6.0/73.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>330.0</td>\n",
              "<td>74.0</td>\n",
              "<td>0.0322</td>\n",
              "<td> (13.0/404.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-4.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-4 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-4 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-4 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table th,\n",
              "#h2o-table-4 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.5</td>\n",
              "<td>0.9115646</td>\n",
              "<td>39.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3684211</td>\n",
              "<td>0.9224599</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5454545</td>\n",
              "<td>0.9130435</td>\n",
              "<td>36.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5</td>\n",
              "<td>0.9678218</td>\n",
              "<td>39.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>78.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5</td>\n",
              "<td>0.8919294</td>\n",
              "<td>39.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.3684211</td>\n",
              "<td>0.9452055</td>\n",
              "<td>46.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.2222223</td>\n",
              "<td>0.9530687</td>\n",
              "<td>55.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>331.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>60.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>331.0</td>\n",
              "<td>78.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0</td>\n",
              "<td>73.0</td>\n",
              "<td>78.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8219178</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>78.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>78.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-5.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-5 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-5 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-5 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table th,\n",
              "#h2o-table-5 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 18.07 %, avg score: 17.77 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0321782</td>\n",
              "<td>1.0</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.1780822</td>\n",
              "<td>0.1780822</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.1780822</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0321782</td>\n",
              "<td>0.9995000</td>\n",
              "<td>0.0</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.1780822</td>\n",
              "<td>-100.0</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.1780822</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0420792</td>\n",
              "<td>0.9436111</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9638889</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9915033</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.2328767</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.2328767</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0569307</td>\n",
              "<td>0.9333333</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9340278</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9765097</td>\n",
              "<td>0.0821918</td>\n",
              "<td>0.3150685</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.3150685</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.1014851</td>\n",
              "<td>0.8219251</td>\n",
              "<td>5.2267884</td>\n",
              "<td>5.3992650</td>\n",
              "<td>0.9444444</td>\n",
              "<td>0.8783671</td>\n",
              "<td>0.9756098</td>\n",
              "<td>0.9334227</td>\n",
              "<td>0.2328767</td>\n",
              "<td>0.5479452</td>\n",
              "<td>422.6788432</td>\n",
              "<td>439.9264952</td>\n",
              "<td>0.5449241</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1534653</td>\n",
              "<td>0.625</td>\n",
              "<td>4.7436399</td>\n",
              "<td>5.1771984</td>\n",
              "<td>0.8571429</td>\n",
              "<td>0.7189077</td>\n",
              "<td>0.9354839</td>\n",
              "<td>0.8607644</td>\n",
              "<td>0.2465753</td>\n",
              "<td>0.7945205</td>\n",
              "<td>374.3639922</td>\n",
              "<td>417.7198409</td>\n",
              "<td>0.7824360</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.2004950</td>\n",
              "<td>0.3748988</td>\n",
              "<td>2.9127614</td>\n",
              "<td>4.6460342</td>\n",
              "<td>0.5263158</td>\n",
              "<td>0.5010478</td>\n",
              "<td>0.8395062</td>\n",
              "<td>0.7763864</td>\n",
              "<td>0.1369863</td>\n",
              "<td>0.9315068</td>\n",
              "<td>191.2761355</td>\n",
              "<td>364.6034162</td>\n",
              "<td>0.8922319</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.3019802</td>\n",
              "<td>0.0833333</td>\n",
              "<td>0.5399265</td>\n",
              "<td>3.2661127</td>\n",
              "<td>0.0975610</td>\n",
              "<td>0.1897661</td>\n",
              "<td>0.5901639</td>\n",
              "<td>0.5792435</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.9863014</td>\n",
              "<td>-46.0073505</td>\n",
              "<td>226.6112733</td>\n",
              "<td>0.8352440</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0196250</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0035461</td>\n",
              "<td>0.0040030</td>\n",
              "<td>0.1806931</td>\n",
              "<td>0.1777142</td>\n",
              "<td>0.0136986</td>\n",
              "<td>1.0</td>\n",
              "<td>-98.0375012</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.03374480241669449\n",
              "RMSE: 0.18369758413407208\n",
              "LogLoss: 0.11789329584194869\n",
              "Mean Per-Class Error: 0.06536853867483342\n",
              "AUC: 0.9901916152795597\n",
              "AUCPR: 0.9601222919027211\n",
              "Gini: 0.9803832305591194</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-6.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-6 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-6 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-6 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table th,\n",
              "#h2o-table-6 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.48750000000000004</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>324.0</td>\n",
              "<td>7.0</td>\n",
              "<td>0.0211</td>\n",
              "<td> (7.0/331.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>8.0</td>\n",
              "<td>65.0</td>\n",
              "<td>0.1096</td>\n",
              "<td> (8.0/73.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>332.0</td>\n",
              "<td>72.0</td>\n",
              "<td>0.0371</td>\n",
              "<td> (15.0/404.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-7.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-7 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-7 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-7 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-7 .h2o-table th,\n",
              "#h2o-table-7 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4875000</td>\n",
              "<td>0.8965517</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.3000000</td>\n",
              "<td>0.9293194</td>\n",
              "<td>57.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.55</td>\n",
              "<td>0.9198813</td>\n",
              "<td>42.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.55</td>\n",
              "<td>0.9628713</td>\n",
              "<td>42.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.1000000</td>\n",
              "<td>1.0</td>\n",
              "<td>74.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4875000</td>\n",
              "<td>0.8739595</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.3250000</td>\n",
              "<td>0.9486405</td>\n",
              "<td>56.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.3000000</td>\n",
              "<td>0.9576005</td>\n",
              "<td>57.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>1.0</td>\n",
              "<td>331.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0</td>\n",
              "<td>331.0</td>\n",
              "<td>92.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.1000000</td>\n",
              "<td>73.0</td>\n",
              "<td>74.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9863014</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>92.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.1000000</td>\n",
              "<td>1.0</td>\n",
              "<td>74.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-8.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-8 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-8 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-8 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-8 .h2o-table th,\n",
              "#h2o-table-8 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 18.07 %, avg score: 17.42 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0123762</td>\n",
              "<td>0.9797250</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9883333</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9883333</td>\n",
              "<td>0.0684932</td>\n",
              "<td>0.0684932</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.0684932</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0222772</td>\n",
              "<td>0.9494107</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9612798</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9763095</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.1232877</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.1232877</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0321782</td>\n",
              "<td>0.9321333</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9367113</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9641255</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.1780822</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.1780822</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0519802</td>\n",
              "<td>0.9</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9071875</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9424348</td>\n",
              "<td>0.1095890</td>\n",
              "<td>0.2876712</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.2876712</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.0519802</td>\n",
              "<td>0.899625</td>\n",
              "<td>0.0</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9424348</td>\n",
              "<td>0.0</td>\n",
              "<td>0.2876712</td>\n",
              "<td>-100.0</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.2876712</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1014851</td>\n",
              "<td>0.7380000</td>\n",
              "<td>5.2575342</td>\n",
              "<td>5.3992650</td>\n",
              "<td>0.95</td>\n",
              "<td>0.8250645</td>\n",
              "<td>0.9756098</td>\n",
              "<td>0.8851810</td>\n",
              "<td>0.2602740</td>\n",
              "<td>0.5479452</td>\n",
              "<td>425.7534247</td>\n",
              "<td>439.9264952</td>\n",
              "<td>0.5449241</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.1534653</td>\n",
              "<td>0.6</td>\n",
              "<td>5.0071755</td>\n",
              "<td>5.2664605</td>\n",
              "<td>0.9047619</td>\n",
              "<td>0.6575397</td>\n",
              "<td>0.9516129</td>\n",
              "<td>0.8080767</td>\n",
              "<td>0.2602740</td>\n",
              "<td>0.8082192</td>\n",
              "<td>400.7175473</td>\n",
              "<td>426.6460451</td>\n",
              "<td>0.7991557</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.2004950</td>\n",
              "<td>0.4200000</td>\n",
              "<td>2.3302091</td>\n",
              "<td>4.5777101</td>\n",
              "<td>0.4210526</td>\n",
              "<td>0.4914181</td>\n",
              "<td>0.8271605</td>\n",
              "<td>0.7337987</td>\n",
              "<td>0.1095890</td>\n",
              "<td>0.9178082</td>\n",
              "<td>133.0209084</td>\n",
              "<td>357.7710130</td>\n",
              "<td>0.8755121</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.3143564</td>\n",
              "<td>0.1</td>\n",
              "<td>0.7218582</td>\n",
              "<td>3.1811024</td>\n",
              "<td>0.1304348</td>\n",
              "<td>0.1886636</td>\n",
              "<td>0.5748031</td>\n",
              "<td>0.5363482</td>\n",
              "<td>0.0821918</td>\n",
              "<td>1.0</td>\n",
              "<td>-27.8141751</td>\n",
              "<td>218.1102362</td>\n",
              "<td>0.8368580</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.4158416</td>\n",
              "<td>0.025</td>\n",
              "<td>0.0</td>\n",
              "<td>2.4047619</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0460796</td>\n",
              "<td>0.4345238</td>\n",
              "<td>0.4166993</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>140.4761905</td>\n",
              "<td>0.7129909</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0015555</td>\n",
              "<td>0.1806931</td>\n",
              "<td>0.1741896</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-9.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-9 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-9 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-9 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-9 .h2o-table th,\n",
              "#h2o-table-9 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9777469</td>\n",
              "<td>0.0160733</td>\n",
              "<td>1.0</td>\n",
              "<td>0.962963</td>\n",
              "<td>0.9753087</td>\n",
              "<td>0.962963</td>\n",
              "<td>0.9875</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9935016</td>\n",
              "<td>0.0056154</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9913793</td>\n",
              "<td>0.9912684</td>\n",
              "<td>0.9864253</td>\n",
              "<td>0.9984351</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0222531</td>\n",
              "<td>0.0160733</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0370370</td>\n",
              "<td>0.0246914</td>\n",
              "<td>0.0370370</td>\n",
              "<td>0.0125</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>1.8</td>\n",
              "<td>1.3038405</td>\n",
              "<td>0.0</td>\n",
              "<td>3.0</td>\n",
              "<td>2.0</td>\n",
              "<td>3.0</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9252561</td>\n",
              "<td>0.0470732</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9243697</td>\n",
              "<td>0.9139785</td>\n",
              "<td>0.8695652</td>\n",
              "<td>0.9183673</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9433744</td>\n",
              "<td>0.0395099</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9361702</td>\n",
              "<td>0.9444444</td>\n",
              "<td>0.8888889</td>\n",
              "<td>0.9473684</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9625278</td>\n",
              "<td>0.0350717</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9482759</td>\n",
              "<td>0.9770115</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9782609</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>6.153948</td>\n",
              "<td>2.1099565</td>\n",
              "<td>7.3636365</td>\n",
              "<td>3.5217392</td>\n",
              "<td>4.7647057</td>\n",
              "<td>6.230769</td>\n",
              "<td>8.888889</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1170117</td>\n",
              "<td>0.0529606</td>\n",
              "<td>0.0865601</td>\n",
              "<td>0.1904924</td>\n",
              "<td>0.1220948</td>\n",
              "<td>0.1360216</td>\n",
              "<td>0.0498897</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0331472</td>\n",
              "<td>0.0295329</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0434783</td>\n",
              "<td>0.03125</td>\n",
              "<td>0.0769231</td>\n",
              "<td>0.0140845</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.9302112</td>\n",
              "<td>0.0482777</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9105088</td>\n",
              "<td>0.9310082</td>\n",
              "<td>0.86756</td>\n",
              "<td>0.9419787</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9770370</td>\n",
              "<td>0.0223801</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9610195</td>\n",
              "<td>0.984375</td>\n",
              "<td>0.9468326</td>\n",
              "<td>0.9929578</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0229630</td>\n",
              "<td>0.0223801</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0389805</td>\n",
              "<td>0.015625</td>\n",
              "<td>0.0531674</td>\n",
              "<td>0.0070423</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0328747</td>\n",
              "<td>0.0186715</td>\n",
              "<td>0.0195267</td>\n",
              "<td>0.0585185</td>\n",
              "<td>0.0359781</td>\n",
              "<td>0.0398469</td>\n",
              "<td>0.0105033</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9775584</td>\n",
              "<td>0.0184836</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9810418</td>\n",
              "<td>0.9648672</td>\n",
              "<td>0.9535894</td>\n",
              "<td>0.9882933</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9137093</td>\n",
              "<td>0.0529209</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9166667</td>\n",
              "<td>0.8947368</td>\n",
              "<td>0.8571429</td>\n",
              "<td>0.9</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.7855815</td>\n",
              "<td>0.0809986</td>\n",
              "<td>0.8336174</td>\n",
              "<td>0.7121890</td>\n",
              "<td>0.7830405</td>\n",
              "<td>0.7042582</td>\n",
              "<td>0.8948027</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9759197</td>\n",
              "<td>0.0350294</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9565217</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9230769</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.1746851</td>\n",
              "<td>0.0543119</td>\n",
              "<td>0.1397379</td>\n",
              "<td>0.241906</td>\n",
              "<td>0.1896788</td>\n",
              "<td>0.1996170</td>\n",
              "<td>0.1024856</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9781542</td>\n",
              "<td>0.0145160</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.96875</td>\n",
              "<td>0.9705882</td>\n",
              "<td>0.9859155</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-10.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-10 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-10 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-10 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-10 .h2o-table th,\n",
              "#h2o-table-10 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-12-17 19:12:34</td>\n",
              "<td> 2.457 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td>\n",
              "<td>nan</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:12:35</td>\n",
              "<td> 2.483 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2028585</td>\n",
              "<td>0.6361497</td>\n",
              "<td>0.9635938</td>\n",
              "<td>0.8799314</td>\n",
              "<td>5.1293017</td>\n",
              "<td>0.0412088</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:12:35</td>\n",
              "<td> 2.513 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.2058191</td>\n",
              "<td>0.5179340</td>\n",
              "<td>0.9635943</td>\n",
              "<td>0.8855178</td>\n",
              "<td>5.2267884</td>\n",
              "<td>0.0522388</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:12:35</td>\n",
              "<td> 2.546 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.2112878</td>\n",
              "<td>0.4509528</td>\n",
              "<td>0.9669142</td>\n",
              "<td>0.8679451</td>\n",
              "<td>5.0915068</td>\n",
              "<td>0.0496278</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:12:35</td>\n",
              "<td> 2.578 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.2041308</td>\n",
              "<td>0.4441397</td>\n",
              "<td>0.9705748</td>\n",
              "<td>0.8840673</td>\n",
              "<td>5.0530077</td>\n",
              "<td>0.0470297</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:12:35</td>\n",
              "<td> 2.613 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.1968875</td>\n",
              "<td>0.2791154</td>\n",
              "<td>0.9729338</td>\n",
              "<td>0.9260011</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0445545</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:12:35</td>\n",
              "<td> 2.646 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.1892091</td>\n",
              "<td>0.1937116</td>\n",
              "<td>0.9811902</td>\n",
              "<td>0.9392992</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0420792</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:12:35</td>\n",
              "<td> 2.673 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.1843336</td>\n",
              "<td>0.1909220</td>\n",
              "<td>0.9824939</td>\n",
              "<td>0.9472779</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0346535</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:12:35</td>\n",
              "<td> 2.691 sec</td>\n",
              "<td>38.0</td>\n",
              "<td>0.1811154</td>\n",
              "<td>0.1885614</td>\n",
              "<td>0.9831975</td>\n",
              "<td>0.9506248</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0321782</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-11.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-11 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-11 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-11 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-11 .h2o-table th,\n",
              "#h2o-table-11 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>RM</td>\n",
              "<td>613.3925171</td>\n",
              "<td>1.0</td>\n",
              "<td>0.3742941</td></tr>\n",
              "<tr><td>LSTAT</td>\n",
              "<td>301.5899048</td>\n",
              "<td>0.4916752</td>\n",
              "<td>0.1840311</td></tr>\n",
              "<tr><td>INDUS</td>\n",
              "<td>214.5288239</td>\n",
              "<td>0.3497415</td>\n",
              "<td>0.1309062</td></tr>\n",
              "<tr><td>PTRATIO</td>\n",
              "<td>132.3670807</td>\n",
              "<td>0.2157951</td>\n",
              "<td>0.0807708</td></tr>\n",
              "<tr><td>TAX</td>\n",
              "<td>69.7306366</td>\n",
              "<td>0.1136803</td>\n",
              "<td>0.0425499</td></tr>\n",
              "<tr><td>DIS</td>\n",
              "<td>54.7674179</td>\n",
              "<td>0.0892861</td>\n",
              "<td>0.0334193</td></tr>\n",
              "<tr><td>AGE</td>\n",
              "<td>54.1240921</td>\n",
              "<td>0.0882373</td>\n",
              "<td>0.0330267</td></tr>\n",
              "<tr><td>ZN</td>\n",
              "<td>53.5467644</td>\n",
              "<td>0.0872961</td>\n",
              "<td>0.0326744</td></tr>\n",
              "<tr><td>NOX</td>\n",
              "<td>42.5103226</td>\n",
              "<td>0.0693036</td>\n",
              "<td>0.0259399</td></tr>\n",
              "<tr><td>RAD</td>\n",
              "<td>31.6422729</td>\n",
              "<td>0.0515857</td>\n",
              "<td>0.0193082</td></tr>\n",
              "<tr><td>CRIM</td>\n",
              "<td>29.9898796</td>\n",
              "<td>0.0488918</td>\n",
              "<td>0.0182999</td></tr>\n",
              "<tr><td>B</td>\n",
              "<td>23.7604256</td>\n",
              "<td>0.0387361</td>\n",
              "<td>0.0144987</td></tr>\n",
              "<tr><td>CHAS</td>\n",
              "<td>16.8480835</td>\n",
              "<td>0.0274671</td>\n",
              "<td>0.0102808</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View Model Leaderboard"
      ],
      "metadata": {
        "id": "6-fh5X0hR7G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the AutoML Leaderboard\n",
        "lb = h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\")\n",
        "lb.head(lb.nrows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MFBdTrb7N3XB",
        "outputId": "f89b7a37-eb5d-41b4-af25-5e556d268eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse    training_time_ms    predict_time_per_row_ms  algo\n",
              "-------------------------------------------------------  --------  ---------  --------  ----------------------  --------  ---------  ------------------  -------------------------  ---------------\n",
              "DRF_1_AutoML_2_20231217_191212                           0.990192  0.117893   0.960122               0.0653685  0.183698  0.0337448                 244                   0.040437  DRF\n",
              "GBM_grid_1_AutoML_2_20231217_191212_model_3              0.98866   0.0997077  0.962918               0.0386748  0.167943  0.028205                  512                   0.035692  GBM\n",
              "GBM_4_AutoML_2_20231217_191212                           0.988412  0.109259   0.957465               0.0554981  0.168325  0.0283332                 503                   0.042912  GBM\n",
              "GBM_5_AutoML_2_20231217_191212                           0.98717   0.115994   0.957657               0.0478417  0.183917  0.0338253                 379                   0.031608  GBM\n",
              "GBM_3_AutoML_2_20231217_191212                           0.986839  0.109234   0.956192               0.0531805  0.173079  0.0299564                 399                   0.029637  GBM\n",
              "GBM_grid_1_AutoML_2_20231217_191212_model_1              0.986715  0.115695   0.948451               0.0722179  0.186096  0.0346317                 572                   0.048784  GBM\n",
              "GBM_grid_1_AutoML_2_20231217_191212_model_4              0.986219  0.115684   0.949669               0.0828953  0.183932  0.0338309                 517                   0.049938  GBM\n",
              "StackedEnsemble_AllModels_1_AutoML_2_20231217_191212     0.986012  0.113172   0.936346               0.04331    0.172917  0.0299002                7371                   0.265056  StackedEnsemble\n",
              "StackedEnsemble_BestOfFamily_1_AutoML_2_20231217_191212  0.98597   0.11655    0.934948               0.0394819  0.174224  0.0303539                4139                   0.095048  StackedEnsemble\n",
              "GBM_grid_1_AutoML_2_20231217_191212_model_2              0.985474  0.111881   0.952169               0.0516699  0.176587  0.031183                  650                   0.033818  GBM\n",
              "GBM_grid_1_AutoML_2_20231217_191212_model_5              0.984646  0.121413   0.94385                0.042503   0.186378  0.0347369                 937                   0.041882  GBM\n",
              "GBM_2_AutoML_2_20231217_191212                           0.984315  0.109373   0.951136               0.0707073  0.173028  0.0299387                 417                   0.035161  GBM\n",
              "XGBoost_grid_1_AutoML_2_20231217_191212_model_3          0.982949  0.12287    0.936559               0.0691967  0.18008   0.0324288                2285                   0.020978  XGBoost\n",
              "DeepLearning_grid_1_AutoML_2_20231217_191212_model_2     0.981977  0.187863   0.91479                0.0592228  0.195071  0.0380525                2755                   0.022426  DeepLearning\n",
              "XGBoost_3_AutoML_2_20231217_191212                       0.981418  0.117972   0.94669                0.0668791  0.180969  0.0327499                 500                   0.025802  XGBoost\n",
              "XRT_1_AutoML_2_20231217_191212                           0.979473  0.200375   0.953964               0.0501593  0.181975  0.0331147                 305                   0.028118  DRF\n",
              "XGBoost_2_AutoML_2_20231217_191212                       0.977155  0.14177    0.906613               0.0516699  0.191503  0.0366735                 810                   0.015811  XGBoost\n",
              "XGBoost_grid_1_AutoML_2_20231217_191212_model_2          0.976969  0.127983   0.940009               0.0546911  0.184943  0.0342038                1580                   0.015942  XGBoost\n",
              "XGBoost_grid_1_AutoML_2_20231217_191212_model_7          0.976824  0.14894    0.91494                0.0707073  0.199705  0.0398821                1314                   0.01547   XGBoost\n",
              "XGBoost_grid_1_AutoML_2_20231217_191212_model_4          0.972686  0.163994   0.880766               0.075239   0.209326  0.0438173                1075                   0.016     XGBoost\n",
              "XGBoost_grid_1_AutoML_2_20231217_191212_model_1          0.972623  0.154947   0.902066               0.0737284  0.205187  0.0421019                 553                   0.016182  XGBoost\n",
              "DeepLearning_grid_3_AutoML_2_20231217_191212_model_2     0.972272  0.193895   0.875517               0.0851095  0.212718  0.0452488                4157                   0.036162  DeepLearning\n",
              "DeepLearning_grid_2_AutoML_2_20231217_191212_model_1     0.970782  0.178475   0.915112               0.0912552  0.201892  0.0407604                4341                   0.0498    DeepLearning\n",
              "DeepLearning_grid_2_AutoML_2_20231217_191212_model_2     0.970658  0.20011    0.853949               0.074432   0.215072  0.0462559                4354                   0.027925  DeepLearning\n",
              "DeepLearning_grid_1_AutoML_2_20231217_191212_model_1     0.969706  0.177542   0.891894               0.075239   0.203933  0.0415888                2575                   0.024754  DeepLearning\n",
              "DeepLearning_grid_3_AutoML_2_20231217_191212_model_1     0.969375  0.198748   0.900388               0.0874271  0.208543  0.0434902                2901                   0.077062  DeepLearning\n",
              "GLM_1_AutoML_2_20231217_191212                           0.966809  0.17124    0.875454               0.0820883  0.210612  0.0443573                 219                   0.06652   GLM\n",
              "DeepLearning_1_AutoML_2_20231217_191212                  0.961925  0.195004   0.83475                0.112507   0.23161   0.0536434                 159                   0.018869  DeepLearning\n",
              "XGBoost_1_AutoML_2_20231217_191212                       0.960725  0.210025   0.813908               0.0706038  0.244219  0.0596428                 795                   0.01455   XGBoost\n",
              "XGBoost_grid_1_AutoML_2_20231217_191212_model_6          0.960642  0.208821   0.817552               0.100319   0.241454  0.0583002                 969                   0.014944  XGBoost\n",
              "XGBoost_grid_1_AutoML_2_20231217_191212_model_5          0.95909   0.219036   0.816146               0.0903447  0.252553  0.0637831                1996                   0.014394  XGBoost\n",
              "GBM_1_AutoML_2_20231217_191212                           0.953421  0.206275   0.789186               0.0719075  0.250429  0.0627146                 787                   0.026619  GBM\n",
              "[32 rows x 10 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                                               </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo           </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DRF_1_AutoML_2_20231217_191212                         </td><td style=\"text-align: right;\">0.990192</td><td style=\"text-align: right;\">0.117893 </td><td style=\"text-align: right;\">0.960122</td><td style=\"text-align: right;\">             0.0653685</td><td style=\"text-align: right;\">0.183698</td><td style=\"text-align: right;\">0.0337448</td><td style=\"text-align: right;\">               244</td><td style=\"text-align: right;\">                 0.040437</td><td>DRF            </td></tr>\n",
              "<tr><td>GBM_grid_1_AutoML_2_20231217_191212_model_3            </td><td style=\"text-align: right;\">0.98866 </td><td style=\"text-align: right;\">0.0997077</td><td style=\"text-align: right;\">0.962918</td><td style=\"text-align: right;\">             0.0386748</td><td style=\"text-align: right;\">0.167943</td><td style=\"text-align: right;\">0.028205 </td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">                 0.035692</td><td>GBM            </td></tr>\n",
              "<tr><td>GBM_4_AutoML_2_20231217_191212                         </td><td style=\"text-align: right;\">0.988412</td><td style=\"text-align: right;\">0.109259 </td><td style=\"text-align: right;\">0.957465</td><td style=\"text-align: right;\">             0.0554981</td><td style=\"text-align: right;\">0.168325</td><td style=\"text-align: right;\">0.0283332</td><td style=\"text-align: right;\">               503</td><td style=\"text-align: right;\">                 0.042912</td><td>GBM            </td></tr>\n",
              "<tr><td>GBM_5_AutoML_2_20231217_191212                         </td><td style=\"text-align: right;\">0.98717 </td><td style=\"text-align: right;\">0.115994 </td><td style=\"text-align: right;\">0.957657</td><td style=\"text-align: right;\">             0.0478417</td><td style=\"text-align: right;\">0.183917</td><td style=\"text-align: right;\">0.0338253</td><td style=\"text-align: right;\">               379</td><td style=\"text-align: right;\">                 0.031608</td><td>GBM            </td></tr>\n",
              "<tr><td>GBM_3_AutoML_2_20231217_191212                         </td><td style=\"text-align: right;\">0.986839</td><td style=\"text-align: right;\">0.109234 </td><td style=\"text-align: right;\">0.956192</td><td style=\"text-align: right;\">             0.0531805</td><td style=\"text-align: right;\">0.173079</td><td style=\"text-align: right;\">0.0299564</td><td style=\"text-align: right;\">               399</td><td style=\"text-align: right;\">                 0.029637</td><td>GBM            </td></tr>\n",
              "<tr><td>GBM_grid_1_AutoML_2_20231217_191212_model_1            </td><td style=\"text-align: right;\">0.986715</td><td style=\"text-align: right;\">0.115695 </td><td style=\"text-align: right;\">0.948451</td><td style=\"text-align: right;\">             0.0722179</td><td style=\"text-align: right;\">0.186096</td><td style=\"text-align: right;\">0.0346317</td><td style=\"text-align: right;\">               572</td><td style=\"text-align: right;\">                 0.048784</td><td>GBM            </td></tr>\n",
              "<tr><td>GBM_grid_1_AutoML_2_20231217_191212_model_4            </td><td style=\"text-align: right;\">0.986219</td><td style=\"text-align: right;\">0.115684 </td><td style=\"text-align: right;\">0.949669</td><td style=\"text-align: right;\">             0.0828953</td><td style=\"text-align: right;\">0.183932</td><td style=\"text-align: right;\">0.0338309</td><td style=\"text-align: right;\">               517</td><td style=\"text-align: right;\">                 0.049938</td><td>GBM            </td></tr>\n",
              "<tr><td>StackedEnsemble_AllModels_1_AutoML_2_20231217_191212   </td><td style=\"text-align: right;\">0.986012</td><td style=\"text-align: right;\">0.113172 </td><td style=\"text-align: right;\">0.936346</td><td style=\"text-align: right;\">             0.04331  </td><td style=\"text-align: right;\">0.172917</td><td style=\"text-align: right;\">0.0299002</td><td style=\"text-align: right;\">              7371</td><td style=\"text-align: right;\">                 0.265056</td><td>StackedEnsemble</td></tr>\n",
              "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_2_20231217_191212</td><td style=\"text-align: right;\">0.98597 </td><td style=\"text-align: right;\">0.11655  </td><td style=\"text-align: right;\">0.934948</td><td style=\"text-align: right;\">             0.0394819</td><td style=\"text-align: right;\">0.174224</td><td style=\"text-align: right;\">0.0303539</td><td style=\"text-align: right;\">              4139</td><td style=\"text-align: right;\">                 0.095048</td><td>StackedEnsemble</td></tr>\n",
              "<tr><td>GBM_grid_1_AutoML_2_20231217_191212_model_2            </td><td style=\"text-align: right;\">0.985474</td><td style=\"text-align: right;\">0.111881 </td><td style=\"text-align: right;\">0.952169</td><td style=\"text-align: right;\">             0.0516699</td><td style=\"text-align: right;\">0.176587</td><td style=\"text-align: right;\">0.031183 </td><td style=\"text-align: right;\">               650</td><td style=\"text-align: right;\">                 0.033818</td><td>GBM            </td></tr>\n",
              "<tr><td>GBM_grid_1_AutoML_2_20231217_191212_model_5            </td><td style=\"text-align: right;\">0.984646</td><td style=\"text-align: right;\">0.121413 </td><td style=\"text-align: right;\">0.94385 </td><td style=\"text-align: right;\">             0.042503 </td><td style=\"text-align: right;\">0.186378</td><td style=\"text-align: right;\">0.0347369</td><td style=\"text-align: right;\">               937</td><td style=\"text-align: right;\">                 0.041882</td><td>GBM            </td></tr>\n",
              "<tr><td>GBM_2_AutoML_2_20231217_191212                         </td><td style=\"text-align: right;\">0.984315</td><td style=\"text-align: right;\">0.109373 </td><td style=\"text-align: right;\">0.951136</td><td style=\"text-align: right;\">             0.0707073</td><td style=\"text-align: right;\">0.173028</td><td style=\"text-align: right;\">0.0299387</td><td style=\"text-align: right;\">               417</td><td style=\"text-align: right;\">                 0.035161</td><td>GBM            </td></tr>\n",
              "<tr><td>XGBoost_grid_1_AutoML_2_20231217_191212_model_3        </td><td style=\"text-align: right;\">0.982949</td><td style=\"text-align: right;\">0.12287  </td><td style=\"text-align: right;\">0.936559</td><td style=\"text-align: right;\">             0.0691967</td><td style=\"text-align: right;\">0.18008 </td><td style=\"text-align: right;\">0.0324288</td><td style=\"text-align: right;\">              2285</td><td style=\"text-align: right;\">                 0.020978</td><td>XGBoost        </td></tr>\n",
              "<tr><td>DeepLearning_grid_1_AutoML_2_20231217_191212_model_2   </td><td style=\"text-align: right;\">0.981977</td><td style=\"text-align: right;\">0.187863 </td><td style=\"text-align: right;\">0.91479 </td><td style=\"text-align: right;\">             0.0592228</td><td style=\"text-align: right;\">0.195071</td><td style=\"text-align: right;\">0.0380525</td><td style=\"text-align: right;\">              2755</td><td style=\"text-align: right;\">                 0.022426</td><td>DeepLearning   </td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_2_20231217_191212                     </td><td style=\"text-align: right;\">0.981418</td><td style=\"text-align: right;\">0.117972 </td><td style=\"text-align: right;\">0.94669 </td><td style=\"text-align: right;\">             0.0668791</td><td style=\"text-align: right;\">0.180969</td><td style=\"text-align: right;\">0.0327499</td><td style=\"text-align: right;\">               500</td><td style=\"text-align: right;\">                 0.025802</td><td>XGBoost        </td></tr>\n",
              "<tr><td>XRT_1_AutoML_2_20231217_191212                         </td><td style=\"text-align: right;\">0.979473</td><td style=\"text-align: right;\">0.200375 </td><td style=\"text-align: right;\">0.953964</td><td style=\"text-align: right;\">             0.0501593</td><td style=\"text-align: right;\">0.181975</td><td style=\"text-align: right;\">0.0331147</td><td style=\"text-align: right;\">               305</td><td style=\"text-align: right;\">                 0.028118</td><td>DRF            </td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_2_20231217_191212                     </td><td style=\"text-align: right;\">0.977155</td><td style=\"text-align: right;\">0.14177  </td><td style=\"text-align: right;\">0.906613</td><td style=\"text-align: right;\">             0.0516699</td><td style=\"text-align: right;\">0.191503</td><td style=\"text-align: right;\">0.0366735</td><td style=\"text-align: right;\">               810</td><td style=\"text-align: right;\">                 0.015811</td><td>XGBoost        </td></tr>\n",
              "<tr><td>XGBoost_grid_1_AutoML_2_20231217_191212_model_2        </td><td style=\"text-align: right;\">0.976969</td><td style=\"text-align: right;\">0.127983 </td><td style=\"text-align: right;\">0.940009</td><td style=\"text-align: right;\">             0.0546911</td><td style=\"text-align: right;\">0.184943</td><td style=\"text-align: right;\">0.0342038</td><td style=\"text-align: right;\">              1580</td><td style=\"text-align: right;\">                 0.015942</td><td>XGBoost        </td></tr>\n",
              "<tr><td>XGBoost_grid_1_AutoML_2_20231217_191212_model_7        </td><td style=\"text-align: right;\">0.976824</td><td style=\"text-align: right;\">0.14894  </td><td style=\"text-align: right;\">0.91494 </td><td style=\"text-align: right;\">             0.0707073</td><td style=\"text-align: right;\">0.199705</td><td style=\"text-align: right;\">0.0398821</td><td style=\"text-align: right;\">              1314</td><td style=\"text-align: right;\">                 0.01547 </td><td>XGBoost        </td></tr>\n",
              "<tr><td>XGBoost_grid_1_AutoML_2_20231217_191212_model_4        </td><td style=\"text-align: right;\">0.972686</td><td style=\"text-align: right;\">0.163994 </td><td style=\"text-align: right;\">0.880766</td><td style=\"text-align: right;\">             0.075239 </td><td style=\"text-align: right;\">0.209326</td><td style=\"text-align: right;\">0.0438173</td><td style=\"text-align: right;\">              1075</td><td style=\"text-align: right;\">                 0.016   </td><td>XGBoost        </td></tr>\n",
              "<tr><td>XGBoost_grid_1_AutoML_2_20231217_191212_model_1        </td><td style=\"text-align: right;\">0.972623</td><td style=\"text-align: right;\">0.154947 </td><td style=\"text-align: right;\">0.902066</td><td style=\"text-align: right;\">             0.0737284</td><td style=\"text-align: right;\">0.205187</td><td style=\"text-align: right;\">0.0421019</td><td style=\"text-align: right;\">               553</td><td style=\"text-align: right;\">                 0.016182</td><td>XGBoost        </td></tr>\n",
              "<tr><td>DeepLearning_grid_3_AutoML_2_20231217_191212_model_2   </td><td style=\"text-align: right;\">0.972272</td><td style=\"text-align: right;\">0.193895 </td><td style=\"text-align: right;\">0.875517</td><td style=\"text-align: right;\">             0.0851095</td><td style=\"text-align: right;\">0.212718</td><td style=\"text-align: right;\">0.0452488</td><td style=\"text-align: right;\">              4157</td><td style=\"text-align: right;\">                 0.036162</td><td>DeepLearning   </td></tr>\n",
              "<tr><td>DeepLearning_grid_2_AutoML_2_20231217_191212_model_1   </td><td style=\"text-align: right;\">0.970782</td><td style=\"text-align: right;\">0.178475 </td><td style=\"text-align: right;\">0.915112</td><td style=\"text-align: right;\">             0.0912552</td><td style=\"text-align: right;\">0.201892</td><td style=\"text-align: right;\">0.0407604</td><td style=\"text-align: right;\">              4341</td><td style=\"text-align: right;\">                 0.0498  </td><td>DeepLearning   </td></tr>\n",
              "<tr><td>DeepLearning_grid_2_AutoML_2_20231217_191212_model_2   </td><td style=\"text-align: right;\">0.970658</td><td style=\"text-align: right;\">0.20011  </td><td style=\"text-align: right;\">0.853949</td><td style=\"text-align: right;\">             0.074432 </td><td style=\"text-align: right;\">0.215072</td><td style=\"text-align: right;\">0.0462559</td><td style=\"text-align: right;\">              4354</td><td style=\"text-align: right;\">                 0.027925</td><td>DeepLearning   </td></tr>\n",
              "<tr><td>DeepLearning_grid_1_AutoML_2_20231217_191212_model_1   </td><td style=\"text-align: right;\">0.969706</td><td style=\"text-align: right;\">0.177542 </td><td style=\"text-align: right;\">0.891894</td><td style=\"text-align: right;\">             0.075239 </td><td style=\"text-align: right;\">0.203933</td><td style=\"text-align: right;\">0.0415888</td><td style=\"text-align: right;\">              2575</td><td style=\"text-align: right;\">                 0.024754</td><td>DeepLearning   </td></tr>\n",
              "<tr><td>DeepLearning_grid_3_AutoML_2_20231217_191212_model_1   </td><td style=\"text-align: right;\">0.969375</td><td style=\"text-align: right;\">0.198748 </td><td style=\"text-align: right;\">0.900388</td><td style=\"text-align: right;\">             0.0874271</td><td style=\"text-align: right;\">0.208543</td><td style=\"text-align: right;\">0.0434902</td><td style=\"text-align: right;\">              2901</td><td style=\"text-align: right;\">                 0.077062</td><td>DeepLearning   </td></tr>\n",
              "<tr><td>GLM_1_AutoML_2_20231217_191212                         </td><td style=\"text-align: right;\">0.966809</td><td style=\"text-align: right;\">0.17124  </td><td style=\"text-align: right;\">0.875454</td><td style=\"text-align: right;\">             0.0820883</td><td style=\"text-align: right;\">0.210612</td><td style=\"text-align: right;\">0.0443573</td><td style=\"text-align: right;\">               219</td><td style=\"text-align: right;\">                 0.06652 </td><td>GLM            </td></tr>\n",
              "<tr><td>DeepLearning_1_AutoML_2_20231217_191212                </td><td style=\"text-align: right;\">0.961925</td><td style=\"text-align: right;\">0.195004 </td><td style=\"text-align: right;\">0.83475 </td><td style=\"text-align: right;\">             0.112507 </td><td style=\"text-align: right;\">0.23161 </td><td style=\"text-align: right;\">0.0536434</td><td style=\"text-align: right;\">               159</td><td style=\"text-align: right;\">                 0.018869</td><td>DeepLearning   </td></tr>\n",
              "<tr><td>XGBoost_1_AutoML_2_20231217_191212                     </td><td style=\"text-align: right;\">0.960725</td><td style=\"text-align: right;\">0.210025 </td><td style=\"text-align: right;\">0.813908</td><td style=\"text-align: right;\">             0.0706038</td><td style=\"text-align: right;\">0.244219</td><td style=\"text-align: right;\">0.0596428</td><td style=\"text-align: right;\">               795</td><td style=\"text-align: right;\">                 0.01455 </td><td>XGBoost        </td></tr>\n",
              "<tr><td>XGBoost_grid_1_AutoML_2_20231217_191212_model_6        </td><td style=\"text-align: right;\">0.960642</td><td style=\"text-align: right;\">0.208821 </td><td style=\"text-align: right;\">0.817552</td><td style=\"text-align: right;\">             0.100319 </td><td style=\"text-align: right;\">0.241454</td><td style=\"text-align: right;\">0.0583002</td><td style=\"text-align: right;\">               969</td><td style=\"text-align: right;\">                 0.014944</td><td>XGBoost        </td></tr>\n",
              "<tr><td>XGBoost_grid_1_AutoML_2_20231217_191212_model_5        </td><td style=\"text-align: right;\">0.95909 </td><td style=\"text-align: right;\">0.219036 </td><td style=\"text-align: right;\">0.816146</td><td style=\"text-align: right;\">             0.0903447</td><td style=\"text-align: right;\">0.252553</td><td style=\"text-align: right;\">0.0637831</td><td style=\"text-align: right;\">              1996</td><td style=\"text-align: right;\">                 0.014394</td><td>XGBoost        </td></tr>\n",
              "<tr><td>GBM_1_AutoML_2_20231217_191212                         </td><td style=\"text-align: right;\">0.953421</td><td style=\"text-align: right;\">0.206275 </td><td style=\"text-align: right;\">0.789186</td><td style=\"text-align: right;\">             0.0719075</td><td style=\"text-align: right;\">0.250429</td><td style=\"text-align: right;\">0.0627146</td><td style=\"text-align: right;\">               787</td><td style=\"text-align: right;\">                 0.026619</td><td>GBM            </td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[32 rows x 10 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict with top models and Evaluate Performance"
      ],
      "metadata": {
        "id": "ajEWbHgAR-d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model =  aml.get_best_model()\n",
        "X_test_h2o = h2o.H2OFrame.from_python(X_test)\n",
        "y_pred = best_model.predict(X_test_h2o)\n",
        "y_pred = y_pred.as_data_frame()['predict'].values\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))\n",
        "sns.heatmap(cf, annot=True);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "0dMaV7vDN-u_",
        "outputId": "daf7f9fc-7e9b-4e59-b197-b9a97e44d88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97        91\n",
            "           1       0.80      0.73      0.76        11\n",
            "\n",
            "    accuracy                           0.95       102\n",
            "   macro avg       0.88      0.85      0.87       102\n",
            "weighted avg       0.95      0.95      0.95       102\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "specific_model =  h2o.get_model('StackedEnsemble_AllModels_1_AutoML_2_20231217_191212')\n",
        "y_pred = specific_model.predict(X_test_h2o)\n",
        "y_pred = y_pred.as_data_frame()['predict'].values\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))\n",
        "sns.heatmap(cf, annot=True);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "IdDLhDVXPblH",
        "outputId": "61ccc676-4cf8-466a-93f9-081595e3c935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97        91\n",
            "           1       0.80      0.73      0.76        11\n",
            "\n",
            "    accuracy                           0.95       102\n",
            "   macro avg       0.88      0.85      0.87       102\n",
            "weighted avg       0.95      0.95      0.95       102\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "specific_model =  aml.get_best_model(criterion=\"logloss\")\n",
        "y_pred = specific_model.predict(X_test_h2o)\n",
        "y_pred = y_pred.as_data_frame()['predict'].values\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))\n",
        "sns.heatmap(cf, annot=True);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "ACYUopsvQf37",
        "outputId": "5e1f2cca-1b72-4d68-efe5-83233731be13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        91\n",
            "           1       0.82      0.82      0.82        11\n",
            "\n",
            "    accuracy                           0.96       102\n",
            "   macro avg       0.90      0.90      0.90       102\n",
            "weighted avg       0.96      0.96      0.96       102\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "specific_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k3VSHvpiQufu",
        "outputId": "bda7f2e1-6a44-45be-f60e-400c63aa70df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
              "Model Key: GBM_grid_1_AutoML_2_20231217_191212_model_3\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    77                 77                          15428                  5            6            5.97403       7             15            11.3766\n",
              "\n",
              "ModelMetricsBinomial: gbm\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.002630170988048533\n",
              "RMSE: 0.05128519267828223\n",
              "LogLoss: 0.01879466745695493\n",
              "Mean Per-Class Error: 0.0\n",
              "AUC: 1.0\n",
              "AUCPR: 1.0\n",
              "Gini: 1.0\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5086934391511305\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  -----------\n",
              "0      331  0    0        (0.0/331.0)\n",
              "1      0    73   0        (0.0/73.0)\n",
              "Total  331  73   0        (0.0/404.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.508693     1         72\n",
              "max f2                       0.508693     1         72\n",
              "max f0point5                 0.508693     1         72\n",
              "max accuracy                 0.508693     1         72\n",
              "max precision                0.997535     1         0\n",
              "max recall                   0.508693     1         72\n",
              "max specificity              0.997535     1         0\n",
              "max absolute_mcc             0.508693     1         72\n",
              "max min_per_class_accuracy   0.508693     1         72\n",
              "max mean_per_class_accuracy  0.508693     1         72\n",
              "max tns                      0.997535     331       0\n",
              "max fns                      0.997535     72        0\n",
              "max fps                      0.000109171  331       399\n",
              "max tps                      0.508693     73        72\n",
              "max tnr                      0.997535     1         0\n",
              "max fnr                      0.997535     0.986301  0\n",
              "max fpr                      0.000109171  1         399\n",
              "max tpr                      0.508693     1         72\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 18.07 %, avg score: 17.91 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
              "1        0.0123762                   0.995604           5.53425  5.53425            1                0.996688     1                           0.996688            0.0684932       0.0684932                  453.425  453.425            0.0684932\n",
              "2        0.0222772                   0.994975           5.53425  5.53425            1                0.995256     1                           0.996052            0.0547945       0.123288                   453.425  453.425            0.123288\n",
              "3        0.0321782                   0.994328           5.53425  5.53425            1                0.994573     1                           0.995597            0.0547945       0.178082                   453.425  453.425            0.178082\n",
              "4        0.0420792                   0.992805           5.53425  5.53425            1                0.993548     1                           0.995115            0.0547945       0.232877                   453.425  453.425            0.232877\n",
              "5        0.0519802                   0.990929           5.53425  5.53425            1                0.991858     1                           0.994494            0.0547945       0.287671                   453.425  453.425            0.287671\n",
              "6        0.101485                    0.975651           5.53425  5.53425            1                0.983228     1                           0.988998            0.273973        0.561644                   453.425  453.425            0.561644\n",
              "7        0.15099                     0.915325           5.53425  5.53425            1                0.954669     1                           0.977743            0.273973        0.835616                   453.425  453.425            0.835616\n",
              "8        0.200495                    0.106978           3.32055  4.98765            0.6              0.541133     0.901235                    0.869938            0.164384        1                          232.055  398.765            0.975831\n",
              "9        0.299505                    0.00729041         0        3.33884            0                0.0369945    0.603306                    0.594585            0               1                          -100     233.884            0.854985\n",
              "10       0.40099                     0.00331159         0        2.49383            0                0.00493632   0.450617                    0.445353            0               1                          -100     149.383            0.731118\n",
              "11       0.5                         0.00147768         0        2                  0                0.0022196    0.361386                    0.357604            0               1                          -100     100                0.610272\n",
              "12       0.59901                     0.000892975        0        1.66942            0                0.00116441   0.301653                    0.298688            0               1                          -100     66.9421            0.489426\n",
              "13       0.700495                    0.000550062        0        1.42756            0                0.000696491  0.257951                    0.255516            0               1                          -100     42.7562            0.365559\n",
              "14       0.799505                    0.000417977        0        1.25077            0                0.000477853  0.226006                    0.223932            0               1                          -100     25.0774            0.244713\n",
              "15       0.898515                    0.000312446        0        1.11295            0                0.000359715  0.201102                    0.199296            0               1                          -100     11.2948            0.123867\n",
              "16       1                           0.000109171        0        1                  0                0.000245141  0.180693                    0.179096            0               1                          -100     0                  0\n",
              "\n",
              "ModelMetricsBinomial: gbm\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.028204962342655966\n",
              "RMSE: 0.16794333074777326\n",
              "LogLoss: 0.09970769717993778\n",
              "Mean Per-Class Error: 0.03867483342300211\n",
              "AUC: 0.9886603484666638\n",
              "AUCPR: 0.9629178037785352\n",
              "Gini: 0.9773206969333277\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2814617223275904\n",
              "       0    1    Error    Rate\n",
              "-----  ---  ---  -------  ------------\n",
              "0      319  12   0.0363   (12.0/331.0)\n",
              "1      3    70   0.0411   (3.0/73.0)\n",
              "Total  322  82   0.0371   (15.0/404.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.281462     0.903226  81\n",
              "max f2                       0.281462     0.935829  81\n",
              "max f0point5                 0.708257     0.934426  57\n",
              "max accuracy                 0.614319     0.965347  64\n",
              "max precision                0.999203     1         0\n",
              "max recall                   0.00880571   1         160\n",
              "max specificity              0.999203     1         0\n",
              "max absolute_mcc             0.281462     0.882628  81\n",
              "max min_per_class_accuracy   0.281462     0.958904  81\n",
              "max mean_per_class_accuracy  0.281462     0.961325  81\n",
              "max tns                      0.999203     331       0\n",
              "max fns                      0.999203     72        0\n",
              "max fps                      8.71598e-06  331       399\n",
              "max tps                      0.00880571   73        160\n",
              "max tnr                      0.999203     1         0\n",
              "max fnr                      0.999203     0.986301  0\n",
              "max fpr                      8.71598e-06  1         399\n",
              "max tpr                      0.00880571   1         160\n",
              "\n",
              "Gains/Lift Table: Avg response rate: 18.07 %, avg score: 17.17 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0123762                   0.996972           5.53425   5.53425            1                0.997903     1                           0.997903            0.0684932       0.0684932                  453.425   453.425            0.0684932\n",
              "2        0.0222772                   0.994855           5.53425   5.53425            1                0.995937     1                           0.997029            0.0547945       0.123288                   453.425   453.425            0.123288\n",
              "3        0.0321782                   0.993483           5.53425   5.53425            1                0.993742     1                           0.996018            0.0547945       0.178082                   453.425   453.425            0.178082\n",
              "4        0.0420792                   0.990544           5.53425   5.53425            1                0.991999     1                           0.995072            0.0547945       0.232877                   453.425   453.425            0.232877\n",
              "5        0.0519802                   0.977702           5.53425   5.53425            1                0.986202     1                           0.993382            0.0547945       0.287671                   453.425   453.425            0.287671\n",
              "6        0.101485                    0.931727           5.53425   5.53425            1                0.9571       1                           0.975684            0.273973        0.561644                   453.425   453.425            0.561644\n",
              "7        0.15099                     0.654885           4.70411   5.26207            0.85             0.798477     0.95082                     0.917583            0.232877        0.794521                   370.411   426.207            0.785457\n",
              "8        0.200495                    0.282873           3.04384   4.71436            0.55             0.462215     0.851852                    0.805147            0.150685        0.945205                   204.384   371.436            0.908952\n",
              "9        0.299505                    0.0199741          0.415068  3.29311            0.075            0.0783767    0.595041                    0.564892            0.0410959       0.986301                   -58.4932  229.311            0.838265\n",
              "10       0.40099                     0.00876294         0.134982  2.49383            0.0243902        0.0119991    0.450617                    0.424962            0.0136986       1                          -86.5018  149.383            0.731118\n",
              "11       0.5                         0.00443625         0         2                  0                0.00617161   0.361386                    0.342034            0               1                          -100      100                0.610272\n",
              "12       0.59901                     0.00278414         0         1.66942            0                0.00349877   0.301653                    0.286077            0               1                          -100      66.9421            0.489426\n",
              "13       0.700495                    0.00154733         0         1.42756            0                0.00208186   0.257951                    0.244933            0               1                          -100      42.7562            0.365559\n",
              "14       0.799505                    0.000533916        0         1.25077            0                0.00102674   0.226006                    0.214728            0               1                          -100      25.0774            0.244713\n",
              "15       0.898515                    0.000115392        0         1.11295            0                0.000262692  0.201102                    0.191095            0               1                          -100      11.2948            0.123867\n",
              "16       1                           8.71e-06           0         1                  0                4.54039e-05  0.180693                    0.171707            0               1                          -100      0                  0\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
              "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------\n",
              "accuracy                 0.97284    0.0220846  0.975309      0.950617      0.987654      0.950617      1\n",
              "auc                      0.986511   0.0185417  0.994805      0.985757      0.997243      0.954751      1\n",
              "err                      0.0271605  0.0220846  0.0246914     0.0493827     0.0123457     0.0493827     0\n",
              "err_count                2.2        1.78885    2             4             1             4             0\n",
              "f0point5                 0.924669   0.0573162  0.909091      0.913044      0.955056      0.846154      1\n",
              "f1                       0.927943   0.0598959  0.909091      0.913044      0.971429      0.846154      1\n",
              "f2                       0.931332   0.0633509  0.909091      0.913044      0.988372      0.846154      1\n",
              "lift_top_group           6.15395    2.10996    7.36364       3.52174       4.76471       6.23077       8.88889\n",
              "logloss                  0.100944   0.074943   0.0747426     0.186786      0.0575461     0.171548      0.014098\n",
              "max_per_class_error      0.0694673  0.0624702  0.0909091     0.0869565     0.015625      0.153846      0\n",
              "mcc                      0.910862   0.0723716  0.894805      0.878561      0.964203      0.816742      1\n",
              "mean_per_class_accuracy  0.957448   0.0382656  0.947403      0.93928       0.992188      0.908371      1\n",
              "mean_per_class_error     0.0425517  0.0382656  0.0525974     0.0607196     0.0078125     0.091629      0\n",
              "mse                      0.0285488  0.0205883  0.0234877     0.0525765     0.0162164     0.0466614     0.00380189\n",
              "pr_auc                   0.964384   0.0426465  0.971124      0.970004      0.989275      0.891516      1\n",
              "precision                0.922547   0.0560931  0.909091      0.913044      0.944444      0.846154      1\n",
              "r2                       0.811819   0.123297   0.799867      0.741414      0.90221       0.653682      0.961922\n",
              "recall                   0.933658   0.0661211  0.909091      0.913044      1             0.846154      1\n",
              "rmse                     0.157514   0.0683577  0.153257      0.229296      0.127344      0.216012      0.0616595\n",
              "specificity              0.981239   0.013624   0.985714      0.965517      0.984375      0.970588      1\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------\n",
              "    2023-12-17 19:13:53  11.800 sec  0                  0.384764         0.472443            0.5             0.180693           1                0.819307\n",
              "    2023-12-17 19:13:53  11.828 sec  5                  0.284885         0.288033            0.974527        0.93831            5.53425          0.0346535\n",
              "    2023-12-17 19:13:53  11.859 sec  10                 0.224554         0.204293            0.99075         0.967144           5.53425          0.029703\n",
              "    2023-12-17 19:13:53  11.887 sec  15                 0.190502         0.15744             0.994247        0.978693           5.53425          0.0222772\n",
              "    2023-12-17 19:13:53  11.917 sec  20                 0.159964         0.119847            0.997227        0.989148           5.53425          0.0173267\n",
              "    2023-12-17 19:13:53  11.947 sec  25                 0.140288         0.0945897           0.997475        0.990163           5.53425          0.0148515\n",
              "    2023-12-17 19:13:53  11.971 sec  30                 0.126281         0.0793306           0.998055        0.992331           5.53425          0.0123762\n",
              "    2023-12-17 19:13:53  12.006 sec  35                 0.113422         0.0664204           0.99909         0.996426           5.53425          0.0049505\n",
              "    2023-12-17 19:13:53  12.035 sec  40                 0.106435         0.0584434           0.999172        0.996823           5.53425          0.0049505\n",
              "    2023-12-17 19:13:53  12.061 sec  45                 0.0928418        0.0469112           0.999752        0.998903           5.53425          0.0049505\n",
              "    2023-12-17 19:13:53  12.091 sec  50                 0.0867458        0.0407324           0.999876        0.999443           5.53425          0.0049505\n",
              "    2023-12-17 19:13:53  12.117 sec  55                 0.0799172        0.0359508           0.999917        0.999625           5.53425          0.00247525\n",
              "    2023-12-17 19:13:53  12.150 sec  60                 0.0722129        0.0305747           0.999959        0.999814           5.53425          0.00247525\n",
              "    2023-12-17 19:13:53  12.177 sec  65                 0.0593765        0.024514            1               1                  5.53425          0\n",
              "    2023-12-17 19:13:53  12.215 sec  70                 0.0566322        0.0223705           1               1                  5.53425          0\n",
              "    2023-12-17 19:13:53  12.272 sec  75                 0.0516664        0.019659            1               1                  5.53425          0\n",
              "    2023-12-17 19:13:53  12.292 sec  77                 0.0512852        0.0187947           1               1                  5.53425          0\n",
              "\n",
              "Variable Importances: \n",
              "variable    relative_importance    scaled_importance    percentage\n",
              "----------  ---------------------  -------------------  ------------\n",
              "RM          91.3628                1                    0.446863\n",
              "INDUS       26.1578                0.286307             0.12794\n",
              "LSTAT       23.3884                0.255995             0.114395\n",
              "TAX         16.5616                0.181273             0.0810043\n",
              "PTRATIO     11.1536                0.122081             0.0545533\n",
              "ZN          10.1761                0.111381             0.049772\n",
              "NOX         8.37772                0.0916972            0.0409761\n",
              "CRIM        5.35533                0.0586161            0.0261934\n",
              "DIS         3.73943                0.0409294            0.0182898\n",
              "RAD         3.46014                0.0378725            0.0169238\n",
              "AGE         3.02956                0.0331597            0.0148178\n",
              "B           1.36674                0.0149595            0.00668485\n",
              "CHAS        0.324566               0.0035525            0.00158748\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
              "Model Key: GBM_grid_1_AutoML_2_20231217_191212_model_3\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-30.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-30 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-30 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-30 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-30 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-30 .h2o-table th,\n",
              "#h2o-table-30 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-30 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-30\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>77.0</td>\n",
              "<td>77.0</td>\n",
              "<td>15428.0</td>\n",
              "<td>5.0</td>\n",
              "<td>6.0</td>\n",
              "<td>5.974026</td>\n",
              "<td>7.0</td>\n",
              "<td>15.0</td>\n",
              "<td>11.376623</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.002630170988048533\n",
              "RMSE: 0.05128519267828223\n",
              "LogLoss: 0.01879466745695493\n",
              "Mean Per-Class Error: 0.0\n",
              "AUC: 1.0\n",
              "AUCPR: 1.0\n",
              "Gini: 1.0</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-31.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-31 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-31 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-31 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-31 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-31 .h2o-table th,\n",
              "#h2o-table-31 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-31 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-31\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5086934391511305</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>331.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td> (0.0/331.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>0.0</td>\n",
              "<td>73.0</td>\n",
              "<td>0.0</td>\n",
              "<td> (0.0/73.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>331.0</td>\n",
              "<td>73.0</td>\n",
              "<td>0.0</td>\n",
              "<td> (0.0/404.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-32.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-32 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-32 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-32 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-32 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-32 .h2o-table th,\n",
              "#h2o-table-32 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-32 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-32\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9975350</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9975350</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9975350</td>\n",
              "<td>331.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9975350</td>\n",
              "<td>72.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0001092</td>\n",
              "<td>331.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.5086934</td>\n",
              "<td>73.0</td>\n",
              "<td>72.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9975350</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9975350</td>\n",
              "<td>0.9863014</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0001092</td>\n",
              "<td>1.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.5086934</td>\n",
              "<td>1.0</td>\n",
              "<td>72.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-33.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-33 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-33 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-33 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-33 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-33 .h2o-table th,\n",
              "#h2o-table-33 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-33 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-33\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 18.07 %, avg score: 17.91 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0123762</td>\n",
              "<td>0.9956041</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9966881</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9966881</td>\n",
              "<td>0.0684932</td>\n",
              "<td>0.0684932</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.0684932</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0222772</td>\n",
              "<td>0.9949749</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9952565</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9960518</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.1232877</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.1232877</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0321782</td>\n",
              "<td>0.9943278</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9945733</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9955969</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.1780822</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.1780822</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0420792</td>\n",
              "<td>0.9928054</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9935478</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9951147</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.2328767</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.2328767</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.0519802</td>\n",
              "<td>0.9909291</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9918576</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9944943</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.2876712</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.2876712</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1014851</td>\n",
              "<td>0.9756512</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9832275</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9889983</td>\n",
              "<td>0.2739726</td>\n",
              "<td>0.5616438</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.5616438</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.1509901</td>\n",
              "<td>0.9153246</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9546694</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9777430</td>\n",
              "<td>0.2739726</td>\n",
              "<td>0.8356164</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.8356164</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.2004950</td>\n",
              "<td>0.1069781</td>\n",
              "<td>3.3205479</td>\n",
              "<td>4.9876543</td>\n",
              "<td>0.6</td>\n",
              "<td>0.5411329</td>\n",
              "<td>0.9012346</td>\n",
              "<td>0.8699380</td>\n",
              "<td>0.1643836</td>\n",
              "<td>1.0</td>\n",
              "<td>232.0547945</td>\n",
              "<td>398.7654321</td>\n",
              "<td>0.9758308</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.2995050</td>\n",
              "<td>0.0072904</td>\n",
              "<td>0.0</td>\n",
              "<td>3.3388430</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0369945</td>\n",
              "<td>0.6033058</td>\n",
              "<td>0.5945848</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>233.8842975</td>\n",
              "<td>0.8549849</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.4009901</td>\n",
              "<td>0.0033116</td>\n",
              "<td>0.0</td>\n",
              "<td>2.4938272</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0049363</td>\n",
              "<td>0.4506173</td>\n",
              "<td>0.4453528</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>149.3827160</td>\n",
              "<td>0.7311178</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0014777</td>\n",
              "<td>0.0</td>\n",
              "<td>2.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0022196</td>\n",
              "<td>0.3613861</td>\n",
              "<td>0.3576036</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>100.0</td>\n",
              "<td>0.6102719</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.5990099</td>\n",
              "<td>0.0008930</td>\n",
              "<td>0.0</td>\n",
              "<td>1.6694215</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0011644</td>\n",
              "<td>0.3016529</td>\n",
              "<td>0.2986881</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>66.9421488</td>\n",
              "<td>0.4894260</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.7004950</td>\n",
              "<td>0.0005501</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4275618</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0006965</td>\n",
              "<td>0.2579505</td>\n",
              "<td>0.2555161</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>42.7561837</td>\n",
              "<td>0.3655589</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.7995050</td>\n",
              "<td>0.0004180</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2507740</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0004779</td>\n",
              "<td>0.2260062</td>\n",
              "<td>0.2239324</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>25.0773994</td>\n",
              "<td>0.2447130</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>0.8985149</td>\n",
              "<td>0.0003124</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1129477</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0003597</td>\n",
              "<td>0.2011019</td>\n",
              "<td>0.1992963</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>11.2947658</td>\n",
              "<td>0.1238671</td></tr>\n",
              "<tr><td>16</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0001092</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0002451</td>\n",
              "<td>0.1806931</td>\n",
              "<td>0.1790956</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 0.028204962342655966\n",
              "RMSE: 0.16794333074777326\n",
              "LogLoss: 0.09970769717993778\n",
              "Mean Per-Class Error: 0.03867483342300211\n",
              "AUC: 0.9886603484666638\n",
              "AUCPR: 0.9629178037785352\n",
              "Gini: 0.9773206969333277</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-34.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-34 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-34 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-34 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-34 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-34 .h2o-table th,\n",
              "#h2o-table-34 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-34 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-34\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2814617223275904</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>319.0</td>\n",
              "<td>12.0</td>\n",
              "<td>0.0363</td>\n",
              "<td> (12.0/331.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>3.0</td>\n",
              "<td>70.0</td>\n",
              "<td>0.0411</td>\n",
              "<td> (3.0/73.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>322.0</td>\n",
              "<td>82.0</td>\n",
              "<td>0.0371</td>\n",
              "<td> (15.0/404.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-35.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-35 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-35 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-35 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-35 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-35 .h2o-table th,\n",
              "#h2o-table-35 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-35 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-35\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.2814617</td>\n",
              "<td>0.9032258</td>\n",
              "<td>81.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2814617</td>\n",
              "<td>0.9358289</td>\n",
              "<td>81.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.7082567</td>\n",
              "<td>0.9344262</td>\n",
              "<td>57.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.6143187</td>\n",
              "<td>0.9653465</td>\n",
              "<td>64.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9992028</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0088057</td>\n",
              "<td>1.0</td>\n",
              "<td>160.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9992028</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.2814617</td>\n",
              "<td>0.8826280</td>\n",
              "<td>81.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.2814617</td>\n",
              "<td>0.9589041</td>\n",
              "<td>81.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.2814617</td>\n",
              "<td>0.9613252</td>\n",
              "<td>81.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9992028</td>\n",
              "<td>331.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9992028</td>\n",
              "<td>72.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0000087</td>\n",
              "<td>331.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0088057</td>\n",
              "<td>73.0</td>\n",
              "<td>160.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9992028</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9992028</td>\n",
              "<td>0.9863014</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0000087</td>\n",
              "<td>1.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0088057</td>\n",
              "<td>1.0</td>\n",
              "<td>160.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-36.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-36 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-36 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-36 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-36 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-36 .h2o-table th,\n",
              "#h2o-table-36 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-36 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-36\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate: 18.07 %, avg score: 17.17 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0123762</td>\n",
              "<td>0.9969717</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9979026</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9979026</td>\n",
              "<td>0.0684932</td>\n",
              "<td>0.0684932</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.0684932</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0222772</td>\n",
              "<td>0.9948553</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9959374</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9970292</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.1232877</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.1232877</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0321782</td>\n",
              "<td>0.9934833</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9937419</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9960177</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.1780822</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.1780822</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0420792</td>\n",
              "<td>0.9905445</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9919985</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9950720</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.2328767</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.2328767</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.0519802</td>\n",
              "<td>0.9777016</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9862016</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9933824</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.2876712</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.2876712</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1014851</td>\n",
              "<td>0.9317275</td>\n",
              "<td>5.5342466</td>\n",
              "<td>5.5342466</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9571004</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9756839</td>\n",
              "<td>0.2739726</td>\n",
              "<td>0.5616438</td>\n",
              "<td>453.4246575</td>\n",
              "<td>453.4246575</td>\n",
              "<td>0.5616438</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.1509901</td>\n",
              "<td>0.6548848</td>\n",
              "<td>4.7041096</td>\n",
              "<td>5.2620705</td>\n",
              "<td>0.85</td>\n",
              "<td>0.7984767</td>\n",
              "<td>0.9508197</td>\n",
              "<td>0.9175832</td>\n",
              "<td>0.2328767</td>\n",
              "<td>0.7945205</td>\n",
              "<td>370.4109589</td>\n",
              "<td>426.2070514</td>\n",
              "<td>0.7854571</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.2004950</td>\n",
              "<td>0.2828732</td>\n",
              "<td>3.0438356</td>\n",
              "<td>4.7143582</td>\n",
              "<td>0.55</td>\n",
              "<td>0.4622151</td>\n",
              "<td>0.8518519</td>\n",
              "<td>0.8051466</td>\n",
              "<td>0.1506849</td>\n",
              "<td>0.9452055</td>\n",
              "<td>204.3835616</td>\n",
              "<td>371.4358194</td>\n",
              "<td>0.9089517</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.2995050</td>\n",
              "<td>0.0199741</td>\n",
              "<td>0.4150685</td>\n",
              "<td>3.2931054</td>\n",
              "<td>0.075</td>\n",
              "<td>0.0783767</td>\n",
              "<td>0.5950413</td>\n",
              "<td>0.5648921</td>\n",
              "<td>0.0410959</td>\n",
              "<td>0.9863014</td>\n",
              "<td>-58.4931507</td>\n",
              "<td>229.3105400</td>\n",
              "<td>0.8382651</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.4009901</td>\n",
              "<td>0.0087629</td>\n",
              "<td>0.1349816</td>\n",
              "<td>2.4938272</td>\n",
              "<td>0.0243902</td>\n",
              "<td>0.0119991</td>\n",
              "<td>0.4506173</td>\n",
              "<td>0.4249624</td>\n",
              "<td>0.0136986</td>\n",
              "<td>1.0</td>\n",
              "<td>-86.5018376</td>\n",
              "<td>149.3827160</td>\n",
              "<td>0.7311178</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0044362</td>\n",
              "<td>0.0</td>\n",
              "<td>2.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0061716</td>\n",
              "<td>0.3613861</td>\n",
              "<td>0.3420335</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>100.0</td>\n",
              "<td>0.6102719</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.5990099</td>\n",
              "<td>0.0027841</td>\n",
              "<td>0.0</td>\n",
              "<td>1.6694215</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0034988</td>\n",
              "<td>0.3016529</td>\n",
              "<td>0.2860774</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>66.9421488</td>\n",
              "<td>0.4894260</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.7004950</td>\n",
              "<td>0.0015473</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4275618</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0020819</td>\n",
              "<td>0.2579505</td>\n",
              "<td>0.2449331</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>42.7561837</td>\n",
              "<td>0.3655589</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.7995050</td>\n",
              "<td>0.0005339</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2507740</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0010267</td>\n",
              "<td>0.2260062</td>\n",
              "<td>0.2147280</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>25.0773994</td>\n",
              "<td>0.2447130</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>0.8985149</td>\n",
              "<td>0.0001154</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1129477</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0002627</td>\n",
              "<td>0.2011019</td>\n",
              "<td>0.1910955</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>11.2947658</td>\n",
              "<td>0.1238671</td></tr>\n",
              "<tr><td>16</td>\n",
              "<td>1.0</td>\n",
              "<td>8.71e-06</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0000454</td>\n",
              "<td>0.1806931</td>\n",
              "<td>0.1717067</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-37.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-37 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-37 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-37 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-37 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-37 .h2o-table th,\n",
              "#h2o-table-37 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-37 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-37\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th></tr></thead>\n",
              "    <tbody><tr><td>accuracy</td>\n",
              "<td>0.9728395</td>\n",
              "<td>0.0220846</td>\n",
              "<td>0.9753087</td>\n",
              "<td>0.9506173</td>\n",
              "<td>0.9876543</td>\n",
              "<td>0.9506173</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>auc</td>\n",
              "<td>0.9865112</td>\n",
              "<td>0.0185417</td>\n",
              "<td>0.9948052</td>\n",
              "<td>0.9857571</td>\n",
              "<td>0.9972426</td>\n",
              "<td>0.9547511</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>err</td>\n",
              "<td>0.0271605</td>\n",
              "<td>0.0220846</td>\n",
              "<td>0.0246914</td>\n",
              "<td>0.0493827</td>\n",
              "<td>0.0123457</td>\n",
              "<td>0.0493827</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>err_count</td>\n",
              "<td>2.2</td>\n",
              "<td>1.7888544</td>\n",
              "<td>2.0</td>\n",
              "<td>4.0</td>\n",
              "<td>1.0</td>\n",
              "<td>4.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>f0point5</td>\n",
              "<td>0.9246689</td>\n",
              "<td>0.0573162</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9130435</td>\n",
              "<td>0.9550562</td>\n",
              "<td>0.8461539</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>f1</td>\n",
              "<td>0.9279433</td>\n",
              "<td>0.0598959</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9130435</td>\n",
              "<td>0.9714286</td>\n",
              "<td>0.8461539</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>f2</td>\n",
              "<td>0.9313320</td>\n",
              "<td>0.0633509</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9130435</td>\n",
              "<td>0.9883721</td>\n",
              "<td>0.8461539</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>lift_top_group</td>\n",
              "<td>6.153948</td>\n",
              "<td>2.1099565</td>\n",
              "<td>7.3636365</td>\n",
              "<td>3.5217392</td>\n",
              "<td>4.7647057</td>\n",
              "<td>6.230769</td>\n",
              "<td>8.888889</td></tr>\n",
              "<tr><td>logloss</td>\n",
              "<td>0.1009440</td>\n",
              "<td>0.0749430</td>\n",
              "<td>0.0747426</td>\n",
              "<td>0.1867858</td>\n",
              "<td>0.0575461</td>\n",
              "<td>0.1715477</td>\n",
              "<td>0.0140980</td></tr>\n",
              "<tr><td>max_per_class_error</td>\n",
              "<td>0.0694673</td>\n",
              "<td>0.0624702</td>\n",
              "<td>0.0909091</td>\n",
              "<td>0.0869565</td>\n",
              "<td>0.015625</td>\n",
              "<td>0.1538462</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>mcc</td>\n",
              "<td>0.9108622</td>\n",
              "<td>0.0723716</td>\n",
              "<td>0.8948052</td>\n",
              "<td>0.8785607</td>\n",
              "<td>0.9642031</td>\n",
              "<td>0.8167421</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>mean_per_class_accuracy</td>\n",
              "<td>0.9574483</td>\n",
              "<td>0.0382656</td>\n",
              "<td>0.9474026</td>\n",
              "<td>0.9392803</td>\n",
              "<td>0.9921875</td>\n",
              "<td>0.9083710</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>mean_per_class_error</td>\n",
              "<td>0.0425517</td>\n",
              "<td>0.0382656</td>\n",
              "<td>0.0525974</td>\n",
              "<td>0.0607196</td>\n",
              "<td>0.0078125</td>\n",
              "<td>0.0916290</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>0.0285488</td>\n",
              "<td>0.0205883</td>\n",
              "<td>0.0234877</td>\n",
              "<td>0.0525765</td>\n",
              "<td>0.0162164</td>\n",
              "<td>0.0466614</td>\n",
              "<td>0.0038019</td></tr>\n",
              "<tr><td>pr_auc</td>\n",
              "<td>0.9643838</td>\n",
              "<td>0.0426465</td>\n",
              "<td>0.9711242</td>\n",
              "<td>0.9700043</td>\n",
              "<td>0.9892752</td>\n",
              "<td>0.8915156</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>precision</td>\n",
              "<td>0.9225465</td>\n",
              "<td>0.0560931</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9130435</td>\n",
              "<td>0.9444444</td>\n",
              "<td>0.8461539</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>0.8118187</td>\n",
              "<td>0.1232968</td>\n",
              "<td>0.7998669</td>\n",
              "<td>0.7414136</td>\n",
              "<td>0.9022096</td>\n",
              "<td>0.6536819</td>\n",
              "<td>0.9619216</td></tr>\n",
              "<tr><td>recall</td>\n",
              "<td>0.9336577</td>\n",
              "<td>0.0661211</td>\n",
              "<td>0.9090909</td>\n",
              "<td>0.9130435</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8461539</td>\n",
              "<td>1.0</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>0.1575136</td>\n",
              "<td>0.0683577</td>\n",
              "<td>0.1532568</td>\n",
              "<td>0.2292956</td>\n",
              "<td>0.1273437</td>\n",
              "<td>0.2160124</td>\n",
              "<td>0.0616595</td></tr>\n",
              "<tr><td>specificity</td>\n",
              "<td>0.9812390</td>\n",
              "<td>0.0136240</td>\n",
              "<td>0.9857143</td>\n",
              "<td>0.9655172</td>\n",
              "<td>0.984375</td>\n",
              "<td>0.9705882</td>\n",
              "<td>1.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-38.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-38 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-38 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-38 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-38 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-38 .h2o-table th,\n",
              "#h2o-table-38 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-38 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-38\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>11.800 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>0.3847637</td>\n",
              "<td>0.4724428</td>\n",
              "<td>0.5</td>\n",
              "<td>0.1806931</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8193069</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>11.828 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.2848853</td>\n",
              "<td>0.2880329</td>\n",
              "<td>0.9745272</td>\n",
              "<td>0.9383103</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0346535</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>11.859 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.2245542</td>\n",
              "<td>0.2042933</td>\n",
              "<td>0.9907503</td>\n",
              "<td>0.9671443</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0297030</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>11.887 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.1905025</td>\n",
              "<td>0.1574402</td>\n",
              "<td>0.9942474</td>\n",
              "<td>0.9786927</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0222772</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>11.917 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.1599645</td>\n",
              "<td>0.1198465</td>\n",
              "<td>0.9972272</td>\n",
              "<td>0.9891484</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0173267</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>11.947 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.1402883</td>\n",
              "<td>0.0945897</td>\n",
              "<td>0.9974755</td>\n",
              "<td>0.9901631</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0148515</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>11.971 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.1262810</td>\n",
              "<td>0.0793306</td>\n",
              "<td>0.9980549</td>\n",
              "<td>0.9923309</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0123762</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.006 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.1134215</td>\n",
              "<td>0.0664204</td>\n",
              "<td>0.9990895</td>\n",
              "<td>0.9964261</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0049505</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.035 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.1064348</td>\n",
              "<td>0.0584434</td>\n",
              "<td>0.9991723</td>\n",
              "<td>0.9968231</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0049505</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.061 sec</td>\n",
              "<td>45.0</td>\n",
              "<td>0.0928418</td>\n",
              "<td>0.0469112</td>\n",
              "<td>0.9997517</td>\n",
              "<td>0.9989032</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0049505</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.091 sec</td>\n",
              "<td>50.0</td>\n",
              "<td>0.0867458</td>\n",
              "<td>0.0407324</td>\n",
              "<td>0.9998758</td>\n",
              "<td>0.9994433</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0049505</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.117 sec</td>\n",
              "<td>55.0</td>\n",
              "<td>0.0799172</td>\n",
              "<td>0.0359508</td>\n",
              "<td>0.9999172</td>\n",
              "<td>0.9996247</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0024752</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.150 sec</td>\n",
              "<td>60.0</td>\n",
              "<td>0.0722129</td>\n",
              "<td>0.0305747</td>\n",
              "<td>0.9999586</td>\n",
              "<td>0.9998136</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0024752</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.177 sec</td>\n",
              "<td>65.0</td>\n",
              "<td>0.0593765</td>\n",
              "<td>0.0245140</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.215 sec</td>\n",
              "<td>70.0</td>\n",
              "<td>0.0566322</td>\n",
              "<td>0.0223705</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.272 sec</td>\n",
              "<td>75.0</td>\n",
              "<td>0.0516664</td>\n",
              "<td>0.0196590</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2023-12-17 19:13:53</td>\n",
              "<td>12.292 sec</td>\n",
              "<td>77.0</td>\n",
              "<td>0.0512852</td>\n",
              "<td>0.0187947</td>\n",
              "<td>1.0</td>\n",
              "<td>1.0</td>\n",
              "<td>5.5342466</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-39.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-39 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-39 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-39 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-39 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-39 .h2o-table th,\n",
              "#h2o-table-39 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-39 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-39\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>RM</td>\n",
              "<td>91.3628311</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4468628</td></tr>\n",
              "<tr><td>INDUS</td>\n",
              "<td>26.1578102</td>\n",
              "<td>0.2863069</td>\n",
              "<td>0.1279399</td></tr>\n",
              "<tr><td>LSTAT</td>\n",
              "<td>23.3884010</td>\n",
              "<td>0.2559947</td>\n",
              "<td>0.1143945</td></tr>\n",
              "<tr><td>TAX</td>\n",
              "<td>16.5616379</td>\n",
              "<td>0.1812733</td>\n",
              "<td>0.0810043</td></tr>\n",
              "<tr><td>PTRATIO</td>\n",
              "<td>11.1536417</td>\n",
              "<td>0.1220807</td>\n",
              "<td>0.0545533</td></tr>\n",
              "<tr><td>ZN</td>\n",
              "<td>10.1760693</td>\n",
              "<td>0.1113808</td>\n",
              "<td>0.0497720</td></tr>\n",
              "<tr><td>NOX</td>\n",
              "<td>8.3777180</td>\n",
              "<td>0.0916972</td>\n",
              "<td>0.0409761</td></tr>\n",
              "<tr><td>CRIM</td>\n",
              "<td>5.3553329</td>\n",
              "<td>0.0586161</td>\n",
              "<td>0.0261934</td></tr>\n",
              "<tr><td>DIS</td>\n",
              "<td>3.7394254</td>\n",
              "<td>0.0409294</td>\n",
              "<td>0.0182898</td></tr>\n",
              "<tr><td>RAD</td>\n",
              "<td>3.4601381</td>\n",
              "<td>0.0378725</td>\n",
              "<td>0.0169238</td></tr>\n",
              "<tr><td>AGE</td>\n",
              "<td>3.0295601</td>\n",
              "<td>0.0331597</td>\n",
              "<td>0.0148178</td></tr>\n",
              "<tr><td>B</td>\n",
              "<td>1.3667440</td>\n",
              "<td>0.0149595</td>\n",
              "<td>0.0066849</td></tr>\n",
              "<tr><td>CHAS</td>\n",
              "<td>0.3245662</td>\n",
              "<td>0.0035525</td>\n",
              "<td>0.0015875</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOrAEu6z9uBf"
      },
      "source": [
        "## Auto-ML with TPOT\n",
        "\n",
        "Here we will use the `tpot` library to build classification models. Do check out the [package documentation](https://epistasislab.github.io/tpot) when needed.\n",
        "\n",
        "TPOT will automate the most tedious part of machine learning by intelligently exploring thousands of possible pipelines using genetic programming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCq_KdcJkTB6"
      },
      "source": [
        "### Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nEm1dBM-Mp_"
      },
      "source": [
        "from tpot import TPOTClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByHDEVVAkXxU"
      },
      "source": [
        "### Create Auto-ML Modeling Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgDDSLuwKJ04"
      },
      "source": [
        "tpot_clf = TPOTClassifier(scoring='neg_log_loss',\n",
        "                          cv=5,\n",
        "                          max_time_mins=5, # max of 5 mins to try and get the best model\n",
        "                          random_state=1,\n",
        "                          verbosity=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xlcq1kkkY8K"
      },
      "source": [
        "### Train Models to select Best Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f483d7076ed04c0e9314d2fea81d3345",
            "07f7cfc0b28743bb90b1638389305113",
            "49e0a0a117234445ab06b8bd388d5663",
            "c9592f6f6f5f454384de95a06574bb00",
            "5f9244b0c43b4f60851c75d3f8e5349c",
            "045eb5a4444f461faa4ea132e250afdf",
            "2ace64977bf7488da85bd7547b3b8917",
            "95e3a720489842acbeb7e1945a48f08e",
            "a05a663c54164ebe822302df313008bc",
            "b73f273224034580af606c0da8f6e51e",
            "f5dac09667b5414f95ca0886b913a307"
          ]
        },
        "id": "vaUG1SVCLwiM",
        "outputId": "b098435c-04b8-4b2d-9750-dd5e1b49c2c4"
      },
      "source": [
        "tpot_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32 operators have been imported by TPOT.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f483d7076ed04c0e9314d2fea81d3345"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "\n",
            "Generation 1 - Current Pareto front scores:\n",
            "\n",
            "-1\t-0.09271912201705111\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.1, GradientBoostingClassifier__max_depth=2, GradientBoostingClassifier__max_features=0.9500000000000001, GradientBoostingClassifier__min_samples_leaf=16, GradientBoostingClassifier__min_samples_split=5, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.9000000000000001)\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "\n",
            "Generation 2 - Current Pareto front scores:\n",
            "\n",
            "-1\t-0.09271912201705111\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.1, GradientBoostingClassifier__max_depth=2, GradientBoostingClassifier__max_features=0.9500000000000001, GradientBoostingClassifier__min_samples_leaf=16, GradientBoostingClassifier__min_samples_split=5, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.9000000000000001)\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by BernoulliNB..\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "\n",
            "5.01 minutes have elapsed. TPOT will close down.\n",
            "TPOT closed during evaluation in one generation.\n",
            "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
            "\n",
            "\n",
            "TPOT closed prematurely. Will use the current best pipeline.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(max_time_mins=5, random_state=1, scoring='neg_log_loss',\n",
              "               verbosity=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(max_time_mins=5, random_state=1, scoring=&#x27;neg_log_loss&#x27;,\n",
              "               verbosity=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(max_time_mins=5, random_state=1, scoring=&#x27;neg_log_loss&#x27;,\n",
              "               verbosity=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TRXDAgXkkVw"
      },
      "source": [
        "### View Training Details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "e9_z3tY3M_aT",
        "outputId": "628ce441-1d99-48b5-90d6-292fa120b9e1"
      },
      "source": [
        "tpot_clf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(max_time_mins=5, random_state=1, scoring='neg_log_loss',\n",
              "               verbosity=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(max_time_mins=5, random_state=1, scoring=&#x27;neg_log_loss&#x27;,\n",
              "               verbosity=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(max_time_mins=5, random_state=1, scoring=&#x27;neg_log_loss&#x27;,\n",
              "               verbosity=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "EzRc-J0rOsKO",
        "outputId": "58469f74-4a53-426b-9097-7bee855d9aac"
      },
      "source": [
        "tpot_clf.fitted_pipeline_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('gradientboostingclassifier',\n",
              "                 GradientBoostingClassifier(max_depth=2,\n",
              "                                            max_features=0.9500000000000001,\n",
              "                                            min_samples_leaf=16,\n",
              "                                            min_samples_split=5, random_state=1,\n",
              "                                            subsample=0.9000000000000001))])"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;gradientboostingclassifier&#x27;,\n",
              "                 GradientBoostingClassifier(max_depth=2,\n",
              "                                            max_features=0.9500000000000001,\n",
              "                                            min_samples_leaf=16,\n",
              "                                            min_samples_split=5, random_state=1,\n",
              "                                            subsample=0.9000000000000001))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gradientboostingclassifier&#x27;,\n",
              "                 GradientBoostingClassifier(max_depth=2,\n",
              "                                            max_features=0.9500000000000001,\n",
              "                                            min_samples_leaf=16,\n",
              "                                            min_samples_split=5, random_state=1,\n",
              "                                            subsample=0.9000000000000001))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=2, max_features=0.9500000000000001,\n",
              "                           min_samples_leaf=16, min_samples_split=5,\n",
              "                           random_state=1, subsample=0.9000000000000001)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8rLZoUQkq0W"
      },
      "source": [
        "### Predict and Evaluate Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NESPOzg7QLx6",
        "outputId": "df218d28-c4bb-4af8-bbbd-2b96fd12f380"
      },
      "source": [
        "predictions = tpot_clf.predict(X_test)\n",
        "predictions[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "nNi40vt6QT8S",
        "outputId": "e815bc68-f506-4327-ce81-8c01352010df"
      },
      "source": [
        "cf = confusion_matrix(y_test, predictions)\n",
        "print(classification_report(y_test, predictions))\n",
        "sns.heatmap(cf, annot=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97        91\n",
            "           1       0.80      0.73      0.76        11\n",
            "\n",
            "    accuracy                           0.95       102\n",
            "   macro avg       0.88      0.85      0.87       102\n",
            "weighted avg       0.95      0.95      0.95       102\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ12LkRneo7b"
      },
      "source": [
        "## Auto-ML with FLAML\n",
        "\n",
        "Here we will use the `flaml` library to build classification models. Do check out the [package documentation](https://microsoft.github.io/FLAML/#) when needed.\n",
        "\n",
        "FLAML is powered by a new, cost-effective hyperparameter optimization and learner selection method invented by Microsoft Research.\n",
        "\n",
        "FLAML leverages the structure of the search space to choose a search order optimized for both cost and error. For example, the system tends to propose cheap configurations at the beginning stage of the search, but quickly moves to configurations with high model complexity and large sample size when needed in the later stage of the search.\n",
        "\n",
        "For another example, it favors cheap learners in the beginning but penalizes them later if the error improvement is slow.\n",
        "\n",
        "The cost-bounded search and cost-based prioritization make a big difference in the search efficiency under budget constraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clRAVMWGfAQs"
      },
      "source": [
        "### Load Dependencies and Setup AutoML Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thbFnJohZxsu"
      },
      "source": [
        "from flaml import AutoML\n",
        "\n",
        "automl = AutoML()\n",
        "\n",
        "automl_settings = {\n",
        "    \"time_budget\": 300, # 5 mins to try and select the best model\n",
        "    \"metric\": 'f1',\n",
        "    \"task\": 'classification',\n",
        "    \"log_file_name\": 'mylog.log',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFJGn8xMfFD3"
      },
      "source": [
        "### Train Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8az8he23aeJQ",
        "outputId": "2b84c5f8-718d-4234-97c4-fd4c2303a981"
      },
      "source": [
        "automl.fit(X_train=X_train, y_train=y_train.values,\n",
        "           **automl_settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 19:55:37] {1679} INFO - task = classification\n",
            "[flaml.automl.logger: 12-17 19:55:37] {1690} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 12-17 19:55:37] {1788} INFO - Minimizing error metric: 1-f1\n",
            "[flaml.automl.logger: 12-17 19:55:37] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl.logger: 12-17 19:55:37] {2218} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:37] {2344} INFO - Estimated sufficient time budget=2710s. Estimated necessary time budget=62s.\n",
            "[flaml.automl.logger: 12-17 19:55:37] {2391} INFO -  at 0.3s,\testimator lgbm's best error=1.0000,\tbest estimator lgbm's best error=1.0000\n",
            "[flaml.automl.logger: 12-17 19:55:37] {2218} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 0.5s,\testimator lgbm's best error=1.0000,\tbest estimator lgbm's best error=1.0000\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 0.6s,\testimator lgbm's best error=0.1432,\tbest estimator lgbm's best error=0.1432\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 0.7s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 0.7s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 0.8s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 0.9s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 0.9s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 1.0s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 1.1s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 1.2s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 1.3s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 1.4s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2391} INFO -  at 1.4s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 19:55:38] {2218} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2391} INFO -  at 1.5s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2218} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2391} INFO -  at 1.6s,\testimator xgboost's best error=1.0000,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2218} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2391} INFO -  at 1.7s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2218} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2391} INFO -  at 1.8s,\testimator xgboost's best error=1.0000,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2218} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2391} INFO -  at 2.0s,\testimator xgboost's best error=0.1515,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2218} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2391} INFO -  at 2.1s,\testimator xgboost's best error=0.1473,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2218} INFO - iteration 20, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2391} INFO -  at 2.3s,\testimator extra_tree's best error=0.9733,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2218} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2391} INFO -  at 2.4s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:39] {2218} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2391} INFO -  at 2.5s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2218} INFO - iteration 23, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2391} INFO -  at 2.7s,\testimator extra_tree's best error=0.5369,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2218} INFO - iteration 24, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2391} INFO -  at 2.9s,\testimator extra_tree's best error=0.5369,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2218} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2391} INFO -  at 3.0s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2218} INFO - iteration 26, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2391} INFO -  at 3.3s,\testimator extra_tree's best error=0.5369,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:40] {2218} INFO - iteration 27, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2391} INFO -  at 3.5s,\testimator extra_tree's best error=0.2347,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2218} INFO - iteration 28, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2391} INFO -  at 3.7s,\testimator extra_tree's best error=0.2347,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2218} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2391} INFO -  at 3.8s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2218} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2391} INFO -  at 3.9s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2218} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2391} INFO -  at 4.0s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2218} INFO - iteration 32, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2391} INFO -  at 4.2s,\testimator extra_tree's best error=0.2347,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2218} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2391} INFO -  at 4.2s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2218} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2391} INFO -  at 4.3s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:41] {2218} INFO - iteration 35, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2391} INFO -  at 4.5s,\testimator rf's best error=0.1504,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2218} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2391} INFO -  at 4.8s,\testimator extra_tree's best error=0.2193,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2218} INFO - iteration 37, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2391} INFO -  at 5.0s,\testimator rf's best error=0.1504,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2218} INFO - iteration 38, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2391} INFO -  at 5.2s,\testimator rf's best error=0.1504,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2218} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2391} INFO -  at 5.3s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:42] {2218} INFO - iteration 40, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2391} INFO -  at 5.5s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2218} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2391} INFO -  at 5.7s,\testimator xgboost's best error=0.1473,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2218} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2391} INFO -  at 5.7s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2218} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2391} INFO -  at 6.0s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2218} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2391} INFO -  at 6.2s,\testimator extra_tree's best error=0.2193,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:43] {2218} INFO - iteration 45, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:44] {2391} INFO -  at 6.6s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:44] {2218} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:44] {2391} INFO -  at 6.7s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:44] {2218} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:44] {2391} INFO -  at 6.9s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:44] {2218} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:44] {2391} INFO -  at 7.2s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:44] {2218} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2391} INFO -  at 7.5s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2218} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2391} INFO -  at 7.7s,\testimator xgboost's best error=0.1362,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2218} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2391} INFO -  at 7.9s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2218} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2391} INFO -  at 8.2s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2218} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2391} INFO -  at 8.4s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:45] {2218} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:46] {2391} INFO -  at 8.8s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:46] {2218} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:46] {2391} INFO -  at 9.2s,\testimator xgboost's best error=0.1362,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:46] {2218} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:46] {2391} INFO -  at 9.4s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:46] {2218} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:47] {2391} INFO -  at 10.0s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:47] {2218} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:47] {2391} INFO -  at 10.1s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:47] {2218} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:47] {2391} INFO -  at 10.3s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:47] {2218} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:48] {2391} INFO -  at 10.6s,\testimator xgboost's best error=0.1329,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:48] {2218} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:48] {2391} INFO -  at 10.8s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:48] {2218} INFO - iteration 62, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:55:48] {2391} INFO -  at 11.0s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:48] {2218} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:49] {2391} INFO -  at 12.2s,\testimator xgboost's best error=0.1329,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:49] {2218} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:51] {2391} INFO -  at 13.6s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:51] {2218} INFO - iteration 65, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:51] {2391} INFO -  at 14.1s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:51] {2218} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2391} INFO -  at 14.5s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2218} INFO - iteration 67, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2391} INFO -  at 14.7s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2218} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2391} INFO -  at 14.9s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2218} INFO - iteration 69, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2391} INFO -  at 15.0s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2218} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2391} INFO -  at 15.2s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:52] {2218} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:53] {2391} INFO -  at 15.7s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:53] {2218} INFO - iteration 72, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:53] {2391} INFO -  at 16.4s,\testimator extra_tree's best error=0.2193,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:53] {2218} INFO - iteration 73, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:55:54] {2391} INFO -  at 17.1s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:54] {2218} INFO - iteration 74, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:54] {2391} INFO -  at 17.4s,\testimator extra_tree's best error=0.1656,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:54] {2218} INFO - iteration 75, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2391} INFO -  at 17.5s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2218} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2391} INFO -  at 18.0s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2218} INFO - iteration 77, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2391} INFO -  at 18.2s,\testimator extra_tree's best error=0.1656,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2218} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2391} INFO -  at 18.3s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2218} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2391} INFO -  at 18.4s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:55] {2218} INFO - iteration 80, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:56] {2391} INFO -  at 18.8s,\testimator extra_tree's best error=0.1237,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:56] {2218} INFO - iteration 81, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:56] {2391} INFO -  at 19.2s,\testimator extra_tree's best error=0.1237,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:56] {2218} INFO - iteration 82, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:57] {2391} INFO -  at 19.7s,\testimator extra_tree's best error=0.1136,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:57] {2218} INFO - iteration 83, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:57] {2391} INFO -  at 20.2s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:57] {2218} INFO - iteration 84, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:58] {2391} INFO -  at 20.7s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:58] {2218} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:58] {2391} INFO -  at 21.1s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:58] {2218} INFO - iteration 86, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:59] {2391} INFO -  at 21.8s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:59] {2218} INFO - iteration 87, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:55:59] {2391} INFO -  at 22.3s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:59] {2218} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:55:59] {2391} INFO -  at 22.4s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:55:59] {2218} INFO - iteration 89, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:00] {2391} INFO -  at 22.9s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:56:00] {2218} INFO - iteration 90, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:01] {2391} INFO -  at 23.5s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:56:01] {2218} INFO - iteration 91, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:01] {2391} INFO -  at 23.9s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:56:01] {2218} INFO - iteration 92, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:02] {2391} INFO -  at 24.8s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:56:02] {2218} INFO - iteration 93, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:02] {2391} INFO -  at 25.4s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:56:02] {2218} INFO - iteration 94, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:04] {2391} INFO -  at 26.8s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:56:04] {2218} INFO - iteration 95, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:05] {2391} INFO -  at 27.6s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:56:05] {2218} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:05] {2391} INFO -  at 27.8s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 19:56:05] {2218} INFO - iteration 97, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:06] {2391} INFO -  at 28.5s,\testimator extra_tree's best error=0.0965,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 19:56:06] {2218} INFO - iteration 98, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:56:06] {2391} INFO -  at 29.1s,\testimator rf's best error=0.1478,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 19:56:06] {2218} INFO - iteration 99, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:08] {2391} INFO -  at 31.1s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl.logger: 12-17 19:56:08] {2218} INFO - iteration 100, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:09] {2391} INFO -  at 32.3s,\testimator extra_tree's best error=0.0965,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl.logger: 12-17 19:56:09] {2218} INFO - iteration 101, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:10] {2391} INFO -  at 33.4s,\testimator extra_tree's best error=0.0965,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl.logger: 12-17 19:56:10] {2218} INFO - iteration 102, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:12] {2391} INFO -  at 34.6s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl.logger: 12-17 19:56:12] {2218} INFO - iteration 103, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:13] {2391} INFO -  at 35.6s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 19:56:13] {2218} INFO - iteration 104, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:14] {2391} INFO -  at 36.5s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 19:56:14] {2218} INFO - iteration 105, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:15] {2391} INFO -  at 37.8s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 19:56:15] {2218} INFO - iteration 106, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:15] {2391} INFO -  at 38.3s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 19:56:15] {2218} INFO - iteration 107, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:16] {2391} INFO -  at 38.9s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 19:56:16] {2218} INFO - iteration 108, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:17] {2391} INFO -  at 39.6s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 19:56:17] {2218} INFO - iteration 109, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:18] {2391} INFO -  at 40.7s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:18] {2218} INFO - iteration 110, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:19] {2391} INFO -  at 41.5s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:19] {2218} INFO - iteration 111, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:19] {2391} INFO -  at 41.9s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:19] {2218} INFO - iteration 112, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:19] {2391} INFO -  at 42.4s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:19] {2218} INFO - iteration 113, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:20] {2391} INFO -  at 43.2s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:20] {2218} INFO - iteration 114, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:56:21] {2391} INFO -  at 43.7s,\testimator rf's best error=0.1478,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:21] {2218} INFO - iteration 115, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:21] {2391} INFO -  at 43.8s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:21] {2218} INFO - iteration 116, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:22] {2391} INFO -  at 44.6s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:22] {2218} INFO - iteration 117, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:22] {2391} INFO -  at 45.0s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:22] {2218} INFO - iteration 118, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:22] {2391} INFO -  at 45.1s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:22] {2218} INFO - iteration 119, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:23] {2391} INFO -  at 45.6s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:23] {2218} INFO - iteration 120, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:23] {2391} INFO -  at 46.1s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 19:56:23] {2218} INFO - iteration 121, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:24] {2391} INFO -  at 46.7s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:24] {2218} INFO - iteration 122, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:24] {2391} INFO -  at 47.1s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:24] {2218} INFO - iteration 123, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:56:24] {2391} INFO -  at 47.3s,\testimator rf's best error=0.1478,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:24] {2218} INFO - iteration 124, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:24] {2391} INFO -  at 47.4s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:24] {2218} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:25] {2391} INFO -  at 47.5s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:25] {2218} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:25] {2391} INFO -  at 47.7s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:25] {2218} INFO - iteration 127, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:25] {2391} INFO -  at 48.4s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:25] {2218} INFO - iteration 128, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:26] {2391} INFO -  at 48.9s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:26] {2218} INFO - iteration 129, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:26] {2391} INFO -  at 49.4s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:26] {2218} INFO - iteration 130, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:27] {2391} INFO -  at 50.1s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:27] {2218} INFO - iteration 131, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:28] {2391} INFO -  at 50.7s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:28] {2218} INFO - iteration 132, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:56:28] {2391} INFO -  at 51.0s,\testimator rf's best error=0.1478,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:28] {2218} INFO - iteration 133, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:29] {2391} INFO -  at 51.8s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:29] {2218} INFO - iteration 134, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:30] {2391} INFO -  at 53.1s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:30] {2218} INFO - iteration 135, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:31] {2391} INFO -  at 53.6s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 19:56:31] {2218} INFO - iteration 136, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:32] {2391} INFO -  at 54.7s,\testimator extra_tree's best error=0.0835,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 19:56:32] {2218} INFO - iteration 137, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:32] {2391} INFO -  at 54.8s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 19:56:32] {2218} INFO - iteration 138, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:32] {2391} INFO -  at 55.4s,\testimator extra_tree's best error=0.0835,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 19:56:32] {2218} INFO - iteration 139, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:33] {2391} INFO -  at 55.6s,\testimator xgboost's best error=0.1288,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 19:56:33] {2218} INFO - iteration 140, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:33] {2391} INFO -  at 56.1s,\testimator extra_tree's best error=0.0835,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 19:56:33] {2218} INFO - iteration 141, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:35] {2391} INFO -  at 57.5s,\testimator extra_tree's best error=0.0835,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 19:56:35] {2218} INFO - iteration 142, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:35] {2391} INFO -  at 58.2s,\testimator extra_tree's best error=0.0835,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 19:56:35] {2218} INFO - iteration 143, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:36] {2391} INFO -  at 59.3s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:36] {2218} INFO - iteration 144, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:37] {2391} INFO -  at 60.0s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:37] {2218} INFO - iteration 145, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:37] {2391} INFO -  at 60.1s,\testimator xgboost's best error=0.1288,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:37] {2218} INFO - iteration 146, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:56:37] {2391} INFO -  at 60.4s,\testimator rf's best error=0.1472,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:37] {2218} INFO - iteration 147, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:38] {2391} INFO -  at 60.5s,\testimator xgboost's best error=0.1251,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:38] {2218} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:38] {2391} INFO -  at 60.7s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:38] {2218} INFO - iteration 149, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:38] {2391} INFO -  at 60.8s,\testimator xgboost's best error=0.1251,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:38] {2218} INFO - iteration 150, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:39] {2391} INFO -  at 62.2s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:39] {2218} INFO - iteration 151, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:40] {2391} INFO -  at 63.0s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:40] {2218} INFO - iteration 152, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:42] {2391} INFO -  at 64.5s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:42] {2218} INFO - iteration 153, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:42] {2391} INFO -  at 64.7s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:42] {2218} INFO - iteration 154, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:42] {2391} INFO -  at 65.1s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:42] {2218} INFO - iteration 155, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:43] {2391} INFO -  at 66.2s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:43] {2218} INFO - iteration 156, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:43] {2391} INFO -  at 66.5s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:43] {2218} INFO - iteration 157, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:44] {2391} INFO -  at 67.0s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:44] {2218} INFO - iteration 158, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:44] {2391} INFO -  at 67.4s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:44] {2218} INFO - iteration 159, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:46] {2391} INFO -  at 69.0s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:46] {2218} INFO - iteration 160, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:46] {2391} INFO -  at 69.2s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:46] {2218} INFO - iteration 161, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:46] {2391} INFO -  at 69.3s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:46] {2218} INFO - iteration 162, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:47] {2391} INFO -  at 70.1s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:47] {2218} INFO - iteration 163, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:48] {2391} INFO -  at 71.4s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:48] {2218} INFO - iteration 164, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:49] {2391} INFO -  at 71.6s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:49] {2218} INFO - iteration 165, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:49] {2391} INFO -  at 71.7s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:49] {2218} INFO - iteration 166, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:49] {2391} INFO -  at 71.8s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:49] {2218} INFO - iteration 167, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:49] {2391} INFO -  at 72.5s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:49] {2218} INFO - iteration 168, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2391} INFO -  at 72.6s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2218} INFO - iteration 169, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2391} INFO -  at 72.7s,\testimator lgbm's best error=0.0927,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2218} INFO - iteration 170, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2391} INFO -  at 72.8s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2218} INFO - iteration 171, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2391} INFO -  at 72.9s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2218} INFO - iteration 172, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2391} INFO -  at 73.1s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2218} INFO - iteration 173, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2391} INFO -  at 73.2s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2218} INFO - iteration 174, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2391} INFO -  at 73.4s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:50] {2218} INFO - iteration 175, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:52] {2391} INFO -  at 75.2s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:52] {2218} INFO - iteration 176, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:52] {2391} INFO -  at 75.3s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:52] {2218} INFO - iteration 177, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:53] {2391} INFO -  at 75.5s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:53] {2218} INFO - iteration 178, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:55] {2391} INFO -  at 77.7s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:55] {2218} INFO - iteration 179, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:55] {2391} INFO -  at 78.3s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:55] {2218} INFO - iteration 180, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:56:56] {2391} INFO -  at 79.1s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:56] {2218} INFO - iteration 181, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:57] {2391} INFO -  at 80.0s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:57] {2218} INFO - iteration 182, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:56:58] {2391} INFO -  at 80.7s,\testimator lgbm's best error=0.0913,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:58] {2218} INFO - iteration 183, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:56:58] {2391} INFO -  at 81.1s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:56:58] {2218} INFO - iteration 184, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:00] {2391} INFO -  at 82.9s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:00] {2218} INFO - iteration 185, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:00] {2391} INFO -  at 83.0s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:00] {2218} INFO - iteration 186, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2391} INFO -  at 84.5s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2218} INFO - iteration 187, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2391} INFO -  at 84.7s,\testimator xgb_limitdepth's best error=0.1415,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2218} INFO - iteration 188, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2391} INFO -  at 84.8s,\testimator xgb_limitdepth's best error=0.1415,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2218} INFO - iteration 189, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2391} INFO -  at 84.9s,\testimator xgb_limitdepth's best error=0.1402,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2218} INFO - iteration 190, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2391} INFO -  at 85.0s,\testimator xgb_limitdepth's best error=0.1402,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2218} INFO - iteration 191, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2391} INFO -  at 85.2s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:02] {2218} INFO - iteration 192, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:03] {2391} INFO -  at 85.9s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:03] {2218} INFO - iteration 193, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:04] {2391} INFO -  at 87.3s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:04] {2218} INFO - iteration 194, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:04] {2391} INFO -  at 87.4s,\testimator xgb_limitdepth's best error=0.1402,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:04] {2218} INFO - iteration 195, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:05] {2391} INFO -  at 87.6s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:05] {2218} INFO - iteration 196, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:05] {2391} INFO -  at 87.7s,\testimator lgbm's best error=0.0913,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:05] {2218} INFO - iteration 197, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:06] {2391} INFO -  at 88.6s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:06] {2218} INFO - iteration 198, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:07] {2391} INFO -  at 90.0s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:07] {2218} INFO - iteration 199, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:07] {2391} INFO -  at 90.1s,\testimator xgb_limitdepth's best error=0.1337,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:07] {2218} INFO - iteration 200, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:07] {2391} INFO -  at 90.3s,\testimator xgb_limitdepth's best error=0.1337,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:07] {2218} INFO - iteration 201, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:07] {2391} INFO -  at 90.4s,\testimator lgbm's best error=0.0913,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:07] {2218} INFO - iteration 202, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:08] {2391} INFO -  at 91.2s,\testimator extra_tree's best error=0.0774,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:08] {2218} INFO - iteration 203, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:08] {2391} INFO -  at 91.4s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:08] {2218} INFO - iteration 204, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:09] {2391} INFO -  at 91.8s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:09] {2218} INFO - iteration 205, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:10] {2391} INFO -  at 92.7s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:10] {2218} INFO - iteration 206, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:11] {2391} INFO -  at 93.6s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:11] {2218} INFO - iteration 207, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:11] {2391} INFO -  at 93.8s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:11] {2218} INFO - iteration 208, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:11] {2391} INFO -  at 94.1s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:11] {2218} INFO - iteration 209, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2391} INFO -  at 94.5s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2218} INFO - iteration 210, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2391} INFO -  at 94.7s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2218} INFO - iteration 211, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2391} INFO -  at 94.8s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0774\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2218} INFO - iteration 212, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2391} INFO -  at 95.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2218} INFO - iteration 213, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2391} INFO -  at 95.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2218} INFO - iteration 214, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2391} INFO -  at 95.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2218} INFO - iteration 215, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2391} INFO -  at 95.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:12] {2218} INFO - iteration 216, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2391} INFO -  at 95.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2218} INFO - iteration 217, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2391} INFO -  at 95.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2218} INFO - iteration 218, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2391} INFO -  at 95.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2218} INFO - iteration 219, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2391} INFO -  at 96.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2218} INFO - iteration 220, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2391} INFO -  at 96.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2218} INFO - iteration 221, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2391} INFO -  at 96.3s,\testimator rf's best error=0.1472,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2218} INFO - iteration 222, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2391} INFO -  at 96.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:13] {2218} INFO - iteration 223, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2391} INFO -  at 96.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2218} INFO - iteration 224, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2391} INFO -  at 96.8s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2218} INFO - iteration 225, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2391} INFO -  at 96.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2218} INFO - iteration 226, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2391} INFO -  at 97.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2218} INFO - iteration 227, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2391} INFO -  at 97.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2218} INFO - iteration 228, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2391} INFO -  at 97.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:14] {2218} INFO - iteration 229, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2391} INFO -  at 97.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2218} INFO - iteration 230, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2391} INFO -  at 97.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2218} INFO - iteration 231, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2391} INFO -  at 97.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2218} INFO - iteration 232, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2391} INFO -  at 98.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2218} INFO - iteration 233, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2391} INFO -  at 98.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2218} INFO - iteration 234, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2391} INFO -  at 98.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2218} INFO - iteration 235, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2391} INFO -  at 98.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:15] {2218} INFO - iteration 236, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2391} INFO -  at 98.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2218} INFO - iteration 237, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2391} INFO -  at 98.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2218} INFO - iteration 238, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2391} INFO -  at 98.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2218} INFO - iteration 239, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2391} INFO -  at 99.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2218} INFO - iteration 240, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2391} INFO -  at 99.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2218} INFO - iteration 241, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2391} INFO -  at 99.3s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:16] {2218} INFO - iteration 242, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2391} INFO -  at 99.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2218} INFO - iteration 243, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2391} INFO -  at 99.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2218} INFO - iteration 244, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2391} INFO -  at 99.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2218} INFO - iteration 245, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2391} INFO -  at 99.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2218} INFO - iteration 246, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2391} INFO -  at 100.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2218} INFO - iteration 247, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2391} INFO -  at 100.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2218} INFO - iteration 248, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2391} INFO -  at 100.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:17] {2218} INFO - iteration 249, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2391} INFO -  at 100.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2218} INFO - iteration 250, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2391} INFO -  at 100.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2218} INFO - iteration 251, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2391} INFO -  at 100.8s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2218} INFO - iteration 252, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2391} INFO -  at 100.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2218} INFO - iteration 253, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2391} INFO -  at 101.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2218} INFO - iteration 254, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2391} INFO -  at 101.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2218} INFO - iteration 255, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2391} INFO -  at 101.3s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:18] {2218} INFO - iteration 256, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2391} INFO -  at 101.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2218} INFO - iteration 257, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2391} INFO -  at 101.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2218} INFO - iteration 258, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2391} INFO -  at 101.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2218} INFO - iteration 259, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2391} INFO -  at 101.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2218} INFO - iteration 260, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2391} INFO -  at 102.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2218} INFO - iteration 261, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2391} INFO -  at 102.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2218} INFO - iteration 262, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2391} INFO -  at 102.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:19] {2218} INFO - iteration 263, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2391} INFO -  at 102.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2218} INFO - iteration 264, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2391} INFO -  at 102.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2218} INFO - iteration 265, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2391} INFO -  at 102.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2218} INFO - iteration 266, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2391} INFO -  at 102.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2218} INFO - iteration 267, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2391} INFO -  at 103.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2218} INFO - iteration 268, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2391} INFO -  at 103.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2218} INFO - iteration 269, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2391} INFO -  at 103.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:20] {2218} INFO - iteration 270, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2391} INFO -  at 103.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2218} INFO - iteration 271, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2391} INFO -  at 103.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2218} INFO - iteration 272, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2391} INFO -  at 103.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2218} INFO - iteration 273, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2391} INFO -  at 104.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2218} INFO - iteration 274, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2391} INFO -  at 104.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2218} INFO - iteration 275, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2391} INFO -  at 104.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2218} INFO - iteration 276, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2391} INFO -  at 104.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:21] {2218} INFO - iteration 277, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:22] {2391} INFO -  at 104.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:22] {2218} INFO - iteration 278, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:22] {2391} INFO -  at 105.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:22] {2218} INFO - iteration 279, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:23] {2391} INFO -  at 105.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:23] {2218} INFO - iteration 280, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:23] {2391} INFO -  at 106.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:23] {2218} INFO - iteration 281, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:25] {2391} INFO -  at 108.2s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:25] {2218} INFO - iteration 282, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:25] {2391} INFO -  at 108.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:25] {2218} INFO - iteration 283, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2391} INFO -  at 108.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2218} INFO - iteration 284, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2391} INFO -  at 108.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2218} INFO - iteration 285, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2391} INFO -  at 108.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2218} INFO - iteration 286, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2391} INFO -  at 108.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2218} INFO - iteration 287, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2391} INFO -  at 109.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2218} INFO - iteration 288, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2391} INFO -  at 109.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2218} INFO - iteration 289, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2391} INFO -  at 109.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:26] {2218} INFO - iteration 290, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2391} INFO -  at 109.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2218} INFO - iteration 291, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2391} INFO -  at 109.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2218} INFO - iteration 292, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2391} INFO -  at 109.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2218} INFO - iteration 293, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2391} INFO -  at 110.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2218} INFO - iteration 294, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2391} INFO -  at 110.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2218} INFO - iteration 295, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2391} INFO -  at 110.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:27] {2218} INFO - iteration 296, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2391} INFO -  at 110.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2218} INFO - iteration 297, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2391} INFO -  at 110.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2218} INFO - iteration 298, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2391} INFO -  at 110.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2218} INFO - iteration 299, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2391} INFO -  at 110.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2218} INFO - iteration 300, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2391} INFO -  at 111.1s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2218} INFO - iteration 301, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2391} INFO -  at 111.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2218} INFO - iteration 302, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2391} INFO -  at 111.4s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:28] {2218} INFO - iteration 303, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:29] {2391} INFO -  at 111.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:29] {2218} INFO - iteration 304, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:29] {2391} INFO -  at 112.4s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:29] {2218} INFO - iteration 305, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2391} INFO -  at 112.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2218} INFO - iteration 306, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2391} INFO -  at 112.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2218} INFO - iteration 307, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2391} INFO -  at 112.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2218} INFO - iteration 308, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2391} INFO -  at 112.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2218} INFO - iteration 309, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2391} INFO -  at 113.1s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2218} INFO - iteration 310, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2391} INFO -  at 113.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2218} INFO - iteration 311, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2391} INFO -  at 113.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:30] {2218} INFO - iteration 312, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:31] {2391} INFO -  at 114.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:31] {2218} INFO - iteration 313, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:31] {2391} INFO -  at 114.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:31] {2218} INFO - iteration 314, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:31] {2391} INFO -  at 114.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:31] {2218} INFO - iteration 315, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:32] {2391} INFO -  at 114.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:32] {2218} INFO - iteration 316, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:32] {2391} INFO -  at 114.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:32] {2218} INFO - iteration 317, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:34] {2391} INFO -  at 116.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:34] {2218} INFO - iteration 318, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:34] {2391} INFO -  at 116.6s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:34] {2218} INFO - iteration 319, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:34] {2391} INFO -  at 117.2s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:34] {2218} INFO - iteration 320, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:34] {2391} INFO -  at 117.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:34] {2218} INFO - iteration 321, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:35] {2391} INFO -  at 117.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:35] {2218} INFO - iteration 322, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:38] {2391} INFO -  at 120.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:38] {2218} INFO - iteration 323, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:40] {2391} INFO -  at 123.2s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:40] {2218} INFO - iteration 324, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:41] {2391} INFO -  at 123.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:41] {2218} INFO - iteration 325, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:42] {2391} INFO -  at 124.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:42] {2218} INFO - iteration 326, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:42] {2391} INFO -  at 125.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:42] {2218} INFO - iteration 327, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2391} INFO -  at 126.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2218} INFO - iteration 328, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2391} INFO -  at 126.7s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2218} INFO - iteration 329, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2391} INFO -  at 126.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2218} INFO - iteration 330, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2391} INFO -  at 127.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2218} INFO - iteration 331, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2391} INFO -  at 127.1s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2218} INFO - iteration 332, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2391} INFO -  at 127.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2218} INFO - iteration 333, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2391} INFO -  at 127.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:44] {2218} INFO - iteration 334, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:45] {2391} INFO -  at 127.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:45] {2218} INFO - iteration 335, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:45] {2391} INFO -  at 127.6s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:45] {2218} INFO - iteration 336, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:45] {2391} INFO -  at 127.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:45] {2218} INFO - iteration 337, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:46] {2391} INFO -  at 128.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:46] {2218} INFO - iteration 338, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:46] {2391} INFO -  at 129.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:46] {2218} INFO - iteration 339, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:46] {2391} INFO -  at 129.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:46] {2218} INFO - iteration 340, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:46] {2391} INFO -  at 129.4s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:46] {2218} INFO - iteration 341, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2391} INFO -  at 129.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2218} INFO - iteration 342, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2391} INFO -  at 129.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2218} INFO - iteration 343, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2391} INFO -  at 129.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2218} INFO - iteration 344, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2391} INFO -  at 130.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2218} INFO - iteration 345, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2391} INFO -  at 130.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2218} INFO - iteration 346, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2391} INFO -  at 130.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2218} INFO - iteration 347, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2391} INFO -  at 130.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:47] {2218} INFO - iteration 348, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2391} INFO -  at 130.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2218} INFO - iteration 349, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2391} INFO -  at 130.8s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2218} INFO - iteration 350, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2391} INFO -  at 130.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2218} INFO - iteration 351, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2391} INFO -  at 131.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2218} INFO - iteration 352, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2391} INFO -  at 131.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2218} INFO - iteration 353, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2391} INFO -  at 131.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2218} INFO - iteration 354, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:48] {2391} INFO -  at 131.5s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:49] {2218} INFO - iteration 355, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:49] {2391} INFO -  at 131.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:49] {2218} INFO - iteration 356, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:49] {2391} INFO -  at 131.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:49] {2218} INFO - iteration 357, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:50] {2391} INFO -  at 132.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:50] {2218} INFO - iteration 358, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:50] {2391} INFO -  at 133.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:50] {2218} INFO - iteration 359, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2391} INFO -  at 133.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2218} INFO - iteration 360, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2391} INFO -  at 133.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2218} INFO - iteration 361, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2391} INFO -  at 133.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2218} INFO - iteration 362, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2391} INFO -  at 134.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2218} INFO - iteration 363, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2391} INFO -  at 134.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2218} INFO - iteration 364, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2391} INFO -  at 134.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:51] {2218} INFO - iteration 365, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:57:53] {2391} INFO -  at 136.2s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:53] {2218} INFO - iteration 366, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:53] {2391} INFO -  at 136.4s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:53] {2218} INFO - iteration 367, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:54] {2391} INFO -  at 136.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:54] {2218} INFO - iteration 368, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:54] {2391} INFO -  at 137.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:54] {2218} INFO - iteration 369, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:55] {2391} INFO -  at 138.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:55] {2218} INFO - iteration 370, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:56] {2391} INFO -  at 138.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:56] {2218} INFO - iteration 371, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:56] {2391} INFO -  at 139.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:56] {2218} INFO - iteration 372, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2391} INFO -  at 139.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2218} INFO - iteration 373, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2391} INFO -  at 139.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2218} INFO - iteration 374, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2391} INFO -  at 139.8s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2218} INFO - iteration 375, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2391} INFO -  at 140.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2218} INFO - iteration 376, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2391} INFO -  at 140.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2218} INFO - iteration 377, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2391} INFO -  at 140.3s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2218} INFO - iteration 378, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2391} INFO -  at 140.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:57] {2218} INFO - iteration 379, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2391} INFO -  at 140.5s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2218} INFO - iteration 380, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2391} INFO -  at 140.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2218} INFO - iteration 381, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2391} INFO -  at 140.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2218} INFO - iteration 382, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2391} INFO -  at 141.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2218} INFO - iteration 383, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2391} INFO -  at 141.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2218} INFO - iteration 384, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2391} INFO -  at 141.3s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2218} INFO - iteration 385, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2391} INFO -  at 141.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:58] {2218} INFO - iteration 386, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:59] {2391} INFO -  at 141.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:59] {2218} INFO - iteration 387, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:57:59] {2391} INFO -  at 141.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:59] {2218} INFO - iteration 388, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:59] {2391} INFO -  at 141.8s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:59] {2218} INFO - iteration 389, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:57:59] {2391} INFO -  at 142.0s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:57:59] {2218} INFO - iteration 390, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2391} INFO -  at 142.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2218} INFO - iteration 391, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2391} INFO -  at 143.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2218} INFO - iteration 392, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2391} INFO -  at 143.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2218} INFO - iteration 393, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2391} INFO -  at 143.2s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2218} INFO - iteration 394, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2391} INFO -  at 143.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:00] {2218} INFO - iteration 395, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:01] {2391} INFO -  at 143.5s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:01] {2218} INFO - iteration 396, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:01] {2391} INFO -  at 143.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:01] {2218} INFO - iteration 397, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:02] {2391} INFO -  at 145.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:02] {2218} INFO - iteration 398, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:02] {2391} INFO -  at 145.2s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:02] {2218} INFO - iteration 399, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:02] {2391} INFO -  at 145.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:02] {2218} INFO - iteration 400, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2391} INFO -  at 145.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2218} INFO - iteration 401, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2391} INFO -  at 145.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2218} INFO - iteration 402, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2391} INFO -  at 145.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2218} INFO - iteration 403, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2391} INFO -  at 146.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2218} INFO - iteration 404, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2391} INFO -  at 146.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2218} INFO - iteration 405, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2391} INFO -  at 146.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2218} INFO - iteration 406, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2391} INFO -  at 146.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:03] {2218} INFO - iteration 407, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2391} INFO -  at 146.6s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2218} INFO - iteration 408, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2391} INFO -  at 146.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2218} INFO - iteration 409, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2391} INFO -  at 146.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2218} INFO - iteration 410, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2391} INFO -  at 147.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2218} INFO - iteration 411, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2391} INFO -  at 147.2s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:04] {2218} INFO - iteration 412, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2391} INFO -  at 147.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2218} INFO - iteration 413, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2391} INFO -  at 147.9s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2218} INFO - iteration 414, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2391} INFO -  at 148.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2218} INFO - iteration 415, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2391} INFO -  at 148.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2218} INFO - iteration 416, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2391} INFO -  at 148.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:05] {2218} INFO - iteration 417, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2391} INFO -  at 148.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2218} INFO - iteration 418, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2391} INFO -  at 148.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2218} INFO - iteration 419, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2391} INFO -  at 148.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2218} INFO - iteration 420, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2391} INFO -  at 149.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2218} INFO - iteration 421, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2391} INFO -  at 149.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2218} INFO - iteration 422, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2391} INFO -  at 149.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2218} INFO - iteration 423, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2391} INFO -  at 149.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:06] {2218} INFO - iteration 424, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:07] {2391} INFO -  at 149.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:07] {2218} INFO - iteration 425, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:07] {2391} INFO -  at 149.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:07] {2218} INFO - iteration 426, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:08] {2391} INFO -  at 150.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:08] {2218} INFO - iteration 427, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:08] {2391} INFO -  at 151.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:08] {2218} INFO - iteration 428, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:09] {2391} INFO -  at 152.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:09] {2218} INFO - iteration 429, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:09] {2391} INFO -  at 152.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:09] {2218} INFO - iteration 430, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:10] {2391} INFO -  at 152.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:10] {2218} INFO - iteration 431, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:10] {2391} INFO -  at 153.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:10] {2218} INFO - iteration 432, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:10] {2391} INFO -  at 153.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:10] {2218} INFO - iteration 433, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:10] {2391} INFO -  at 153.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:10] {2218} INFO - iteration 434, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2391} INFO -  at 153.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2218} INFO - iteration 435, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2391} INFO -  at 153.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2218} INFO - iteration 436, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2391} INFO -  at 153.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2218} INFO - iteration 437, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2391} INFO -  at 154.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2218} INFO - iteration 438, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2391} INFO -  at 154.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2218} INFO - iteration 439, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2391} INFO -  at 154.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:11] {2218} INFO - iteration 440, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2391} INFO -  at 154.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2218} INFO - iteration 441, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2391} INFO -  at 154.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2218} INFO - iteration 442, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2391} INFO -  at 154.8s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2218} INFO - iteration 443, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2391} INFO -  at 154.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2218} INFO - iteration 444, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2391} INFO -  at 155.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2218} INFO - iteration 445, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2391} INFO -  at 155.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2218} INFO - iteration 446, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2391} INFO -  at 155.3s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:12] {2218} INFO - iteration 447, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:14] {2391} INFO -  at 157.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:14] {2218} INFO - iteration 448, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:14] {2391} INFO -  at 157.3s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:14] {2218} INFO - iteration 449, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2391} INFO -  at 157.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2218} INFO - iteration 450, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2391} INFO -  at 157.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2218} INFO - iteration 451, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2391} INFO -  at 157.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2218} INFO - iteration 452, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2391} INFO -  at 158.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2218} INFO - iteration 453, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2391} INFO -  at 158.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2218} INFO - iteration 454, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2391} INFO -  at 158.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:15] {2218} INFO - iteration 455, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2391} INFO -  at 158.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2218} INFO - iteration 456, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2391} INFO -  at 158.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2218} INFO - iteration 457, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2391} INFO -  at 158.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2218} INFO - iteration 458, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2391} INFO -  at 158.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2218} INFO - iteration 459, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2391} INFO -  at 159.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2218} INFO - iteration 460, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2391} INFO -  at 159.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2218} INFO - iteration 461, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2391} INFO -  at 159.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:16] {2218} INFO - iteration 462, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2391} INFO -  at 159.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2218} INFO - iteration 463, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2391} INFO -  at 159.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2218} INFO - iteration 464, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2391} INFO -  at 159.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2218} INFO - iteration 465, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2391} INFO -  at 160.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2218} INFO - iteration 466, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2391} INFO -  at 160.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2218} INFO - iteration 467, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2391} INFO -  at 160.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2218} INFO - iteration 468, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2391} INFO -  at 160.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:17] {2218} INFO - iteration 469, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:18] {2391} INFO -  at 160.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:18] {2218} INFO - iteration 470, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:18] {2391} INFO -  at 160.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:18] {2218} INFO - iteration 471, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:18] {2391} INFO -  at 160.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:18] {2218} INFO - iteration 472, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:18] {2391} INFO -  at 161.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:18] {2218} INFO - iteration 473, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:19] {2391} INFO -  at 161.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:19] {2218} INFO - iteration 474, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:19] {2391} INFO -  at 162.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:19] {2218} INFO - iteration 475, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:19] {2391} INFO -  at 162.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:19] {2218} INFO - iteration 476, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:19] {2391} INFO -  at 162.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:19] {2218} INFO - iteration 477, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:20] {2391} INFO -  at 162.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:20] {2218} INFO - iteration 478, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:21] {2391} INFO -  at 164.3s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:21] {2218} INFO - iteration 479, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:22] {2391} INFO -  at 164.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:22] {2218} INFO - iteration 480, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:22] {2391} INFO -  at 165.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:22] {2218} INFO - iteration 481, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:23] {2391} INFO -  at 165.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:23] {2218} INFO - iteration 482, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:23] {2391} INFO -  at 165.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:23] {2218} INFO - iteration 483, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:23] {2391} INFO -  at 166.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:23] {2218} INFO - iteration 484, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2391} INFO -  at 166.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2218} INFO - iteration 485, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2391} INFO -  at 167.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2218} INFO - iteration 486, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2391} INFO -  at 167.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2218} INFO - iteration 487, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2391} INFO -  at 167.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2218} INFO - iteration 488, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2391} INFO -  at 167.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:24] {2218} INFO - iteration 489, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2391} INFO -  at 167.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2218} INFO - iteration 490, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2391} INFO -  at 167.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2218} INFO - iteration 491, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2391} INFO -  at 167.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2218} INFO - iteration 492, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2391} INFO -  at 168.0s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2218} INFO - iteration 493, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2391} INFO -  at 168.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2218} INFO - iteration 494, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2391} INFO -  at 168.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:25] {2218} INFO - iteration 495, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:27] {2391} INFO -  at 170.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:27] {2218} INFO - iteration 496, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:27] {2391} INFO -  at 170.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:27] {2218} INFO - iteration 497, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:27] {2391} INFO -  at 170.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:27] {2218} INFO - iteration 498, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2391} INFO -  at 170.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2218} INFO - iteration 499, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2391} INFO -  at 170.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2218} INFO - iteration 500, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2391} INFO -  at 170.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2218} INFO - iteration 501, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2391} INFO -  at 171.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2218} INFO - iteration 502, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2391} INFO -  at 171.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2218} INFO - iteration 503, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2391} INFO -  at 171.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2218} INFO - iteration 504, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2391} INFO -  at 171.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:28] {2218} INFO - iteration 505, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2391} INFO -  at 171.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2218} INFO - iteration 506, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2391} INFO -  at 171.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2218} INFO - iteration 507, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2391} INFO -  at 171.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2218} INFO - iteration 508, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2391} INFO -  at 172.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2218} INFO - iteration 509, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2391} INFO -  at 172.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2218} INFO - iteration 510, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2391} INFO -  at 172.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:29] {2218} INFO - iteration 511, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2391} INFO -  at 172.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2218} INFO - iteration 512, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2391} INFO -  at 172.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2218} INFO - iteration 513, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2391} INFO -  at 172.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2218} INFO - iteration 514, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2391} INFO -  at 173.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2218} INFO - iteration 515, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2391} INFO -  at 173.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2218} INFO - iteration 516, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2391} INFO -  at 173.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2218} INFO - iteration 517, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2391} INFO -  at 173.4s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:30] {2218} INFO - iteration 518, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:31] {2391} INFO -  at 173.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:31] {2218} INFO - iteration 519, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:31] {2391} INFO -  at 173.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:31] {2218} INFO - iteration 520, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:32] {2391} INFO -  at 174.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:32] {2218} INFO - iteration 521, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:32] {2391} INFO -  at 175.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:32] {2218} INFO - iteration 522, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:32] {2391} INFO -  at 175.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:32] {2218} INFO - iteration 523, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:32] {2391} INFO -  at 175.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:32] {2218} INFO - iteration 524, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2391} INFO -  at 175.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2218} INFO - iteration 525, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2391} INFO -  at 175.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2218} INFO - iteration 526, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2391} INFO -  at 175.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2218} INFO - iteration 527, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2391} INFO -  at 176.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2218} INFO - iteration 528, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2391} INFO -  at 176.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2218} INFO - iteration 529, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2391} INFO -  at 176.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:33] {2218} INFO - iteration 530, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:34] {2391} INFO -  at 176.7s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:34] {2218} INFO - iteration 531, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:35] {2391} INFO -  at 177.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:35] {2218} INFO - iteration 532, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:35] {2391} INFO -  at 178.1s,\testimator rf's best error=0.1210,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:35] {2218} INFO - iteration 533, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:35] {2391} INFO -  at 178.4s,\testimator rf's best error=0.1210,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:35] {2218} INFO - iteration 534, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:36] {2391} INFO -  at 178.8s,\testimator rf's best error=0.1210,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:36] {2218} INFO - iteration 535, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:36] {2391} INFO -  at 179.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:36] {2218} INFO - iteration 536, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2391} INFO -  at 179.5s,\testimator rf's best error=0.1210,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2218} INFO - iteration 537, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2391} INFO -  at 179.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2218} INFO - iteration 538, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2391} INFO -  at 179.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2218} INFO - iteration 539, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2391} INFO -  at 180.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2218} INFO - iteration 540, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2391} INFO -  at 180.3s,\testimator rf's best error=0.1210,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:37] {2218} INFO - iteration 541, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:38] {2391} INFO -  at 180.6s,\testimator rf's best error=0.1210,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:38] {2218} INFO - iteration 542, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:38] {2391} INFO -  at 180.9s,\testimator rf's best error=0.1210,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:38] {2218} INFO - iteration 543, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:38] {2391} INFO -  at 181.0s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:38] {2218} INFO - iteration 544, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:38] {2391} INFO -  at 181.3s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:38] {2218} INFO - iteration 545, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:39] {2391} INFO -  at 181.6s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:39] {2218} INFO - iteration 546, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:39] {2391} INFO -  at 181.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:39] {2218} INFO - iteration 547, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:39] {2391} INFO -  at 182.0s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:39] {2218} INFO - iteration 548, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:39] {2391} INFO -  at 182.3s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:39] {2218} INFO - iteration 549, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2391} INFO -  at 182.6s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2218} INFO - iteration 550, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2391} INFO -  at 182.7s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2218} INFO - iteration 551, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2391} INFO -  at 182.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2218} INFO - iteration 552, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2391} INFO -  at 183.1s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2218} INFO - iteration 553, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2391} INFO -  at 183.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:40] {2218} INFO - iteration 554, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2391} INFO -  at 183.6s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2218} INFO - iteration 555, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2391} INFO -  at 183.8s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2218} INFO - iteration 556, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2391} INFO -  at 184.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2218} INFO - iteration 557, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2391} INFO -  at 184.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2218} INFO - iteration 558, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2391} INFO -  at 184.4s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:41] {2218} INFO - iteration 559, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:42] {2391} INFO -  at 184.7s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:42] {2218} INFO - iteration 560, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:42] {2391} INFO -  at 185.0s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:42] {2218} INFO - iteration 561, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:42] {2391} INFO -  at 185.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:42] {2218} INFO - iteration 562, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:43] {2391} INFO -  at 186.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:43] {2218} INFO - iteration 563, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:43] {2391} INFO -  at 186.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:43] {2218} INFO - iteration 564, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2391} INFO -  at 186.5s,\testimator rf's best error=0.1058,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2218} INFO - iteration 565, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2391} INFO -  at 186.7s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2218} INFO - iteration 566, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2391} INFO -  at 186.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2218} INFO - iteration 567, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2391} INFO -  at 187.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2218} INFO - iteration 568, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2391} INFO -  at 187.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:44] {2218} INFO - iteration 569, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:46] {2391} INFO -  at 188.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:46] {2218} INFO - iteration 570, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:47] {2391} INFO -  at 189.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:47] {2218} INFO - iteration 571, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:47] {2391} INFO -  at 190.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:47] {2218} INFO - iteration 572, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:48] {2391} INFO -  at 191.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:48] {2218} INFO - iteration 573, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:49] {2391} INFO -  at 191.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:49] {2218} INFO - iteration 574, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:49] {2391} INFO -  at 192.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:49] {2218} INFO - iteration 575, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:49] {2391} INFO -  at 192.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:49] {2218} INFO - iteration 576, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:50] {2391} INFO -  at 192.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:50] {2218} INFO - iteration 577, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:50] {2391} INFO -  at 192.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:50] {2218} INFO - iteration 578, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:50] {2391} INFO -  at 193.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:50] {2218} INFO - iteration 579, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:51] {2391} INFO -  at 194.4s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:51] {2218} INFO - iteration 580, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:52] {2391} INFO -  at 194.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:52] {2218} INFO - iteration 581, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:52] {2391} INFO -  at 194.9s,\testimator rf's best error=0.1023,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:52] {2218} INFO - iteration 582, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2391} INFO -  at 195.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2218} INFO - iteration 583, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2391} INFO -  at 195.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2218} INFO - iteration 584, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2391} INFO -  at 196.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2218} INFO - iteration 585, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2391} INFO -  at 196.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2218} INFO - iteration 586, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2391} INFO -  at 196.4s,\testimator rf's best error=0.1008,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:53] {2218} INFO - iteration 587, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:58:55] {2391} INFO -  at 198.4s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:55] {2218} INFO - iteration 588, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:56] {2391} INFO -  at 198.7s,\testimator rf's best error=0.1008,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:56] {2218} INFO - iteration 589, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:56] {2391} INFO -  at 198.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:56] {2218} INFO - iteration 590, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:56] {2391} INFO -  at 199.1s,\testimator rf's best error=0.1008,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:56] {2218} INFO - iteration 591, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:56] {2391} INFO -  at 199.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:56] {2218} INFO - iteration 592, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2391} INFO -  at 199.6s,\testimator rf's best error=0.1008,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2218} INFO - iteration 593, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2391} INFO -  at 199.8s,\testimator rf's best error=0.1008,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2218} INFO - iteration 594, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2391} INFO -  at 200.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2218} INFO - iteration 595, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2391} INFO -  at 200.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2218} INFO - iteration 596, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2391} INFO -  at 200.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:57] {2218} INFO - iteration 597, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:58:58] {2391} INFO -  at 200.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:58] {2218} INFO - iteration 598, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:58] {2391} INFO -  at 200.7s,\testimator rf's best error=0.1008,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:58] {2218} INFO - iteration 599, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:58] {2391} INFO -  at 201.0s,\testimator rf's best error=0.1008,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:58] {2218} INFO - iteration 600, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:58] {2391} INFO -  at 201.3s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:58] {2218} INFO - iteration 601, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:59] {2391} INFO -  at 201.6s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:59] {2218} INFO - iteration 602, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:58:59] {2391} INFO -  at 202.0s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:59] {2218} INFO - iteration 603, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:59] {2391} INFO -  at 202.2s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:59] {2218} INFO - iteration 604, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:58:59] {2391} INFO -  at 202.3s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:58:59] {2218} INFO - iteration 605, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:00] {2391} INFO -  at 202.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:00] {2218} INFO - iteration 606, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:59:00] {2391} INFO -  at 203.3s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:00] {2218} INFO - iteration 607, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:02] {2391} INFO -  at 205.0s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:02] {2218} INFO - iteration 608, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:02] {2391} INFO -  at 205.4s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:02] {2218} INFO - iteration 609, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:03] {2391} INFO -  at 205.9s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:03] {2218} INFO - iteration 610, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:03] {2391} INFO -  at 206.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:03] {2218} INFO - iteration 611, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:03] {2391} INFO -  at 206.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:03] {2218} INFO - iteration 612, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:04] {2391} INFO -  at 206.5s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:04] {2218} INFO - iteration 613, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:04] {2391} INFO -  at 206.9s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:04] {2218} INFO - iteration 614, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:04] {2391} INFO -  at 207.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:04] {2218} INFO - iteration 615, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:04] {2391} INFO -  at 207.4s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:04] {2218} INFO - iteration 616, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2391} INFO -  at 207.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2218} INFO - iteration 617, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2391} INFO -  at 207.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2218} INFO - iteration 618, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2391} INFO -  at 208.0s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2218} INFO - iteration 619, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2391} INFO -  at 208.2s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2218} INFO - iteration 620, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2391} INFO -  at 208.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:05] {2218} INFO - iteration 621, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:06] {2391} INFO -  at 208.5s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:06] {2218} INFO - iteration 622, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:06] {2391} INFO -  at 209.4s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:06] {2218} INFO - iteration 623, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:07] {2391} INFO -  at 210.3s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:07] {2218} INFO - iteration 624, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2391} INFO -  at 210.6s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2218} INFO - iteration 625, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2391} INFO -  at 210.8s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2218} INFO - iteration 626, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2391} INFO -  at 211.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2218} INFO - iteration 627, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2391} INFO -  at 211.2s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2218} INFO - iteration 628, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2391} INFO -  at 211.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2218} INFO - iteration 629, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:08] {2391} INFO -  at 211.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2218} INFO - iteration 630, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2391} INFO -  at 211.6s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2218} INFO - iteration 631, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2391} INFO -  at 211.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2218} INFO - iteration 632, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2391} INFO -  at 211.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2218} INFO - iteration 633, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2391} INFO -  at 212.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2218} INFO - iteration 634, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2391} INFO -  at 212.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:09] {2218} INFO - iteration 635, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:10] {2391} INFO -  at 212.8s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:10] {2218} INFO - iteration 636, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:10] {2391} INFO -  at 212.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:10] {2218} INFO - iteration 637, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:10] {2391} INFO -  at 213.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:10] {2218} INFO - iteration 638, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:10] {2391} INFO -  at 213.4s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:10] {2218} INFO - iteration 639, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2391} INFO -  at 213.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2218} INFO - iteration 640, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2391} INFO -  at 213.7s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2218} INFO - iteration 641, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2391} INFO -  at 213.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2218} INFO - iteration 642, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2391} INFO -  at 214.0s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2218} INFO - iteration 643, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2391} INFO -  at 214.5s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:11] {2218} INFO - iteration 644, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2391} INFO -  at 214.8s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2218} INFO - iteration 645, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2391} INFO -  at 214.9s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2218} INFO - iteration 646, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2391} INFO -  at 215.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2218} INFO - iteration 647, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2391} INFO -  at 215.3s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2218} INFO - iteration 648, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2391} INFO -  at 215.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:12] {2218} INFO - iteration 649, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:13] {2391} INFO -  at 215.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:13] {2218} INFO - iteration 650, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:13] {2391} INFO -  at 216.2s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:13] {2218} INFO - iteration 651, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:14] {2391} INFO -  at 216.8s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:14] {2218} INFO - iteration 652, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:14] {2391} INFO -  at 217.1s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:14] {2218} INFO - iteration 653, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:14] {2391} INFO -  at 217.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:14] {2218} INFO - iteration 654, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:15] {2391} INFO -  at 217.8s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:15] {2218} INFO - iteration 655, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:15] {2391} INFO -  at 218.2s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:15] {2218} INFO - iteration 656, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:16] {2391} INFO -  at 218.8s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:16] {2218} INFO - iteration 657, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:16] {2391} INFO -  at 219.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:16] {2218} INFO - iteration 658, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:16] {2391} INFO -  at 219.4s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:16] {2218} INFO - iteration 659, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2391} INFO -  at 219.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2218} INFO - iteration 660, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2391} INFO -  at 219.7s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2218} INFO - iteration 661, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2391} INFO -  at 219.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2218} INFO - iteration 662, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2391} INFO -  at 220.1s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2218} INFO - iteration 663, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2391} INFO -  at 220.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:17] {2218} INFO - iteration 664, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2391} INFO -  at 220.5s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2218} INFO - iteration 665, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2391} INFO -  at 220.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2218} INFO - iteration 666, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2391} INFO -  at 220.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2218} INFO - iteration 667, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2391} INFO -  at 221.2s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2218} INFO - iteration 668, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2391} INFO -  at 221.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:18] {2218} INFO - iteration 669, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:19] {2391} INFO -  at 221.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:19] {2218} INFO - iteration 670, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2391} INFO -  at 222.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2218} INFO - iteration 671, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2391} INFO -  at 222.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2218} INFO - iteration 672, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2391} INFO -  at 223.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2218} INFO - iteration 673, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2391} INFO -  at 223.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2218} INFO - iteration 674, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2391} INFO -  at 223.4s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:20] {2218} INFO - iteration 675, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:21] {2391} INFO -  at 223.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:21] {2218} INFO - iteration 676, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:21] {2391} INFO -  at 223.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:21] {2218} INFO - iteration 677, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:21] {2391} INFO -  at 223.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:21] {2218} INFO - iteration 678, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:59:22] {2391} INFO -  at 224.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:22] {2218} INFO - iteration 679, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:22] {2391} INFO -  at 225.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:22] {2218} INFO - iteration 680, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:22] {2391} INFO -  at 225.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:22] {2218} INFO - iteration 681, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:22] {2391} INFO -  at 225.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:22] {2218} INFO - iteration 682, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2391} INFO -  at 225.6s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2218} INFO - iteration 683, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2391} INFO -  at 225.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2218} INFO - iteration 684, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2391} INFO -  at 225.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2218} INFO - iteration 685, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2391} INFO -  at 226.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2218} INFO - iteration 686, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2391} INFO -  at 226.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2218} INFO - iteration 687, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2391} INFO -  at 226.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:23] {2218} INFO - iteration 688, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:59:25] {2391} INFO -  at 227.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:25] {2218} INFO - iteration 689, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:25] {2391} INFO -  at 228.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:25] {2218} INFO - iteration 690, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:59:26] {2391} INFO -  at 228.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:26] {2218} INFO - iteration 691, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:26] {2391} INFO -  at 229.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:26] {2218} INFO - iteration 692, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:26] {2391} INFO -  at 229.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:26] {2218} INFO - iteration 693, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:26] {2391} INFO -  at 229.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:26] {2218} INFO - iteration 694, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:27] {2391} INFO -  at 229.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:27] {2218} INFO - iteration 695, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:27] {2391} INFO -  at 230.0s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:27] {2218} INFO - iteration 696, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:59:28] {2391} INFO -  at 231.4s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:28] {2218} INFO - iteration 697, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:29] {2391} INFO -  at 232.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:29] {2218} INFO - iteration 698, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2391} INFO -  at 232.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2218} INFO - iteration 699, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2391} INFO -  at 233.0s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2218} INFO - iteration 700, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2391} INFO -  at 233.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2218} INFO - iteration 701, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2391} INFO -  at 233.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2218} INFO - iteration 702, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2391} INFO -  at 233.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:30] {2218} INFO - iteration 703, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:31] {2391} INFO -  at 233.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:31] {2218} INFO - iteration 704, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:31] {2391} INFO -  at 233.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:31] {2218} INFO - iteration 705, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:31] {2391} INFO -  at 234.2s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:31] {2218} INFO - iteration 706, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:31] {2391} INFO -  at 234.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:31] {2218} INFO - iteration 707, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2391} INFO -  at 234.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2218} INFO - iteration 708, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2391} INFO -  at 234.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2218} INFO - iteration 709, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2391} INFO -  at 234.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2218} INFO - iteration 710, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2391} INFO -  at 235.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2218} INFO - iteration 711, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2391} INFO -  at 235.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2218} INFO - iteration 712, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2391} INFO -  at 235.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:32] {2218} INFO - iteration 713, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2391} INFO -  at 235.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2218} INFO - iteration 714, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2391} INFO -  at 235.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2218} INFO - iteration 715, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2391} INFO -  at 235.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2218} INFO - iteration 716, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2391} INFO -  at 236.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2218} INFO - iteration 717, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2391} INFO -  at 236.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2218} INFO - iteration 718, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2391} INFO -  at 236.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:33] {2218} INFO - iteration 719, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2391} INFO -  at 236.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2218} INFO - iteration 720, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2391} INFO -  at 236.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2218} INFO - iteration 721, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2391} INFO -  at 236.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2218} INFO - iteration 722, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2391} INFO -  at 237.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2218} INFO - iteration 723, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2391} INFO -  at 237.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:34] {2218} INFO - iteration 724, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:35] {2391} INFO -  at 237.5s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:35] {2218} INFO - iteration 725, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:35] {2391} INFO -  at 237.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:35] {2218} INFO - iteration 726, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:35] {2391} INFO -  at 237.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:35] {2218} INFO - iteration 727, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:35] {2391} INFO -  at 238.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:35] {2218} INFO - iteration 728, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:59:36] {2391} INFO -  at 239.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:36] {2218} INFO - iteration 729, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:36] {2391} INFO -  at 239.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:36] {2218} INFO - iteration 730, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:36] {2391} INFO -  at 239.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:36] {2218} INFO - iteration 731, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2391} INFO -  at 239.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2218} INFO - iteration 732, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2391} INFO -  at 240.0s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2218} INFO - iteration 733, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2391} INFO -  at 240.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2218} INFO - iteration 734, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2391} INFO -  at 240.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2218} INFO - iteration 735, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2391} INFO -  at 240.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:37] {2218} INFO - iteration 736, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2391} INFO -  at 240.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2218} INFO - iteration 737, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2391} INFO -  at 240.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2218} INFO - iteration 738, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2391} INFO -  at 240.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2218} INFO - iteration 739, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2391} INFO -  at 241.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2218} INFO - iteration 740, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2391} INFO -  at 241.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2218} INFO - iteration 741, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2391} INFO -  at 241.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:38] {2218} INFO - iteration 742, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2391} INFO -  at 241.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2218} INFO - iteration 743, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2391} INFO -  at 241.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2218} INFO - iteration 744, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2391} INFO -  at 241.9s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2218} INFO - iteration 745, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2391} INFO -  at 242.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2218} INFO - iteration 746, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2391} INFO -  at 242.4s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:39] {2218} INFO - iteration 747, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:40] {2391} INFO -  at 242.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:40] {2218} INFO - iteration 748, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:40] {2391} INFO -  at 242.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:40] {2218} INFO - iteration 749, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:40] {2391} INFO -  at 243.0s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:40] {2218} INFO - iteration 750, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:40] {2391} INFO -  at 243.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:40] {2218} INFO - iteration 751, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:41] {2391} INFO -  at 244.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:41] {2218} INFO - iteration 752, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:42] {2391} INFO -  at 245.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:42] {2218} INFO - iteration 753, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:43] {2391} INFO -  at 245.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:43] {2218} INFO - iteration 754, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:43] {2391} INFO -  at 246.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:43] {2218} INFO - iteration 755, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:43] {2391} INFO -  at 246.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:43] {2218} INFO - iteration 756, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2391} INFO -  at 246.6s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2218} INFO - iteration 757, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2391} INFO -  at 246.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2218} INFO - iteration 758, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2391} INFO -  at 246.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2218} INFO - iteration 759, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2391} INFO -  at 247.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2218} INFO - iteration 760, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2391} INFO -  at 247.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2218} INFO - iteration 761, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2391} INFO -  at 247.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:44] {2218} INFO - iteration 762, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2391} INFO -  at 247.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2218} INFO - iteration 763, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2391} INFO -  at 247.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2218} INFO - iteration 764, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2391} INFO -  at 247.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2218} INFO - iteration 765, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2391} INFO -  at 248.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2218} INFO - iteration 766, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2391} INFO -  at 248.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:45] {2218} INFO - iteration 767, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2391} INFO -  at 248.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2218} INFO - iteration 768, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2391} INFO -  at 248.8s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2218} INFO - iteration 769, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2391} INFO -  at 248.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2218} INFO - iteration 770, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2391} INFO -  at 249.1s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2218} INFO - iteration 771, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2391} INFO -  at 249.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:46] {2218} INFO - iteration 772, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2391} INFO -  at 249.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2218} INFO - iteration 773, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2391} INFO -  at 249.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2218} INFO - iteration 774, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2391} INFO -  at 249.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2218} INFO - iteration 775, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2391} INFO -  at 250.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2218} INFO - iteration 776, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2391} INFO -  at 250.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2218} INFO - iteration 777, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2391} INFO -  at 250.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:47] {2218} INFO - iteration 778, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2391} INFO -  at 250.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2218} INFO - iteration 779, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2391} INFO -  at 250.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2218} INFO - iteration 780, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2391} INFO -  at 250.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2218} INFO - iteration 781, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2391} INFO -  at 250.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2218} INFO - iteration 782, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2391} INFO -  at 251.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2218} INFO - iteration 783, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2391} INFO -  at 251.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2218} INFO - iteration 784, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:48] {2391} INFO -  at 251.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2218} INFO - iteration 785, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2391} INFO -  at 251.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2218} INFO - iteration 786, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2391} INFO -  at 251.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2218} INFO - iteration 787, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2391} INFO -  at 252.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2218} INFO - iteration 788, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2391} INFO -  at 252.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2218} INFO - iteration 789, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2391} INFO -  at 252.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2218} INFO - iteration 790, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2391} INFO -  at 252.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:49] {2218} INFO - iteration 791, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2391} INFO -  at 252.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2218} INFO - iteration 792, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2391} INFO -  at 252.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2218} INFO - iteration 793, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2391} INFO -  at 252.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2218} INFO - iteration 794, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2391} INFO -  at 253.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2218} INFO - iteration 795, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2391} INFO -  at 253.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2218} INFO - iteration 796, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2391} INFO -  at 253.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:50] {2218} INFO - iteration 797, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2391} INFO -  at 253.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2218} INFO - iteration 798, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2391} INFO -  at 253.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2218} INFO - iteration 799, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2391} INFO -  at 253.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2218} INFO - iteration 800, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2391} INFO -  at 254.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2218} INFO - iteration 801, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2391} INFO -  at 254.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2218} INFO - iteration 802, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:51] {2391} INFO -  at 254.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2218} INFO - iteration 803, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2391} INFO -  at 254.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2218} INFO - iteration 804, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2391} INFO -  at 254.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2218} INFO - iteration 805, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2391} INFO -  at 255.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2218} INFO - iteration 806, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2391} INFO -  at 255.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2218} INFO - iteration 807, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2391} INFO -  at 255.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2218} INFO - iteration 808, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2391} INFO -  at 255.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:52] {2218} INFO - iteration 809, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:53] {2391} INFO -  at 255.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:53] {2218} INFO - iteration 810, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:53] {2391} INFO -  at 255.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:53] {2218} INFO - iteration 811, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:53] {2391} INFO -  at 256.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:53] {2218} INFO - iteration 812, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:53] {2391} INFO -  at 256.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:53] {2218} INFO - iteration 813, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:54] {2391} INFO -  at 256.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:54] {2218} INFO - iteration 814, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:55] {2391} INFO -  at 257.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:55] {2218} INFO - iteration 815, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 19:59:56] {2391} INFO -  at 258.5s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:56] {2218} INFO - iteration 816, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:56] {2391} INFO -  at 258.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:56] {2218} INFO - iteration 817, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:56] {2391} INFO -  at 259.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:56] {2218} INFO - iteration 818, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:57] {2391} INFO -  at 259.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:57] {2218} INFO - iteration 819, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:57] {2391} INFO -  at 259.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:57] {2218} INFO - iteration 820, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:57] {2391} INFO -  at 259.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:57] {2218} INFO - iteration 821, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 19:59:57] {2391} INFO -  at 260.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:57] {2218} INFO - iteration 822, current learner rf\n",
            "[flaml.automl.logger: 12-17 19:59:58] {2391} INFO -  at 260.6s,\testimator rf's best error=0.0919,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:58] {2218} INFO - iteration 823, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 19:59:58] {2391} INFO -  at 260.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:58] {2218} INFO - iteration 824, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 19:59:59] {2391} INFO -  at 261.6s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 19:59:59] {2218} INFO - iteration 825, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:00:00] {2391} INFO -  at 262.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:00] {2218} INFO - iteration 826, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:00] {2391} INFO -  at 263.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:00] {2218} INFO - iteration 827, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:00:01] {2391} INFO -  at 264.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:01] {2218} INFO - iteration 828, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:01] {2391} INFO -  at 264.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:01] {2218} INFO - iteration 829, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:01] {2391} INFO -  at 264.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:01] {2218} INFO - iteration 830, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2391} INFO -  at 264.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2218} INFO - iteration 831, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2391} INFO -  at 264.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2218} INFO - iteration 832, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2391} INFO -  at 264.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2218} INFO - iteration 833, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2391} INFO -  at 265.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2218} INFO - iteration 834, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2391} INFO -  at 265.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2218} INFO - iteration 835, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2391} INFO -  at 265.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:02] {2218} INFO - iteration 836, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2391} INFO -  at 265.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2218} INFO - iteration 837, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2391} INFO -  at 265.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2218} INFO - iteration 838, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2391} INFO -  at 265.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2218} INFO - iteration 839, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2391} INFO -  at 266.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2218} INFO - iteration 840, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2391} INFO -  at 266.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2218} INFO - iteration 841, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2391} INFO -  at 266.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:03] {2218} INFO - iteration 842, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2391} INFO -  at 266.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2218} INFO - iteration 843, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2391} INFO -  at 266.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2218} INFO - iteration 844, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2391} INFO -  at 267.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2218} INFO - iteration 845, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2391} INFO -  at 267.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2218} INFO - iteration 846, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2391} INFO -  at 267.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2218} INFO - iteration 847, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2391} INFO -  at 267.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:04] {2218} INFO - iteration 848, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2391} INFO -  at 267.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2218} INFO - iteration 849, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2391} INFO -  at 267.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2218} INFO - iteration 850, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2391} INFO -  at 267.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2218} INFO - iteration 851, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2391} INFO -  at 268.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2218} INFO - iteration 852, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2391} INFO -  at 268.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2218} INFO - iteration 853, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2391} INFO -  at 268.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:05] {2218} INFO - iteration 854, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:06] {2391} INFO -  at 268.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:06] {2218} INFO - iteration 855, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:06] {2391} INFO -  at 268.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:06] {2218} INFO - iteration 856, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:00:07] {2391} INFO -  at 269.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:07] {2218} INFO - iteration 857, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:08] {2391} INFO -  at 270.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:08] {2218} INFO - iteration 858, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:09] {2391} INFO -  at 271.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:09] {2218} INFO - iteration 859, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:09] {2391} INFO -  at 272.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:09] {2218} INFO - iteration 860, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:10] {2391} INFO -  at 272.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:10] {2218} INFO - iteration 861, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:10] {2391} INFO -  at 272.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:10] {2218} INFO - iteration 862, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:00:11] {2391} INFO -  at 273.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:11] {2218} INFO - iteration 863, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:11] {2391} INFO -  at 273.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:11] {2218} INFO - iteration 864, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:00:12] {2391} INFO -  at 275.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:12] {2218} INFO - iteration 865, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:12] {2391} INFO -  at 275.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:12] {2218} INFO - iteration 866, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:12] {2391} INFO -  at 275.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:12] {2218} INFO - iteration 867, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2391} INFO -  at 275.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2218} INFO - iteration 868, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2391} INFO -  at 275.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2218} INFO - iteration 869, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2391} INFO -  at 275.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2218} INFO - iteration 870, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2391} INFO -  at 276.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2218} INFO - iteration 871, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2391} INFO -  at 276.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2218} INFO - iteration 872, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2391} INFO -  at 276.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:13] {2218} INFO - iteration 873, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2391} INFO -  at 276.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2218} INFO - iteration 874, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2391} INFO -  at 276.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2218} INFO - iteration 875, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2391} INFO -  at 276.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2218} INFO - iteration 876, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2391} INFO -  at 277.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2218} INFO - iteration 877, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2391} INFO -  at 277.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2218} INFO - iteration 878, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2391} INFO -  at 277.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:14] {2218} INFO - iteration 879, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2391} INFO -  at 277.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2218} INFO - iteration 880, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2391} INFO -  at 277.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2218} INFO - iteration 881, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2391} INFO -  at 277.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2218} INFO - iteration 882, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2391} INFO -  at 278.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2218} INFO - iteration 883, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2391} INFO -  at 278.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:15] {2218} INFO - iteration 884, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2391} INFO -  at 279.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2218} INFO - iteration 885, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2391} INFO -  at 279.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2218} INFO - iteration 886, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2391} INFO -  at 280.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2218} INFO - iteration 887, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2391} INFO -  at 280.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2218} INFO - iteration 888, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2391} INFO -  at 280.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:17] {2218} INFO - iteration 889, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:18] {2391} INFO -  at 280.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:18] {2218} INFO - iteration 890, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:18] {2391} INFO -  at 280.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:18] {2218} INFO - iteration 891, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:18] {2391} INFO -  at 280.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:18] {2218} INFO - iteration 892, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:00:18] {2391} INFO -  at 281.0s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:18] {2218} INFO - iteration 893, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2391} INFO -  at 281.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2218} INFO - iteration 894, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2391} INFO -  at 281.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2218} INFO - iteration 895, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2391} INFO -  at 282.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2218} INFO - iteration 896, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2391} INFO -  at 282.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2218} INFO - iteration 897, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2391} INFO -  at 282.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:19] {2218} INFO - iteration 898, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:20] {2391} INFO -  at 282.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:20] {2218} INFO - iteration 899, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:20] {2391} INFO -  at 282.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:20] {2218} INFO - iteration 900, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:20] {2391} INFO -  at 283.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:20] {2218} INFO - iteration 901, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:21] {2391} INFO -  at 283.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:21] {2218} INFO - iteration 902, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:22] {2391} INFO -  at 284.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:22] {2218} INFO - iteration 903, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:22] {2391} INFO -  at 285.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:22] {2218} INFO - iteration 904, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:23] {2391} INFO -  at 285.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:23] {2218} INFO - iteration 905, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:23] {2391} INFO -  at 286.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:23] {2218} INFO - iteration 906, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:23] {2391} INFO -  at 286.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:23] {2218} INFO - iteration 907, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:24] {2391} INFO -  at 286.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:24] {2218} INFO - iteration 908, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:24] {2391} INFO -  at 287.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:24] {2218} INFO - iteration 909, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:24] {2391} INFO -  at 287.4s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:24] {2218} INFO - iteration 910, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:25] {2391} INFO -  at 287.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:25] {2218} INFO - iteration 911, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:25] {2391} INFO -  at 288.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:25] {2218} INFO - iteration 912, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:26] {2391} INFO -  at 289.0s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:26] {2218} INFO - iteration 913, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:27] {2391} INFO -  at 289.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:27] {2218} INFO - iteration 914, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:27] {2391} INFO -  at 290.4s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:27] {2218} INFO - iteration 915, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:28] {2391} INFO -  at 290.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:28] {2218} INFO - iteration 916, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:28] {2391} INFO -  at 291.3s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:28] {2218} INFO - iteration 917, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2391} INFO -  at 291.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2218} INFO - iteration 918, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2391} INFO -  at 291.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2218} INFO - iteration 919, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2391} INFO -  at 291.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2218} INFO - iteration 920, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2391} INFO -  at 292.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2218} INFO - iteration 921, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2391} INFO -  at 292.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2218} INFO - iteration 922, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2391} INFO -  at 292.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:29] {2218} INFO - iteration 923, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:30] {2391} INFO -  at 292.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:30] {2218} INFO - iteration 924, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:30] {2391} INFO -  at 292.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:30] {2218} INFO - iteration 925, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:30] {2391} INFO -  at 293.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:30] {2218} INFO - iteration 926, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:31] {2391} INFO -  at 294.1s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:31] {2218} INFO - iteration 927, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2391} INFO -  at 294.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2218} INFO - iteration 928, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2391} INFO -  at 294.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2218} INFO - iteration 929, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2391} INFO -  at 294.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2218} INFO - iteration 930, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2391} INFO -  at 295.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2218} INFO - iteration 931, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2391} INFO -  at 295.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2218} INFO - iteration 932, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2391} INFO -  at 295.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:32] {2218} INFO - iteration 933, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:33] {2391} INFO -  at 295.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:33] {2218} INFO - iteration 934, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:34] {2391} INFO -  at 296.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:34] {2218} INFO - iteration 935, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:34] {2391} INFO -  at 297.3s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:34] {2218} INFO - iteration 936, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:36] {2391} INFO -  at 298.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:36] {2218} INFO - iteration 937, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:36] {2391} INFO -  at 298.8s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:36] {2218} INFO - iteration 938, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:00:36] {2391} INFO -  at 299.4s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:36] {2218} INFO - iteration 939, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:37] {2391} INFO -  at 299.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:37] {2218} INFO - iteration 940, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:00:37] {2391} INFO -  at 299.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:37] {2218} INFO - iteration 941, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:00:37] {2391} INFO -  at 300.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:37] {2218} INFO - iteration 942, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:00:37] {2391} INFO -  at 300.0s,\testimator lrl1's best error=0.6364,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:00:37] {2627} INFO - retrain xgb_limitdepth for 0.0s\n",
            "[flaml.automl.logger: 12-17 20:00:37] {2630} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
            "              colsample_bylevel=0.5086933112492915, colsample_bynode=None,\n",
            "              colsample_bytree=0.6306120069350191, device=None,\n",
            "              early_stopping_rounds=None, enable_categorical=False,\n",
            "              eval_metric=None, feature_types=None, gamma=None,\n",
            "              grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=1.0, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
            "              min_child_weight=0.024162635916970876, missing=nan,\n",
            "              monotone_constraints=None, multi_strategy=None, n_estimators=11,\n",
            "              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
            "[flaml.automl.logger: 12-17 20:00:37] {1930} INFO - fit succeeded\n",
            "[flaml.automl.logger: 12-17 20:00:37] {1931} INFO - Time taken to find the best model: 94.95896315574646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1cJ3bdafHX8"
      },
      "source": [
        "### View Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HFj20qrMbxUF",
        "outputId": "c3f87dd9-ad45-4e53-f5b0-00178016793a"
      },
      "source": [
        "automl.best_estimator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xgb_limitdepth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SaTeekgb_W-",
        "outputId": "253d9857-3f46-46c6-f1f1-4a616cd49c71"
      },
      "source": [
        "automl.best_config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 11,\n",
              " 'max_depth': 6,\n",
              " 'min_child_weight': 0.024162635916970876,\n",
              " 'learning_rate': 1.0,\n",
              " 'subsample': 0.9978568217362944,\n",
              " 'colsample_bylevel': 0.5086933112492915,\n",
              " 'colsample_bytree': 0.6306120069350191,\n",
              " 'reg_alpha': 0.005488592959841232,\n",
              " 'reg_lambda': 0.9621287550295926}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWURjyjQcCzv",
        "outputId": "3a3cf444-ca4c-4069-aba6-10e5ced658f0"
      },
      "source": [
        "automl.model.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 11,\n",
              " 'max_depth': 6,\n",
              " 'min_child_weight': 0.024162635916970876,\n",
              " 'learning_rate': 1.0,\n",
              " 'subsample': 0.9978568217362944,\n",
              " 'colsample_bylevel': 0.5086933112492915,\n",
              " 'colsample_bytree': 0.6306120069350191,\n",
              " 'reg_alpha': 0.005488592959841232,\n",
              " 'reg_lambda': 0.9621287550295926,\n",
              " 'n_jobs': -1,\n",
              " 'verbosity': 0,\n",
              " 'task': <flaml.automl.task.generic_task.GenericTask at 0x7cd3540fbf40>,\n",
              " '_estimator_type': 'classifier'}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZxy1n34fLKG"
      },
      "source": [
        "### Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "Z38VkmjCcX2u",
        "outputId": "2e636472-277b-48b0-bd5a-bcf2feab04c1"
      },
      "source": [
        "predictions = automl.predict(X_test)\n",
        "cf = confusion_matrix(y_test, predictions)\n",
        "print(classification_report(y_test, predictions))\n",
        "sns.heatmap(cf, annot=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98        91\n",
            "           1       0.89      0.73      0.80        11\n",
            "\n",
            "    accuracy                           0.96       102\n",
            "   macro avg       0.93      0.86      0.89       102\n",
            "weighted avg       0.96      0.96      0.96       102\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVsrvRkffNpG"
      },
      "source": [
        "## FLAML AutoML with Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVfOcxr0cpSO"
      },
      "source": [
        "automl = AutoML()\n",
        "\n",
        "automl_settings = {\n",
        "    \"time_budget\": 300,\n",
        "    \"metric\": 'f1',\n",
        "    \"task\": 'classification',\n",
        "    \"log_file_name\": 'mylog.log',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE-7XMVzc0rm",
        "outputId": "34467196-b087-4800-cd7a-d3898acc1e0d"
      },
      "source": [
        "automl.fit(X_train=X_train, y_train=y_train.values, ensemble=True,\n",
        "           **automl_settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:01:03] {1679} INFO - task = classification\n",
            "[flaml.automl.logger: 12-17 20:01:03] {1690} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 12-17 20:01:03] {1788} INFO - Minimizing error metric: 1-f1\n",
            "[flaml.automl.logger: 12-17 20:01:03] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2218} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2344} INFO - Estimated sufficient time budget=570s. Estimated necessary time budget=13s.\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2391} INFO -  at 0.1s,\testimator lgbm's best error=1.0000,\tbest estimator lgbm's best error=1.0000\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2218} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2391} INFO -  at 0.2s,\testimator lgbm's best error=1.0000,\tbest estimator lgbm's best error=1.0000\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2218} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2391} INFO -  at 0.2s,\testimator lgbm's best error=0.1432,\tbest estimator lgbm's best error=0.1432\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2218} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2391} INFO -  at 0.3s,\testimator xgboost's best error=1.0000,\tbest estimator lgbm's best error=0.1432\n",
            "[flaml.automl.logger: 12-17 20:01:03] {2218} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 0.4s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 0.5s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 0.5s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 0.6s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 0.7s,\testimator lgbm's best error=0.1209,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 0.8s,\testimator xgboost's best error=1.0000,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 0.9s,\testimator xgboost's best error=0.1515,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 11, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 1.1s,\testimator extra_tree's best error=0.9733,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 12, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2391} INFO -  at 1.4s,\testimator rf's best error=0.1504,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:04] {2218} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2391} INFO -  at 1.5s,\testimator xgboost's best error=0.1473,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2218} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2391} INFO -  at 1.6s,\testimator xgboost's best error=0.1473,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2218} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2391} INFO -  at 1.7s,\testimator xgboost's best error=0.1362,\tbest estimator lgbm's best error=0.1209\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2218} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2391} INFO -  at 1.8s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2218} INFO - iteration 17, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2391} INFO -  at 2.0s,\testimator extra_tree's best error=0.5369,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2218} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2391} INFO -  at 2.1s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2218} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2391} INFO -  at 2.2s,\testimator xgboost's best error=0.1362,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:05] {2218} INFO - iteration 20, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2391} INFO -  at 2.4s,\testimator rf's best error=0.1504,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2218} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2391} INFO -  at 2.5s,\testimator xgboost's best error=0.1329,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2218} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2391} INFO -  at 2.6s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2218} INFO - iteration 23, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2391} INFO -  at 2.8s,\testimator rf's best error=0.1504,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2218} INFO - iteration 24, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2391} INFO -  at 3.0s,\testimator extra_tree's best error=0.5369,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2218} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2391} INFO -  at 3.3s,\testimator extra_tree's best error=0.5369,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:06] {2218} INFO - iteration 26, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2391} INFO -  at 3.5s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2218} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2391} INFO -  at 3.6s,\testimator xgboost's best error=0.1329,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2218} INFO - iteration 28, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2391} INFO -  at 3.9s,\testimator extra_tree's best error=0.2347,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2218} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2391} INFO -  at 4.1s,\testimator extra_tree's best error=0.2347,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2218} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2391} INFO -  at 4.2s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2218} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2391} INFO -  at 4.3s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2218} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2391} INFO -  at 4.3s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:07] {2218} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2391} INFO -  at 4.5s,\testimator extra_tree's best error=0.2347,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2218} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2391} INFO -  at 4.6s,\testimator lgbm's best error=0.1119,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2218} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2391} INFO -  at 4.8s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2218} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2391} INFO -  at 5.1s,\testimator extra_tree's best error=0.2193,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2218} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2391} INFO -  at 5.2s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2218} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2391} INFO -  at 5.3s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:08] {2218} INFO - iteration 39, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2391} INFO -  at 5.5s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2218} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2391} INFO -  at 5.6s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2218} INFO - iteration 41, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2391} INFO -  at 5.8s,\testimator extra_tree's best error=0.2193,\tbest estimator lgbm's best error=0.1119\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2218} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2391} INFO -  at 5.9s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2218} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2391} INFO -  at 6.0s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2218} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2391} INFO -  at 6.3s,\testimator extra_tree's best error=0.2193,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:09] {2218} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2391} INFO -  at 6.4s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2218} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2391} INFO -  at 6.5s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2218} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2391} INFO -  at 6.6s,\testimator xgboost's best error=0.1288,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2218} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2391} INFO -  at 6.7s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2218} INFO - iteration 49, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2391} INFO -  at 7.0s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2218} INFO - iteration 50, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2391} INFO -  at 7.3s,\testimator extra_tree's best error=0.1656,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:10] {2218} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:11] {2391} INFO -  at 7.5s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:11] {2218} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:11] {2391} INFO -  at 8.0s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:11] {2218} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:13] {2391} INFO -  at 10.0s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:13] {2218} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:13] {2391} INFO -  at 10.3s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:13] {2218} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:14] {2391} INFO -  at 10.5s,\testimator xgboost's best error=0.1251,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:14] {2218} INFO - iteration 56, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:14] {2391} INFO -  at 10.7s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:14] {2218} INFO - iteration 57, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:14] {2391} INFO -  at 11.2s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:14] {2218} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:15] {2391} INFO -  at 11.5s,\testimator xgboost's best error=0.1251,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:15] {2218} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:15] {2391} INFO -  at 11.9s,\testimator lgbm's best error=0.1040,\tbest estimator lgbm's best error=0.1040\n",
            "[flaml.automl.logger: 12-17 20:01:15] {2218} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:16] {2391} INFO -  at 12.7s,\testimator xgboost's best error=0.1023,\tbest estimator xgboost's best error=0.1023\n",
            "[flaml.automl.logger: 12-17 20:01:16] {2218} INFO - iteration 61, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:16] {2391} INFO -  at 13.3s,\testimator rf's best error=0.1478,\tbest estimator xgboost's best error=0.1023\n",
            "[flaml.automl.logger: 12-17 20:01:16] {2218} INFO - iteration 62, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:17] {2391} INFO -  at 14.0s,\testimator extra_tree's best error=0.1656,\tbest estimator xgboost's best error=0.1023\n",
            "[flaml.automl.logger: 12-17 20:01:17] {2218} INFO - iteration 63, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:18] {2391} INFO -  at 15.0s,\testimator extra_tree's best error=0.1237,\tbest estimator xgboost's best error=0.1023\n",
            "[flaml.automl.logger: 12-17 20:01:18] {2218} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:20] {2391} INFO -  at 16.5s,\testimator lgbm's best error=0.1040,\tbest estimator xgboost's best error=0.1023\n",
            "[flaml.automl.logger: 12-17 20:01:20] {2218} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:20] {2391} INFO -  at 17.0s,\testimator xgboost's best error=0.1023,\tbest estimator xgboost's best error=0.1023\n",
            "[flaml.automl.logger: 12-17 20:01:20] {2218} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:21] {2391} INFO -  at 17.6s,\testimator xgboost's best error=0.1023,\tbest estimator xgboost's best error=0.1023\n",
            "[flaml.automl.logger: 12-17 20:01:21] {2218} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:21] {2391} INFO -  at 18.2s,\testimator xgboost's best error=0.1023,\tbest estimator xgboost's best error=0.1023\n",
            "[flaml.automl.logger: 12-17 20:01:21] {2218} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:22] {2391} INFO -  at 18.6s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:22] {2218} INFO - iteration 69, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:22] {2391} INFO -  at 19.0s,\testimator xgboost's best error=0.1023,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:22] {2218} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:22] {2391} INFO -  at 19.2s,\testimator xgboost's best error=0.1023,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:22] {2218} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:23] {2391} INFO -  at 19.4s,\testimator xgboost's best error=0.1023,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:23] {2218} INFO - iteration 72, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:23] {2391} INFO -  at 19.6s,\testimator extra_tree's best error=0.1237,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:23] {2218} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:23] {2391} INFO -  at 19.9s,\testimator xgboost's best error=0.1023,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:23] {2218} INFO - iteration 74, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:24] {2391} INFO -  at 20.6s,\testimator extra_tree's best error=0.1136,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:24] {2218} INFO - iteration 75, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:24] {2391} INFO -  at 21.0s,\testimator rf's best error=0.1478,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:24] {2218} INFO - iteration 76, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:25] {2391} INFO -  at 21.5s,\testimator rf's best error=0.1472,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:25] {2218} INFO - iteration 77, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:25] {2391} INFO -  at 22.2s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:25] {2218} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:27] {2391} INFO -  at 24.1s,\testimator xgboost's best error=0.1023,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:27] {2218} INFO - iteration 79, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:27] {2391} INFO -  at 24.3s,\testimator rf's best error=0.1472,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:27] {2218} INFO - iteration 80, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:28] {2391} INFO -  at 24.9s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:28] {2218} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:29] {2391} INFO -  at 25.5s,\testimator xgboost's best error=0.1023,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:29] {2218} INFO - iteration 82, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:29] {2391} INFO -  at 25.8s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:29] {2218} INFO - iteration 83, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:30] {2391} INFO -  at 26.4s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:30] {2218} INFO - iteration 84, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:30] {2391} INFO -  at 27.0s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:30] {2218} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:31] {2391} INFO -  at 27.5s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:31] {2218} INFO - iteration 86, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:31] {2391} INFO -  at 27.9s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:31] {2218} INFO - iteration 87, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:31] {2391} INFO -  at 28.3s,\testimator rf's best error=0.1210,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:31] {2218} INFO - iteration 88, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:32] {2391} INFO -  at 28.6s,\testimator rf's best error=0.1210,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:32] {2218} INFO - iteration 89, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:32] {2391} INFO -  at 29.0s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:32] {2218} INFO - iteration 90, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:33] {2391} INFO -  at 29.5s,\testimator rf's best error=0.1210,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:33] {2218} INFO - iteration 91, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:33] {2391} INFO -  at 30.2s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:33] {2218} INFO - iteration 92, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:34] {2391} INFO -  at 30.6s,\testimator rf's best error=0.1210,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:34] {2218} INFO - iteration 93, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:34] {2391} INFO -  at 30.9s,\testimator rf's best error=0.1210,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:34] {2218} INFO - iteration 94, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:34] {2391} INFO -  at 30.9s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:34] {2218} INFO - iteration 95, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:34] {2391} INFO -  at 31.2s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:34] {2218} INFO - iteration 96, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:35] {2391} INFO -  at 31.5s,\testimator rf's best error=0.1210,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:35] {2218} INFO - iteration 97, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:35] {2391} INFO -  at 31.8s,\testimator rf's best error=0.1210,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:35] {2218} INFO - iteration 98, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:35] {2391} INFO -  at 32.1s,\testimator rf's best error=0.1058,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:35] {2218} INFO - iteration 99, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:35] {2391} INFO -  at 32.4s,\testimator rf's best error=0.1058,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:35] {2218} INFO - iteration 100, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:36] {2391} INFO -  at 32.7s,\testimator extra_tree's best error=0.1032,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:36] {2218} INFO - iteration 101, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:36] {2391} INFO -  at 33.1s,\testimator rf's best error=0.1058,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:36] {2218} INFO - iteration 102, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:36] {2391} INFO -  at 33.1s,\testimator lgbm's best error=0.0986,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:36] {2218} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:36] {2391} INFO -  at 33.3s,\testimator xgboost's best error=0.1023,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:36] {2218} INFO - iteration 104, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:37] {2391} INFO -  at 33.6s,\testimator rf's best error=0.1058,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:37] {2218} INFO - iteration 105, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:37] {2391} INFO -  at 34.0s,\testimator rf's best error=0.1058,\tbest estimator lgbm's best error=0.0986\n",
            "[flaml.automl.logger: 12-17 20:01:37] {2218} INFO - iteration 106, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:37] {2391} INFO -  at 34.4s,\testimator extra_tree's best error=0.0965,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 20:01:38] {2218} INFO - iteration 107, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:38] {2391} INFO -  at 34.6s,\testimator rf's best error=0.1058,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 20:01:38] {2218} INFO - iteration 108, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:38] {2391} INFO -  at 35.1s,\testimator extra_tree's best error=0.0965,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 20:01:38] {2218} INFO - iteration 109, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:39] {2391} INFO -  at 35.4s,\testimator rf's best error=0.1058,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 20:01:39] {2218} INFO - iteration 110, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:39] {2391} INFO -  at 35.7s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 20:01:39] {2218} INFO - iteration 111, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:39] {2391} INFO -  at 36.1s,\testimator extra_tree's best error=0.0965,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 20:01:39] {2218} INFO - iteration 112, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:39] {2391} INFO -  at 36.3s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0965\n",
            "[flaml.automl.logger: 12-17 20:01:39] {2218} INFO - iteration 113, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:40] {2391} INFO -  at 36.7s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:40] {2218} INFO - iteration 114, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:40] {2391} INFO -  at 37.0s,\testimator rf's best error=0.1058,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:40] {2218} INFO - iteration 115, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:40] {2391} INFO -  at 37.3s,\testimator rf's best error=0.1058,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:40] {2218} INFO - iteration 116, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:41] {2391} INFO -  at 37.6s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:41] {2218} INFO - iteration 117, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:41] {2391} INFO -  at 38.0s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:41] {2218} INFO - iteration 118, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:41] {2391} INFO -  at 38.1s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:41] {2218} INFO - iteration 119, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:42] {2391} INFO -  at 38.4s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:42] {2218} INFO - iteration 120, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:42] {2391} INFO -  at 38.7s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:42] {2218} INFO - iteration 121, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:42] {2391} INFO -  at 39.0s,\testimator extra_tree's best error=0.0875,\tbest estimator extra_tree's best error=0.0875\n",
            "[flaml.automl.logger: 12-17 20:01:42] {2218} INFO - iteration 122, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2391} INFO -  at 39.5s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2218} INFO - iteration 123, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2391} INFO -  at 39.6s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2218} INFO - iteration 124, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2391} INFO -  at 39.6s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2218} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2391} INFO -  at 39.7s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2218} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2391} INFO -  at 39.8s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2218} INFO - iteration 127, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2391} INFO -  at 40.1s,\testimator rf's best error=0.1058,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:43] {2218} INFO - iteration 128, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2391} INFO -  at 40.4s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2218} INFO - iteration 129, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2391} INFO -  at 40.6s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2218} INFO - iteration 130, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2391} INFO -  at 40.7s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2218} INFO - iteration 131, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2391} INFO -  at 41.1s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2218} INFO - iteration 132, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2391} INFO -  at 41.2s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:44] {2218} INFO - iteration 133, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:45] {2391} INFO -  at 41.5s,\testimator rf's best error=0.1058,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:45] {2218} INFO - iteration 134, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:45] {2391} INFO -  at 41.6s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:45] {2218} INFO - iteration 135, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:45] {2391} INFO -  at 42.2s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:45] {2218} INFO - iteration 136, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:46] {2391} INFO -  at 42.4s,\testimator xgboost's best error=0.1023,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:46] {2218} INFO - iteration 137, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:46] {2391} INFO -  at 42.5s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:46] {2218} INFO - iteration 138, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:46] {2391} INFO -  at 43.2s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:46] {2218} INFO - iteration 139, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:47] {2391} INFO -  at 43.5s,\testimator rf's best error=0.1058,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:47] {2218} INFO - iteration 140, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:47] {2391} INFO -  at 43.9s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:47] {2218} INFO - iteration 141, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:47] {2391} INFO -  at 44.2s,\testimator rf's best error=0.1023,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:47] {2218} INFO - iteration 142, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:48] {2391} INFO -  at 44.7s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:48] {2218} INFO - iteration 143, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:48] {2391} INFO -  at 45.1s,\testimator extra_tree's best error=0.0867,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:48] {2218} INFO - iteration 144, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:48] {2391} INFO -  at 45.3s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:48] {2218} INFO - iteration 145, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2391} INFO -  at 45.4s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2218} INFO - iteration 146, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2391} INFO -  at 45.5s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2218} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2391} INFO -  at 45.6s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2218} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2391} INFO -  at 45.6s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2218} INFO - iteration 149, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2391} INFO -  at 45.7s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2218} INFO - iteration 150, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2391} INFO -  at 46.0s,\testimator rf's best error=0.1008,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2218} INFO - iteration 151, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2391} INFO -  at 46.3s,\testimator rf's best error=0.1008,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:49] {2218} INFO - iteration 152, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:50] {2391} INFO -  at 46.6s,\testimator rf's best error=0.1008,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:50] {2218} INFO - iteration 153, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:50] {2391} INFO -  at 46.6s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:50] {2218} INFO - iteration 154, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:50] {2391} INFO -  at 46.7s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0867\n",
            "[flaml.automl.logger: 12-17 20:01:50] {2218} INFO - iteration 155, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:51] {2391} INFO -  at 47.4s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:51] {2218} INFO - iteration 156, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:51] {2391} INFO -  at 47.9s,\testimator rf's best error=0.1008,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:51] {2218} INFO - iteration 157, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:51] {2391} INFO -  at 48.1s,\testimator rf's best error=0.1008,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:51] {2218} INFO - iteration 158, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:52] {2391} INFO -  at 48.5s,\testimator rf's best error=0.1008,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:52] {2218} INFO - iteration 159, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:52] {2391} INFO -  at 49.3s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:52] {2218} INFO - iteration 160, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:53] {2391} INFO -  at 49.7s,\testimator rf's best error=0.1008,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:53] {2218} INFO - iteration 161, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:53] {2391} INFO -  at 50.1s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:53] {2218} INFO - iteration 162, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:54] {2391} INFO -  at 50.6s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:54] {2218} INFO - iteration 163, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:54] {2391} INFO -  at 51.3s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:54] {2218} INFO - iteration 164, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:55] {2391} INFO -  at 51.6s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:55] {2218} INFO - iteration 165, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:55] {2391} INFO -  at 51.9s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:55] {2218} INFO - iteration 166, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:55] {2391} INFO -  at 52.0s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:55] {2218} INFO - iteration 167, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2391} INFO -  at 52.6s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2218} INFO - iteration 168, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2391} INFO -  at 52.7s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2218} INFO - iteration 169, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2391} INFO -  at 52.8s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2218} INFO - iteration 170, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2391} INFO -  at 52.8s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2218} INFO - iteration 171, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2391} INFO -  at 53.1s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2218} INFO - iteration 172, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2391} INFO -  at 53.3s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:56] {2218} INFO - iteration 173, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:57] {2391} INFO -  at 53.7s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:57] {2218} INFO - iteration 174, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:57] {2391} INFO -  at 54.0s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:57] {2218} INFO - iteration 175, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:01:58] {2391} INFO -  at 54.6s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:58] {2218} INFO - iteration 176, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:58] {2391} INFO -  at 54.9s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:58] {2218} INFO - iteration 177, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:58] {2391} INFO -  at 55.2s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:58] {2218} INFO - iteration 178, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2391} INFO -  at 55.6s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2218} INFO - iteration 179, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2391} INFO -  at 55.7s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2218} INFO - iteration 180, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2391} INFO -  at 55.8s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2218} INFO - iteration 181, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2391} INFO -  at 56.2s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2218} INFO - iteration 182, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2391} INFO -  at 56.2s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:01:59] {2218} INFO - iteration 183, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2391} INFO -  at 56.6s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2218} INFO - iteration 184, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2391} INFO -  at 56.7s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2218} INFO - iteration 185, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2391} INFO -  at 57.1s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2218} INFO - iteration 186, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2391} INFO -  at 57.2s,\testimator xgb_limitdepth's best error=0.1415,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2218} INFO - iteration 187, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2391} INFO -  at 57.4s,\testimator xgb_limitdepth's best error=0.1415,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:00] {2218} INFO - iteration 188, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:01] {2391} INFO -  at 57.5s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:01] {2218} INFO - iteration 189, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:01] {2391} INFO -  at 57.6s,\testimator xgb_limitdepth's best error=0.1402,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:01] {2218} INFO - iteration 190, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:01] {2391} INFO -  at 57.8s,\testimator xgb_limitdepth's best error=0.1402,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:01] {2218} INFO - iteration 191, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:02] {2391} INFO -  at 58.5s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:02] {2218} INFO - iteration 192, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:02] {2391} INFO -  at 58.7s,\testimator xgb_limitdepth's best error=0.1402,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:02] {2218} INFO - iteration 193, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:02] {2391} INFO -  at 58.8s,\testimator xgb_limitdepth's best error=0.1337,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:02] {2218} INFO - iteration 194, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:02] {2391} INFO -  at 58.9s,\testimator xgb_limitdepth's best error=0.1337,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:02] {2218} INFO - iteration 195, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:03] {2391} INFO -  at 59.5s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:03] {2218} INFO - iteration 196, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:03] {2391} INFO -  at 59.9s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:03] {2218} INFO - iteration 197, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:03] {2391} INFO -  at 60.2s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:03] {2218} INFO - iteration 198, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:04] {2391} INFO -  at 60.6s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:04] {2218} INFO - iteration 199, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:05] {2391} INFO -  at 61.5s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:05] {2218} INFO - iteration 200, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:05] {2391} INFO -  at 62.3s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:05] {2218} INFO - iteration 201, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:06] {2391} INFO -  at 62.6s,\testimator lgbm's best error=0.0986,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:06] {2218} INFO - iteration 202, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:06] {2391} INFO -  at 62.9s,\testimator rf's best error=0.0922,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:06] {2218} INFO - iteration 203, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:07] {2391} INFO -  at 63.7s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:07] {2218} INFO - iteration 204, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:07] {2391} INFO -  at 63.8s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:07] {2218} INFO - iteration 205, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:07] {2391} INFO -  at 63.9s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:07] {2218} INFO - iteration 206, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:08] {2391} INFO -  at 64.9s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:08] {2218} INFO - iteration 207, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:08] {2391} INFO -  at 65.0s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:08] {2218} INFO - iteration 208, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:09] {2391} INFO -  at 65.4s,\testimator extra_tree's best error=0.0854,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:09] {2218} INFO - iteration 209, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:09] {2391} INFO -  at 65.6s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:09] {2218} INFO - iteration 210, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:09] {2391} INFO -  at 65.7s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0854\n",
            "[flaml.automl.logger: 12-17 20:02:09] {2218} INFO - iteration 211, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:10] {2391} INFO -  at 66.6s,\testimator extra_tree's best error=0.0835,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 20:02:10] {2218} INFO - iteration 212, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:10] {2391} INFO -  at 67.2s,\testimator extra_tree's best error=0.0835,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 20:02:10] {2218} INFO - iteration 213, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:10] {2391} INFO -  at 67.3s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 20:02:10] {2218} INFO - iteration 214, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2391} INFO -  at 67.5s,\testimator xgb_limitdepth's best error=0.0858,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2218} INFO - iteration 215, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2391} INFO -  at 67.6s,\testimator xgboost's best error=0.0982,\tbest estimator extra_tree's best error=0.0835\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2218} INFO - iteration 216, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2391} INFO -  at 67.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2218} INFO - iteration 217, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2391} INFO -  at 68.2s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2218} INFO - iteration 218, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2391} INFO -  at 68.2s,\testimator lgbm's best error=0.0986,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2218} INFO - iteration 219, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2391} INFO -  at 68.3s,\testimator lgbm's best error=0.0986,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:11] {2218} INFO - iteration 220, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2391} INFO -  at 68.5s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2218} INFO - iteration 221, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2391} INFO -  at 68.5s,\testimator lgbm's best error=0.0986,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2218} INFO - iteration 222, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2391} INFO -  at 68.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2218} INFO - iteration 223, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2391} INFO -  at 68.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2218} INFO - iteration 224, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2391} INFO -  at 69.0s,\testimator lgbm's best error=0.0986,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2218} INFO - iteration 225, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2391} INFO -  at 69.1s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:12] {2218} INFO - iteration 226, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2391} INFO -  at 69.4s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2218} INFO - iteration 227, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2391} INFO -  at 69.5s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2218} INFO - iteration 228, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2391} INFO -  at 69.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2218} INFO - iteration 229, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2391} INFO -  at 69.9s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2218} INFO - iteration 230, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2391} INFO -  at 70.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2218} INFO - iteration 231, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2391} INFO -  at 70.2s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2218} INFO - iteration 232, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2391} INFO -  at 70.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:13] {2218} INFO - iteration 233, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2391} INFO -  at 70.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2218} INFO - iteration 234, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2391} INFO -  at 70.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2218} INFO - iteration 235, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2391} INFO -  at 71.1s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2218} INFO - iteration 236, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2391} INFO -  at 71.2s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2218} INFO - iteration 237, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:14] {2391} INFO -  at 71.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2218} INFO - iteration 238, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2391} INFO -  at 71.5s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2218} INFO - iteration 239, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2391} INFO -  at 71.7s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2218} INFO - iteration 240, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2391} INFO -  at 72.2s,\testimator extra_tree's best error=0.0835,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2218} INFO - iteration 241, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2391} INFO -  at 72.3s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:15] {2218} INFO - iteration 242, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:17] {2391} INFO -  at 74.0s,\testimator extra_tree's best error=0.0835,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:17] {2218} INFO - iteration 243, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:18] {2391} INFO -  at 74.4s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:18] {2218} INFO - iteration 244, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:18] {2391} INFO -  at 74.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:18] {2218} INFO - iteration 245, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:19] {2391} INFO -  at 75.6s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:19] {2218} INFO - iteration 246, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:19] {2391} INFO -  at 76.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:19] {2218} INFO - iteration 247, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:20] {2391} INFO -  at 76.4s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:20] {2218} INFO - iteration 248, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:20] {2391} INFO -  at 76.5s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:20] {2218} INFO - iteration 249, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:20] {2391} INFO -  at 76.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:20] {2218} INFO - iteration 250, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:21] {2391} INFO -  at 77.4s,\testimator extra_tree's best error=0.0835,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:21] {2218} INFO - iteration 251, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:21] {2391} INFO -  at 77.5s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:21] {2218} INFO - iteration 252, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:21] {2391} INFO -  at 77.9s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:21] {2218} INFO - iteration 253, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:22] {2391} INFO -  at 78.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:22] {2218} INFO - iteration 254, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:22] {2391} INFO -  at 79.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:22] {2218} INFO - iteration 255, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:22] {2391} INFO -  at 79.2s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:22] {2218} INFO - iteration 256, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:22] {2391} INFO -  at 79.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:22] {2218} INFO - iteration 257, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:23] {2391} INFO -  at 79.6s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:23] {2218} INFO - iteration 258, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:23] {2391} INFO -  at 79.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:23] {2218} INFO - iteration 259, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:24] {2391} INFO -  at 80.6s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:24] {2218} INFO - iteration 260, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:24] {2391} INFO -  at 80.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:24] {2218} INFO - iteration 261, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:25] {2391} INFO -  at 82.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:25] {2218} INFO - iteration 262, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:26] {2391} INFO -  at 82.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:26] {2218} INFO - iteration 263, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:26] {2391} INFO -  at 83.0s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:26] {2218} INFO - iteration 264, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:28] {2391} INFO -  at 84.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:28] {2218} INFO - iteration 265, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:28] {2391} INFO -  at 84.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:28] {2218} INFO - iteration 266, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:28] {2391} INFO -  at 84.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:28] {2218} INFO - iteration 267, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:28] {2391} INFO -  at 84.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:28] {2218} INFO - iteration 268, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:29] {2391} INFO -  at 85.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:29] {2218} INFO - iteration 269, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:29] {2391} INFO -  at 85.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:29] {2218} INFO - iteration 270, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:29] {2391} INFO -  at 86.0s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:29] {2218} INFO - iteration 271, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:31] {2391} INFO -  at 87.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:31] {2218} INFO - iteration 272, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:31] {2391} INFO -  at 88.2s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:31] {2218} INFO - iteration 273, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:32] {2391} INFO -  at 88.6s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:32] {2218} INFO - iteration 274, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:32] {2391} INFO -  at 89.1s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:32] {2218} INFO - iteration 275, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:33] {2391} INFO -  at 89.5s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:33] {2218} INFO - iteration 276, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:33] {2391} INFO -  at 89.8s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:33] {2218} INFO - iteration 277, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:34] {2391} INFO -  at 90.6s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:34] {2218} INFO - iteration 278, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:34] {2391} INFO -  at 91.0s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:34] {2218} INFO - iteration 279, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:34] {2391} INFO -  at 91.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:34] {2218} INFO - iteration 280, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2391} INFO -  at 92.4s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2218} INFO - iteration 281, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2391} INFO -  at 92.5s,\testimator lgbm's best error=0.0927,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2218} INFO - iteration 282, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2391} INFO -  at 92.8s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2218} INFO - iteration 283, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2391} INFO -  at 92.9s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2218} INFO - iteration 284, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2391} INFO -  at 93.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2218} INFO - iteration 285, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2391} INFO -  at 93.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2218} INFO - iteration 286, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2391} INFO -  at 93.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:36] {2218} INFO - iteration 287, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2391} INFO -  at 93.5s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2218} INFO - iteration 288, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2391} INFO -  at 93.6s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2218} INFO - iteration 289, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2391} INFO -  at 93.8s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2218} INFO - iteration 290, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2391} INFO -  at 93.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2218} INFO - iteration 291, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2391} INFO -  at 94.1s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2218} INFO - iteration 292, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2391} INFO -  at 94.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2218} INFO - iteration 293, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2391} INFO -  at 94.3s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:37] {2218} INFO - iteration 294, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:38] {2391} INFO -  at 94.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:38] {2218} INFO - iteration 295, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:38] {2391} INFO -  at 95.3s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:38] {2218} INFO - iteration 296, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:40] {2391} INFO -  at 97.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:40] {2218} INFO - iteration 297, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:40] {2391} INFO -  at 97.2s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:40] {2218} INFO - iteration 298, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2391} INFO -  at 97.5s,\testimator rf's best error=0.0922,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2218} INFO - iteration 299, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2391} INFO -  at 97.6s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2218} INFO - iteration 300, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2391} INFO -  at 97.7s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2218} INFO - iteration 301, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2391} INFO -  at 97.9s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2218} INFO - iteration 302, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2391} INFO -  at 98.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2218} INFO - iteration 303, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2391} INFO -  at 98.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:41] {2218} INFO - iteration 304, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2391} INFO -  at 98.4s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2218} INFO - iteration 305, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2391} INFO -  at 98.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2218} INFO - iteration 306, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2391} INFO -  at 98.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2218} INFO - iteration 307, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2391} INFO -  at 98.8s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2218} INFO - iteration 308, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2391} INFO -  at 98.9s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2218} INFO - iteration 309, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2391} INFO -  at 99.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:42] {2218} INFO - iteration 310, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:43] {2391} INFO -  at 99.5s,\testimator rf's best error=0.0919,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:43] {2218} INFO - iteration 311, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:43] {2391} INFO -  at 99.6s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:43] {2218} INFO - iteration 312, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:43] {2391} INFO -  at 99.8s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:43] {2218} INFO - iteration 313, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:43] {2391} INFO -  at 100.2s,\testimator xgboost's best error=0.0982,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:43] {2218} INFO - iteration 314, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:44] {2391} INFO -  at 101.2s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:44] {2218} INFO - iteration 315, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:45] {2391} INFO -  at 102.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:45] {2218} INFO - iteration 316, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:46] {2391} INFO -  at 102.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:46] {2218} INFO - iteration 317, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:46] {2391} INFO -  at 102.8s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:46] {2218} INFO - iteration 318, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:46] {2391} INFO -  at 102.9s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:46] {2218} INFO - iteration 319, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:46] {2391} INFO -  at 103.0s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:46] {2218} INFO - iteration 320, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:47] {2391} INFO -  at 103.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:47] {2218} INFO - iteration 321, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:47] {2391} INFO -  at 104.1s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:47] {2218} INFO - iteration 322, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:48] {2391} INFO -  at 104.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:48] {2218} INFO - iteration 323, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:49] {2391} INFO -  at 105.5s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:49] {2218} INFO - iteration 324, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:51] {2391} INFO -  at 107.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:51] {2218} INFO - iteration 325, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:52] {2391} INFO -  at 108.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:52] {2218} INFO - iteration 326, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:52] {2391} INFO -  at 109.1s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:52] {2218} INFO - iteration 327, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:52] {2391} INFO -  at 109.4s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:53] {2218} INFO - iteration 328, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:53] {2391} INFO -  at 109.5s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:53] {2218} INFO - iteration 329, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:53] {2391} INFO -  at 110.3s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:53] {2218} INFO - iteration 330, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:54] {2391} INFO -  at 110.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:54] {2218} INFO - iteration 331, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:54] {2391} INFO -  at 111.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:54] {2218} INFO - iteration 332, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:54] {2391} INFO -  at 111.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:54] {2218} INFO - iteration 333, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2391} INFO -  at 111.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2218} INFO - iteration 334, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2391} INFO -  at 111.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2218} INFO - iteration 335, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2391} INFO -  at 111.7s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2218} INFO - iteration 336, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2391} INFO -  at 111.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2218} INFO - iteration 337, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2391} INFO -  at 112.0s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2218} INFO - iteration 338, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2391} INFO -  at 112.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:55] {2218} INFO - iteration 339, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:02:56] {2391} INFO -  at 112.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:56] {2218} INFO - iteration 340, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:02:56] {2391} INFO -  at 112.9s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:56] {2218} INFO - iteration 341, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:02:57] {2391} INFO -  at 114.1s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:57] {2218} INFO - iteration 342, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:58] {2391} INFO -  at 114.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:58] {2218} INFO - iteration 343, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:58] {2391} INFO -  at 115.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:58] {2218} INFO - iteration 344, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:02:59] {2391} INFO -  at 115.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:59] {2218} INFO - iteration 345, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:59] {2391} INFO -  at 116.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:59] {2218} INFO - iteration 346, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:02:59] {2391} INFO -  at 116.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:02:59] {2218} INFO - iteration 347, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:00] {2391} INFO -  at 117.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:00] {2218} INFO - iteration 348, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:00] {2391} INFO -  at 117.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:00] {2218} INFO - iteration 349, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:00] {2391} INFO -  at 117.3s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:00] {2218} INFO - iteration 350, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:01] {2391} INFO -  at 117.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:01] {2218} INFO - iteration 351, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:01] {2391} INFO -  at 117.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:01] {2218} INFO - iteration 352, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:01] {2391} INFO -  at 117.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:01] {2218} INFO - iteration 353, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2391} INFO -  at 119.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2218} INFO - iteration 354, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2391} INFO -  at 119.6s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2218} INFO - iteration 355, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2391} INFO -  at 119.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2218} INFO - iteration 356, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2391} INFO -  at 120.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2218} INFO - iteration 357, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2391} INFO -  at 120.1s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2218} INFO - iteration 358, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2391} INFO -  at 120.3s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:03] {2218} INFO - iteration 359, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:04] {2391} INFO -  at 120.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:04] {2218} INFO - iteration 360, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:04] {2391} INFO -  at 120.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:04] {2218} INFO - iteration 361, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:06] {2391} INFO -  at 122.4s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:06] {2218} INFO - iteration 362, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:06] {2391} INFO -  at 123.3s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:06] {2218} INFO - iteration 363, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:07] {2391} INFO -  at 124.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:07] {2218} INFO - iteration 364, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:07] {2391} INFO -  at 124.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:07] {2218} INFO - iteration 365, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2391} INFO -  at 124.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2218} INFO - iteration 366, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2391} INFO -  at 124.8s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2218} INFO - iteration 367, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2391} INFO -  at 124.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2218} INFO - iteration 368, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2391} INFO -  at 125.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2218} INFO - iteration 369, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2391} INFO -  at 125.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:08] {2218} INFO - iteration 370, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2391} INFO -  at 125.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2218} INFO - iteration 371, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2391} INFO -  at 125.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2218} INFO - iteration 372, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2391} INFO -  at 125.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2218} INFO - iteration 373, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2391} INFO -  at 125.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2218} INFO - iteration 374, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2391} INFO -  at 126.0s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:09] {2218} INFO - iteration 375, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:10] {2391} INFO -  at 126.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:10] {2218} INFO - iteration 376, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:10] {2391} INFO -  at 126.8s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:10] {2218} INFO - iteration 377, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:11] {2391} INFO -  at 127.6s,\testimator lgbm's best error=0.0913,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:11] {2218} INFO - iteration 378, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:12] {2391} INFO -  at 128.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:12] {2218} INFO - iteration 379, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:12] {2391} INFO -  at 129.0s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:12] {2218} INFO - iteration 380, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:13] {2391} INFO -  at 130.0s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:13] {2218} INFO - iteration 381, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:13] {2391} INFO -  at 130.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:13] {2218} INFO - iteration 382, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:13] {2391} INFO -  at 130.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:13] {2218} INFO - iteration 383, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2391} INFO -  at 130.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2218} INFO - iteration 384, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2391} INFO -  at 130.6s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2218} INFO - iteration 385, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2391} INFO -  at 130.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2218} INFO - iteration 386, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2391} INFO -  at 130.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2218} INFO - iteration 387, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2391} INFO -  at 131.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2218} INFO - iteration 388, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:14] {2391} INFO -  at 131.4s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:15] {2218} INFO - iteration 389, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:15] {2391} INFO -  at 131.8s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:15] {2218} INFO - iteration 390, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:16] {2391} INFO -  at 132.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:16] {2218} INFO - iteration 391, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:17] {2391} INFO -  at 134.2s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:17] {2218} INFO - iteration 392, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:17] {2391} INFO -  at 134.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:17] {2218} INFO - iteration 393, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:18] {2391} INFO -  at 134.5s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:18] {2218} INFO - iteration 394, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:18] {2391} INFO -  at 134.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:18] {2218} INFO - iteration 395, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:18] {2391} INFO -  at 134.8s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:18] {2218} INFO - iteration 396, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:19] {2391} INFO -  at 135.6s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:19] {2218} INFO - iteration 397, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:20] {2391} INFO -  at 136.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:20] {2218} INFO - iteration 398, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:20] {2391} INFO -  at 136.7s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:20] {2218} INFO - iteration 399, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:20] {2391} INFO -  at 136.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:20] {2218} INFO - iteration 400, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:20] {2391} INFO -  at 137.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:20] {2218} INFO - iteration 401, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:21] {2391} INFO -  at 137.5s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:21] {2218} INFO - iteration 402, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:22] {2391} INFO -  at 138.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:22] {2218} INFO - iteration 403, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:22] {2391} INFO -  at 139.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:22] {2218} INFO - iteration 404, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:22] {2391} INFO -  at 139.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:22] {2218} INFO - iteration 405, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:23] {2391} INFO -  at 139.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:23] {2218} INFO - iteration 406, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:24] {2391} INFO -  at 140.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:24] {2218} INFO - iteration 407, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:24] {2391} INFO -  at 141.4s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:25] {2218} INFO - iteration 408, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:25] {2391} INFO -  at 141.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:25] {2218} INFO - iteration 409, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:25] {2391} INFO -  at 142.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2218} INFO - iteration 410, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2391} INFO -  at 142.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2218} INFO - iteration 411, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2391} INFO -  at 142.9s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2218} INFO - iteration 412, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2391} INFO -  at 143.0s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2218} INFO - iteration 413, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2391} INFO -  at 143.2s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:26] {2218} INFO - iteration 414, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:27] {2391} INFO -  at 143.8s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:27] {2218} INFO - iteration 415, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:27] {2391} INFO -  at 144.0s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:27] {2218} INFO - iteration 416, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:27] {2391} INFO -  at 144.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:27] {2218} INFO - iteration 417, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:29] {2391} INFO -  at 145.6s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:29] {2218} INFO - iteration 418, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:29] {2391} INFO -  at 145.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:29] {2218} INFO - iteration 419, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:30] {2391} INFO -  at 146.5s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:30] {2218} INFO - iteration 420, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:30] {2391} INFO -  at 147.1s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:30] {2218} INFO - iteration 421, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:30] {2391} INFO -  at 147.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:30] {2218} INFO - iteration 422, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2391} INFO -  at 147.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2218} INFO - iteration 423, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2391} INFO -  at 147.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2218} INFO - iteration 424, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2391} INFO -  at 148.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2218} INFO - iteration 425, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2391} INFO -  at 148.2s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2218} INFO - iteration 426, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2391} INFO -  at 148.3s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:31] {2218} INFO - iteration 427, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2391} INFO -  at 148.5s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2218} INFO - iteration 428, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2391} INFO -  at 148.6s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2218} INFO - iteration 429, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2391} INFO -  at 148.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2218} INFO - iteration 430, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2391} INFO -  at 148.9s,\testimator lgbm's best error=0.0855,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2218} INFO - iteration 431, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2391} INFO -  at 149.1s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2218} INFO - iteration 432, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2391} INFO -  at 149.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2218} INFO - iteration 433, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2391} INFO -  at 149.4s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:32] {2218} INFO - iteration 434, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:33] {2391} INFO -  at 149.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:33] {2218} INFO - iteration 435, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:33] {2391} INFO -  at 149.8s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:33] {2218} INFO - iteration 436, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:33] {2391} INFO -  at 150.0s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:33] {2218} INFO - iteration 437, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:34] {2391} INFO -  at 151.0s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:34] {2218} INFO - iteration 438, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:35] {2391} INFO -  at 151.5s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:35] {2218} INFO - iteration 439, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:35] {2391} INFO -  at 152.2s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:35] {2218} INFO - iteration 440, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:35] {2391} INFO -  at 152.3s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:35] {2218} INFO - iteration 441, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:36] {2391} INFO -  at 152.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:36] {2218} INFO - iteration 442, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:36] {2391} INFO -  at 152.6s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:36] {2218} INFO - iteration 443, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:36] {2391} INFO -  at 152.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:36] {2218} INFO - iteration 444, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:37] {2391} INFO -  at 153.6s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:37] {2218} INFO - iteration 445, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:37] {2391} INFO -  at 154.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:37] {2218} INFO - iteration 446, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:38] {2391} INFO -  at 154.8s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:38] {2218} INFO - iteration 447, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:39] {2391} INFO -  at 155.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:39] {2218} INFO - iteration 448, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:39] {2391} INFO -  at 156.1s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:39] {2218} INFO - iteration 449, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:39] {2391} INFO -  at 156.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:39] {2218} INFO - iteration 450, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:40] {2391} INFO -  at 156.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:40] {2218} INFO - iteration 451, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:41] {2391} INFO -  at 158.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:41] {2218} INFO - iteration 452, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:41] {2391} INFO -  at 158.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:41] {2218} INFO - iteration 453, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2391} INFO -  at 158.6s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2218} INFO - iteration 454, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2391} INFO -  at 158.7s,\testimator lgbm's best error=0.0849,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2218} INFO - iteration 455, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2391} INFO -  at 159.0s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2218} INFO - iteration 456, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2391} INFO -  at 159.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2218} INFO - iteration 457, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2391} INFO -  at 159.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:42] {2218} INFO - iteration 458, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2391} INFO -  at 159.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2218} INFO - iteration 459, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2391} INFO -  at 159.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2218} INFO - iteration 460, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2391} INFO -  at 159.7s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2218} INFO - iteration 461, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2391} INFO -  at 159.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2218} INFO - iteration 462, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2391} INFO -  at 160.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2218} INFO - iteration 463, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:43] {2391} INFO -  at 160.4s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:44] {2218} INFO - iteration 464, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:44] {2391} INFO -  at 160.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:44] {2218} INFO - iteration 465, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:44] {2391} INFO -  at 160.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:44] {2218} INFO - iteration 466, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:44] {2391} INFO -  at 161.3s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:44] {2218} INFO - iteration 467, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:45] {2391} INFO -  at 161.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:45] {2218} INFO - iteration 468, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:45] {2391} INFO -  at 161.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:45] {2218} INFO - iteration 469, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:03:47] {2391} INFO -  at 163.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:47] {2218} INFO - iteration 470, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:47] {2391} INFO -  at 163.9s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:47] {2218} INFO - iteration 471, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:47] {2391} INFO -  at 164.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:47] {2218} INFO - iteration 472, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:48] {2391} INFO -  at 164.4s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:48] {2218} INFO - iteration 473, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:48] {2391} INFO -  at 164.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:48] {2218} INFO - iteration 474, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:48] {2391} INFO -  at 165.0s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:48] {2218} INFO - iteration 475, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:48] {2391} INFO -  at 165.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:48] {2218} INFO - iteration 476, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:49] {2391} INFO -  at 165.4s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:49] {2218} INFO - iteration 477, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:49] {2391} INFO -  at 165.6s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:49] {2218} INFO - iteration 478, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:50] {2391} INFO -  at 166.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:50] {2218} INFO - iteration 479, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:51] {2391} INFO -  at 167.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:51] {2218} INFO - iteration 480, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:52] {2391} INFO -  at 168.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:52] {2218} INFO - iteration 481, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:52] {2391} INFO -  at 168.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:52] {2218} INFO - iteration 482, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:52] {2391} INFO -  at 169.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:52] {2218} INFO - iteration 483, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:53] {2391} INFO -  at 169.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:53] {2218} INFO - iteration 484, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:53] {2391} INFO -  at 170.0s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:53] {2218} INFO - iteration 485, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:54] {2391} INFO -  at 170.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:54] {2218} INFO - iteration 486, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:54] {2391} INFO -  at 170.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:54] {2218} INFO - iteration 487, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2391} INFO -  at 171.4s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2218} INFO - iteration 488, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2391} INFO -  at 171.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2218} INFO - iteration 489, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2391} INFO -  at 171.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2218} INFO - iteration 490, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2391} INFO -  at 171.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2218} INFO - iteration 491, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2391} INFO -  at 172.0s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2218} INFO - iteration 492, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2391} INFO -  at 172.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:55] {2218} INFO - iteration 493, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:56] {2391} INFO -  at 172.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:56] {2218} INFO - iteration 494, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:56] {2391} INFO -  at 172.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:56] {2218} INFO - iteration 495, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:03:56] {2391} INFO -  at 173.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:56] {2218} INFO - iteration 496, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:56] {2391} INFO -  at 173.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:56] {2218} INFO - iteration 497, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2391} INFO -  at 173.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2218} INFO - iteration 498, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2391} INFO -  at 173.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2218} INFO - iteration 499, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2391} INFO -  at 173.9s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2218} INFO - iteration 500, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2391} INFO -  at 174.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2218} INFO - iteration 501, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2391} INFO -  at 174.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2218} INFO - iteration 502, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2391} INFO -  at 174.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:57] {2218} INFO - iteration 503, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:03:58] {2391} INFO -  at 174.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:58] {2218} INFO - iteration 504, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:58] {2391} INFO -  at 174.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:58] {2218} INFO - iteration 505, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:58] {2391} INFO -  at 175.0s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:58] {2218} INFO - iteration 506, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:58] {2391} INFO -  at 175.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:58] {2218} INFO - iteration 507, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:59] {2391} INFO -  at 175.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:59] {2218} INFO - iteration 508, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:03:59] {2391} INFO -  at 175.6s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:59] {2218} INFO - iteration 509, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:03:59] {2391} INFO -  at 175.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:03:59] {2218} INFO - iteration 510, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:00] {2391} INFO -  at 176.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:00] {2218} INFO - iteration 511, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:04:01] {2391} INFO -  at 178.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:01] {2218} INFO - iteration 512, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:02] {2391} INFO -  at 178.6s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:02] {2218} INFO - iteration 513, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:02] {2391} INFO -  at 178.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:02] {2218} INFO - iteration 514, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:02] {2391} INFO -  at 179.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:02] {2218} INFO - iteration 515, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:02] {2391} INFO -  at 179.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:02] {2218} INFO - iteration 516, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:03] {2391} INFO -  at 180.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:03] {2218} INFO - iteration 517, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:04] {2391} INFO -  at 180.8s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:04] {2218} INFO - iteration 518, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:05] {2391} INFO -  at 181.8s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:05] {2218} INFO - iteration 519, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:05] {2391} INFO -  at 182.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:05] {2218} INFO - iteration 520, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:06] {2391} INFO -  at 182.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:06] {2218} INFO - iteration 521, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:06] {2391} INFO -  at 182.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:06] {2218} INFO - iteration 522, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:06] {2391} INFO -  at 183.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:06] {2218} INFO - iteration 523, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:06] {2391} INFO -  at 183.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:06] {2218} INFO - iteration 524, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2391} INFO -  at 183.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2218} INFO - iteration 525, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2391} INFO -  at 183.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2218} INFO - iteration 526, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2391} INFO -  at 183.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2218} INFO - iteration 527, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2391} INFO -  at 183.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2218} INFO - iteration 528, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2391} INFO -  at 184.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2218} INFO - iteration 529, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2391} INFO -  at 184.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:07] {2218} INFO - iteration 530, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:08] {2391} INFO -  at 184.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:08] {2218} INFO - iteration 531, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:08] {2391} INFO -  at 184.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:08] {2218} INFO - iteration 532, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:09] {2391} INFO -  at 185.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:09] {2218} INFO - iteration 533, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2391} INFO -  at 186.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2218} INFO - iteration 534, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2391} INFO -  at 186.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2218} INFO - iteration 535, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:10] {2391} INFO -  at 186.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2218} INFO - iteration 536, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:10] {2391} INFO -  at 187.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2218} INFO - iteration 537, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2391} INFO -  at 187.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2218} INFO - iteration 538, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:10] {2391} INFO -  at 187.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:10] {2218} INFO - iteration 539, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:11] {2391} INFO -  at 187.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:11] {2218} INFO - iteration 540, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:11] {2391} INFO -  at 187.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:11] {2218} INFO - iteration 541, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:11] {2391} INFO -  at 187.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:11] {2218} INFO - iteration 542, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:11] {2391} INFO -  at 188.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:11] {2218} INFO - iteration 543, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:11] {2391} INFO -  at 188.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:11] {2218} INFO - iteration 544, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:11] {2391} INFO -  at 188.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:11] {2218} INFO - iteration 545, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2391} INFO -  at 188.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2218} INFO - iteration 546, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2391} INFO -  at 188.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2218} INFO - iteration 547, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:12] {2391} INFO -  at 188.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2218} INFO - iteration 548, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:12] {2391} INFO -  at 189.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2218} INFO - iteration 549, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2391} INFO -  at 189.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2218} INFO - iteration 550, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:12] {2391} INFO -  at 189.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:12] {2218} INFO - iteration 551, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:13] {2391} INFO -  at 189.6s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:13] {2218} INFO - iteration 552, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:13] {2391} INFO -  at 189.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:13] {2218} INFO - iteration 553, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:13] {2391} INFO -  at 189.9s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:13] {2218} INFO - iteration 554, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:13] {2391} INFO -  at 190.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:13] {2218} INFO - iteration 555, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:13] {2391} INFO -  at 190.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:13] {2218} INFO - iteration 556, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:04:14] {2391} INFO -  at 191.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:14] {2218} INFO - iteration 557, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:14] {2391} INFO -  at 191.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:14] {2218} INFO - iteration 558, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:14] {2391} INFO -  at 191.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:14] {2218} INFO - iteration 559, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:15] {2391} INFO -  at 191.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:15] {2218} INFO - iteration 560, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:15] {2391} INFO -  at 191.9s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:15] {2218} INFO - iteration 561, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:15] {2391} INFO -  at 192.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:15] {2218} INFO - iteration 562, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:15] {2391} INFO -  at 192.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:15] {2218} INFO - iteration 563, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:16] {2391} INFO -  at 192.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:16] {2218} INFO - iteration 564, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:16] {2391} INFO -  at 192.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:16] {2218} INFO - iteration 565, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:16] {2391} INFO -  at 193.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:16] {2218} INFO - iteration 566, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:17] {2391} INFO -  at 193.9s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:17] {2218} INFO - iteration 567, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:18] {2391} INFO -  at 194.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:18] {2218} INFO - iteration 568, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:18] {2391} INFO -  at 194.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:18] {2218} INFO - iteration 569, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:19] {2391} INFO -  at 195.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:19] {2218} INFO - iteration 570, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:19] {2391} INFO -  at 195.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:19] {2218} INFO - iteration 571, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:19] {2391} INFO -  at 196.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:19] {2218} INFO - iteration 572, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:19] {2391} INFO -  at 196.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:19] {2218} INFO - iteration 573, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2391} INFO -  at 196.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2218} INFO - iteration 574, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:20] {2391} INFO -  at 196.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2218} INFO - iteration 575, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:20] {2391} INFO -  at 196.8s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2218} INFO - iteration 576, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2391} INFO -  at 196.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2218} INFO - iteration 577, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2391} INFO -  at 197.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2218} INFO - iteration 578, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:20] {2391} INFO -  at 197.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:20] {2218} INFO - iteration 579, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:21] {2391} INFO -  at 197.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2218} INFO - iteration 580, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:21] {2391} INFO -  at 197.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2218} INFO - iteration 581, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2391} INFO -  at 197.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2218} INFO - iteration 582, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2391} INFO -  at 198.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2218} INFO - iteration 583, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2391} INFO -  at 198.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2218} INFO - iteration 584, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2391} INFO -  at 198.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:21] {2218} INFO - iteration 585, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:22] {2391} INFO -  at 198.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:22] {2218} INFO - iteration 586, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:22] {2391} INFO -  at 198.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:22] {2218} INFO - iteration 587, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:22] {2391} INFO -  at 199.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:22] {2218} INFO - iteration 588, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:22] {2391} INFO -  at 199.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:22] {2218} INFO - iteration 589, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:23] {2391} INFO -  at 199.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:23] {2218} INFO - iteration 590, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:23] {2391} INFO -  at 199.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:23] {2218} INFO - iteration 591, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:23] {2391} INFO -  at 199.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:23] {2218} INFO - iteration 592, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:23] {2391} INFO -  at 200.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:23] {2218} INFO - iteration 593, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:23] {2391} INFO -  at 200.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:23] {2218} INFO - iteration 594, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:24] {2391} INFO -  at 201.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:24] {2218} INFO - iteration 595, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:24] {2391} INFO -  at 201.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:24] {2218} INFO - iteration 596, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:25] {2391} INFO -  at 201.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:25] {2218} INFO - iteration 597, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:25] {2391} INFO -  at 201.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:25] {2218} INFO - iteration 598, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:25] {2391} INFO -  at 201.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:25] {2218} INFO - iteration 599, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:25] {2391} INFO -  at 202.3s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:25] {2218} INFO - iteration 600, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:26] {2391} INFO -  at 203.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:26] {2218} INFO - iteration 601, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:27] {2391} INFO -  at 203.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:27] {2218} INFO - iteration 602, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:27] {2391} INFO -  at 204.0s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:27] {2218} INFO - iteration 603, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:27] {2391} INFO -  at 204.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:27] {2218} INFO - iteration 604, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:28] {2391} INFO -  at 204.4s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:28] {2218} INFO - iteration 605, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:28] {2391} INFO -  at 204.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:28] {2218} INFO - iteration 606, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:28] {2391} INFO -  at 204.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:28] {2218} INFO - iteration 607, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:28] {2391} INFO -  at 204.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:28] {2218} INFO - iteration 608, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:28] {2391} INFO -  at 205.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:28] {2218} INFO - iteration 609, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:29] {2391} INFO -  at 206.1s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:29] {2218} INFO - iteration 610, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:30] {2391} INFO -  at 206.8s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:30] {2218} INFO - iteration 611, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:30] {2391} INFO -  at 207.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:30] {2218} INFO - iteration 612, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:30] {2391} INFO -  at 207.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:30] {2218} INFO - iteration 613, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:31] {2391} INFO -  at 207.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:31] {2218} INFO - iteration 614, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:32] {2391} INFO -  at 209.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:32] {2218} INFO - iteration 615, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:33] {2391} INFO -  at 209.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:33] {2218} INFO - iteration 616, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:33] {2391} INFO -  at 209.8s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:33] {2218} INFO - iteration 617, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:33] {2391} INFO -  at 210.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:33] {2218} INFO - iteration 618, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:33] {2391} INFO -  at 210.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:33] {2218} INFO - iteration 619, current learner extra_tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:35] {2391} INFO -  at 211.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:35] {2218} INFO - iteration 620, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:36] {2391} INFO -  at 213.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:36] {2218} INFO - iteration 621, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:36] {2391} INFO -  at 213.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:36] {2218} INFO - iteration 622, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:37] {2391} INFO -  at 213.6s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:37] {2218} INFO - iteration 623, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:37] {2391} INFO -  at 214.3s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:37] {2218} INFO - iteration 624, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:38] {2391} INFO -  at 214.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:38] {2218} INFO - iteration 625, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:38] {2391} INFO -  at 214.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:38] {2218} INFO - iteration 626, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:38] {2391} INFO -  at 214.8s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:38] {2218} INFO - iteration 627, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:38] {2391} INFO -  at 215.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:38] {2218} INFO - iteration 628, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:39] {2391} INFO -  at 215.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:39] {2218} INFO - iteration 629, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:39] {2391} INFO -  at 215.7s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:39] {2218} INFO - iteration 630, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:39] {2391} INFO -  at 215.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:39] {2218} INFO - iteration 631, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:40] {2391} INFO -  at 216.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:40] {2218} INFO - iteration 632, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:40] {2391} INFO -  at 216.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:40] {2218} INFO - iteration 633, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:40] {2391} INFO -  at 217.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:40] {2218} INFO - iteration 634, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:40] {2391} INFO -  at 217.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:40] {2218} INFO - iteration 635, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2391} INFO -  at 217.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2218} INFO - iteration 636, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2391} INFO -  at 217.5s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2218} INFO - iteration 637, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2391} INFO -  at 217.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2218} INFO - iteration 638, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:41] {2391} INFO -  at 217.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2218} INFO - iteration 639, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:41] {2391} INFO -  at 218.0s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2218} INFO - iteration 640, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2391} INFO -  at 218.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2218} INFO - iteration 641, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:41] {2391} INFO -  at 218.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:41] {2218} INFO - iteration 642, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:42] {2391} INFO -  at 218.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:42] {2218} INFO - iteration 643, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:42] {2391} INFO -  at 219.0s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:42] {2218} INFO - iteration 644, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:42] {2391} INFO -  at 219.2s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:42] {2218} INFO - iteration 645, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:43] {2391} INFO -  at 219.4s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:43] {2218} INFO - iteration 646, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:43] {2391} INFO -  at 219.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:43] {2218} INFO - iteration 647, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:43] {2391} INFO -  at 219.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:43] {2218} INFO - iteration 648, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:43] {2391} INFO -  at 220.3s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:43] {2218} INFO - iteration 649, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:44] {2391} INFO -  at 221.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:44] {2218} INFO - iteration 650, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:04:46] {2391} INFO -  at 222.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:46] {2218} INFO - iteration 651, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:46] {2391} INFO -  at 223.2s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:46] {2218} INFO - iteration 652, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:47] {2391} INFO -  at 223.8s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:47] {2218} INFO - iteration 653, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:47] {2391} INFO -  at 224.2s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:47] {2218} INFO - iteration 654, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:04:48] {2391} INFO -  at 224.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:48] {2218} INFO - iteration 655, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2391} INFO -  at 225.5s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2218} INFO - iteration 656, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2391} INFO -  at 225.6s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2218} INFO - iteration 657, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2391} INFO -  at 225.8s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2218} INFO - iteration 658, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2391} INFO -  at 226.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2218} INFO - iteration 659, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:49] {2391} INFO -  at 226.2s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2218} INFO - iteration 660, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2391} INFO -  at 226.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:49] {2218} INFO - iteration 661, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:50] {2391} INFO -  at 226.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:50] {2218} INFO - iteration 662, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:50] {2391} INFO -  at 227.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:50] {2218} INFO - iteration 663, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:50] {2391} INFO -  at 227.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:50] {2218} INFO - iteration 664, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:51] {2391} INFO -  at 227.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:51] {2218} INFO - iteration 665, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:51] {2391} INFO -  at 228.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:51] {2218} INFO - iteration 666, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:04:53] {2391} INFO -  at 230.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:53] {2218} INFO - iteration 667, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:53] {2391} INFO -  at 230.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:53] {2218} INFO - iteration 668, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:53] {2391} INFO -  at 230.4s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:53] {2218} INFO - iteration 669, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:04:54] {2391} INFO -  at 230.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:54] {2218} INFO - iteration 670, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:04:54] {2391} INFO -  at 231.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:54] {2218} INFO - iteration 671, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:55] {2391} INFO -  at 231.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:55] {2218} INFO - iteration 672, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:55] {2391} INFO -  at 231.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:55] {2218} INFO - iteration 673, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:55] {2391} INFO -  at 232.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:55] {2218} INFO - iteration 674, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2391} INFO -  at 232.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2218} INFO - iteration 675, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:56] {2391} INFO -  at 232.6s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2218} INFO - iteration 676, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2391} INFO -  at 232.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2218} INFO - iteration 677, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:56] {2391} INFO -  at 232.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2218} INFO - iteration 678, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2391} INFO -  at 233.1s,\testimator xgboost's best error=0.0850,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2218} INFO - iteration 679, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2391} INFO -  at 233.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:56] {2218} INFO - iteration 680, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:57] {2391} INFO -  at 233.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:57] {2218} INFO - iteration 681, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:57] {2391} INFO -  at 233.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:57] {2218} INFO - iteration 682, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:04:59] {2391} INFO -  at 235.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:59] {2218} INFO - iteration 683, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:04:59] {2391} INFO -  at 236.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:59] {2218} INFO - iteration 684, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:04:59] {2391} INFO -  at 236.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:04:59] {2218} INFO - iteration 685, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:00] {2391} INFO -  at 236.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:00] {2218} INFO - iteration 686, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:00] {2391} INFO -  at 236.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:00] {2218} INFO - iteration 687, current learner extra_tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:01] {2391} INFO -  at 237.4s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2218} INFO - iteration 688, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2391} INFO -  at 237.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2218} INFO - iteration 689, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2391} INFO -  at 237.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2218} INFO - iteration 690, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:01] {2391} INFO -  at 238.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2218} INFO - iteration 691, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2391} INFO -  at 238.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2218} INFO - iteration 692, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:01] {2391} INFO -  at 238.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:01] {2218} INFO - iteration 693, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:02] {2391} INFO -  at 238.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2218} INFO - iteration 694, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2391} INFO -  at 238.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2218} INFO - iteration 695, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2391} INFO -  at 238.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2218} INFO - iteration 696, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2391} INFO -  at 239.2s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2218} INFO - iteration 697, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2391} INFO -  at 239.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:02] {2218} INFO - iteration 698, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:03] {2391} INFO -  at 239.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:03] {2218} INFO - iteration 699, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:03] {2391} INFO -  at 240.1s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:03] {2218} INFO - iteration 700, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:03] {2391} INFO -  at 240.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:03] {2218} INFO - iteration 701, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:04] {2391} INFO -  at 241.0s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:04] {2218} INFO - iteration 702, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:04] {2391} INFO -  at 241.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:04] {2218} INFO - iteration 703, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:04] {2391} INFO -  at 241.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:04] {2218} INFO - iteration 704, current learner extra_tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:06] {2391} INFO -  at 242.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:06] {2218} INFO - iteration 705, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:06] {2391} INFO -  at 242.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:06] {2218} INFO - iteration 706, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:06] {2391} INFO -  at 243.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:06] {2218} INFO - iteration 707, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:06] {2391} INFO -  at 243.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:06] {2218} INFO - iteration 708, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2391} INFO -  at 243.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2218} INFO - iteration 709, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2391} INFO -  at 243.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2218} INFO - iteration 710, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2391} INFO -  at 243.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2218} INFO - iteration 711, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2391} INFO -  at 243.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2218} INFO - iteration 712, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2391} INFO -  at 244.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2218} INFO - iteration 713, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:07] {2391} INFO -  at 244.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:07] {2218} INFO - iteration 714, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:08] {2391} INFO -  at 244.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:08] {2218} INFO - iteration 715, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:08] {2391} INFO -  at 244.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:08] {2218} INFO - iteration 716, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:09] {2391} INFO -  at 245.5s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:09] {2218} INFO - iteration 717, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:05:09] {2391} INFO -  at 246.1s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:09] {2218} INFO - iteration 718, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:09] {2391} INFO -  at 246.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:09] {2218} INFO - iteration 719, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:10] {2391} INFO -  at 246.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:10] {2218} INFO - iteration 720, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:10] {2391} INFO -  at 246.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:10] {2218} INFO - iteration 721, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:11] {2391} INFO -  at 247.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:11] {2218} INFO - iteration 722, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:11] {2391} INFO -  at 247.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:11] {2218} INFO - iteration 723, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:11] {2391} INFO -  at 248.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:11] {2218} INFO - iteration 724, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:12] {2391} INFO -  at 249.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:12] {2218} INFO - iteration 725, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2391} INFO -  at 249.6s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2218} INFO - iteration 726, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2391} INFO -  at 249.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2218} INFO - iteration 727, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2391} INFO -  at 250.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2218} INFO - iteration 728, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:13] {2391} INFO -  at 250.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2218} INFO - iteration 729, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2391} INFO -  at 250.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:13] {2218} INFO - iteration 730, current learner extra_tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:15] {2391} INFO -  at 252.2s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:15] {2218} INFO - iteration 731, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:05:16] {2391} INFO -  at 253.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:16] {2218} INFO - iteration 732, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:16] {2391} INFO -  at 253.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:16] {2218} INFO - iteration 733, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:17] {2391} INFO -  at 253.4s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:17] {2218} INFO - iteration 734, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:17] {2391} INFO -  at 253.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:17] {2218} INFO - iteration 735, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:17] {2391} INFO -  at 253.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:17] {2218} INFO - iteration 736, current learner extra_tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:18] {2391} INFO -  at 255.2s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:18] {2218} INFO - iteration 737, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:19] {2391} INFO -  at 255.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:19] {2218} INFO - iteration 738, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:19] {2391} INFO -  at 255.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:19] {2218} INFO - iteration 739, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:20] {2391} INFO -  at 256.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:20] {2218} INFO - iteration 740, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:20] {2391} INFO -  at 257.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:20] {2218} INFO - iteration 741, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:05:21] {2391} INFO -  at 257.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:21] {2218} INFO - iteration 742, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:21] {2391} INFO -  at 257.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:21] {2218} INFO - iteration 743, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:21] {2391} INFO -  at 258.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:21] {2218} INFO - iteration 744, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:21] {2391} INFO -  at 258.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:21] {2218} INFO - iteration 745, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:22] {2391} INFO -  at 258.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:22] {2218} INFO - iteration 746, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:22] {2391} INFO -  at 258.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:22] {2218} INFO - iteration 747, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:22] {2391} INFO -  at 259.0s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:22] {2218} INFO - iteration 748, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:22] {2391} INFO -  at 259.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:22] {2218} INFO - iteration 749, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:22] {2391} INFO -  at 259.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:22] {2218} INFO - iteration 750, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:23] {2391} INFO -  at 259.5s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:23] {2218} INFO - iteration 751, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:23] {2391} INFO -  at 259.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:23] {2218} INFO - iteration 752, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:23] {2391} INFO -  at 259.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:23] {2218} INFO - iteration 753, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:24] {2391} INFO -  at 261.1s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:24] {2218} INFO - iteration 754, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:25] {2391} INFO -  at 261.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:25] {2218} INFO - iteration 755, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:25] {2391} INFO -  at 261.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:25] {2218} INFO - iteration 756, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:25] {2391} INFO -  at 262.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:25] {2218} INFO - iteration 757, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:26] {2391} INFO -  at 262.9s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:26] {2218} INFO - iteration 758, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:26] {2391} INFO -  at 263.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:26] {2218} INFO - iteration 759, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:26] {2391} INFO -  at 263.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:26] {2218} INFO - iteration 760, current learner extra_tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:28] {2391} INFO -  at 265.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:28] {2218} INFO - iteration 761, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:28] {2391} INFO -  at 265.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:28] {2218} INFO - iteration 762, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:29] {2391} INFO -  at 265.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:29] {2218} INFO - iteration 763, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:29] {2391} INFO -  at 265.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:29] {2218} INFO - iteration 764, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:29] {2391} INFO -  at 265.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:29] {2218} INFO - iteration 765, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:05:30] {2391} INFO -  at 267.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:30] {2218} INFO - iteration 766, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2391} INFO -  at 267.6s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2218} INFO - iteration 767, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2391} INFO -  at 267.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2218} INFO - iteration 768, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:31] {2391} INFO -  at 267.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2218} INFO - iteration 769, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2391} INFO -  at 268.1s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2218} INFO - iteration 770, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2391} INFO -  at 268.4s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:31] {2218} INFO - iteration 771, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:32] {2391} INFO -  at 268.6s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:32] {2218} INFO - iteration 772, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:32] {2391} INFO -  at 268.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:32] {2218} INFO - iteration 773, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:05:33] {2391} INFO -  at 269.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:33] {2218} INFO - iteration 774, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:33] {2391} INFO -  at 269.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:33] {2218} INFO - iteration 775, current learner extra_tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:35] {2391} INFO -  at 271.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:35] {2218} INFO - iteration 776, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:35] {2391} INFO -  at 271.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:35] {2218} INFO - iteration 777, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:35] {2391} INFO -  at 272.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:35] {2218} INFO - iteration 778, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:35] {2391} INFO -  at 272.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:35] {2218} INFO - iteration 779, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:35] {2391} INFO -  at 272.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:35] {2218} INFO - iteration 780, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:36] {2391} INFO -  at 272.5s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:36] {2218} INFO - iteration 781, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:36] {2391} INFO -  at 273.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:36] {2218} INFO - iteration 782, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:37] {2391} INFO -  at 273.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:37] {2218} INFO - iteration 783, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:37] {2391} INFO -  at 274.0s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:37] {2218} INFO - iteration 784, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:38] {2391} INFO -  at 275.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:38] {2218} INFO - iteration 785, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:39] {2391} INFO -  at 276.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:39] {2218} INFO - iteration 786, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:39] {2391} INFO -  at 276.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:39] {2218} INFO - iteration 787, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:40] {2391} INFO -  at 276.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:40] {2218} INFO - iteration 788, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:40] {2391} INFO -  at 276.7s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:40] {2218} INFO - iteration 789, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:40] {2391} INFO -  at 276.9s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:40] {2218} INFO - iteration 790, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:40] {2391} INFO -  at 277.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:40] {2218} INFO - iteration 791, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:40] {2391} INFO -  at 277.3s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:40] {2218} INFO - iteration 792, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:41] {2391} INFO -  at 277.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:41] {2218} INFO - iteration 793, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:41] {2391} INFO -  at 277.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:41] {2218} INFO - iteration 794, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:41] {2391} INFO -  at 278.3s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:41] {2218} INFO - iteration 795, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2391} INFO -  at 278.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2218} INFO - iteration 796, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:42] {2391} INFO -  at 278.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2218} INFO - iteration 797, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2391} INFO -  at 278.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2218} INFO - iteration 798, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2391} INFO -  at 278.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2218} INFO - iteration 799, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2391} INFO -  at 279.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:42] {2218} INFO - iteration 800, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:43] {2391} INFO -  at 279.8s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:43] {2218} INFO - iteration 801, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:43] {2391} INFO -  at 280.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:43] {2218} INFO - iteration 802, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:43] {2391} INFO -  at 280.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:43] {2218} INFO - iteration 803, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:05:44] {2391} INFO -  at 280.8s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:44] {2218} INFO - iteration 804, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:44] {2391} INFO -  at 281.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:44] {2218} INFO - iteration 805, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:44] {2391} INFO -  at 281.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:44] {2218} INFO - iteration 806, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:44] {2391} INFO -  at 281.3s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:44] {2218} INFO - iteration 807, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:45] {2391} INFO -  at 281.9s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:45] {2218} INFO - iteration 808, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:45] {2391} INFO -  at 282.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:45] {2218} INFO - iteration 809, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:45] {2391} INFO -  at 282.2s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:45] {2218} INFO - iteration 810, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:46] {2391} INFO -  at 282.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:46] {2218} INFO - iteration 811, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:46] {2391} INFO -  at 282.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:46] {2218} INFO - iteration 812, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:47] {2391} INFO -  at 283.4s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:47] {2218} INFO - iteration 813, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:47] {2391} INFO -  at 283.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:47] {2218} INFO - iteration 814, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:47] {2391} INFO -  at 283.8s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:47] {2218} INFO - iteration 815, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:47] {2391} INFO -  at 284.3s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:47] {2218} INFO - iteration 816, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:48] {2391} INFO -  at 284.7s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:48] {2218} INFO - iteration 817, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:48] {2391} INFO -  at 284.9s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:48] {2218} INFO - iteration 818, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:48] {2391} INFO -  at 285.1s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:48] {2218} INFO - iteration 819, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:48] {2391} INFO -  at 285.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:48] {2218} INFO - iteration 820, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:49] {2391} INFO -  at 285.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:49] {2218} INFO - iteration 821, current learner lgbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:49] {2391} INFO -  at 285.8s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:49] {2218} INFO - iteration 822, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:49] {2391} INFO -  at 286.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:49] {2218} INFO - iteration 823, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:49] {2391} INFO -  at 286.2s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:49] {2218} INFO - iteration 824, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:50] {2391} INFO -  at 286.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:50] {2218} INFO - iteration 825, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:50] {2391} INFO -  at 287.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:50] {2218} INFO - iteration 826, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:51] {2391} INFO -  at 288.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:51] {2218} INFO - iteration 827, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:52] {2391} INFO -  at 288.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:52] {2218} INFO - iteration 828, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:52] {2391} INFO -  at 289.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:52] {2218} INFO - iteration 829, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:53] {2391} INFO -  at 290.1s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:53] {2218} INFO - iteration 830, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:53] {2391} INFO -  at 290.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:53] {2218} INFO - iteration 831, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2391} INFO -  at 290.4s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2218} INFO - iteration 832, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2391} INFO -  at 290.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2218} INFO - iteration 833, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2391} INFO -  at 290.9s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2218} INFO - iteration 834, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2391} INFO -  at 291.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2218} INFO - iteration 835, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2391} INFO -  at 291.2s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:54] {2218} INFO - iteration 836, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:55] {2391} INFO -  at 291.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:55] {2218} INFO - iteration 837, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:55] {2391} INFO -  at 291.6s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:55] {2218} INFO - iteration 838, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:55] {2391} INFO -  at 291.8s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:55] {2218} INFO - iteration 839, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:55] {2391} INFO -  at 292.0s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:55] {2218} INFO - iteration 840, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:05:56] {2391} INFO -  at 292.9s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:56] {2218} INFO - iteration 841, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:56] {2391} INFO -  at 293.0s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:56] {2218} INFO - iteration 842, current learner rf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:57] {2391} INFO -  at 293.7s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:57] {2218} INFO - iteration 843, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:57] {2391} INFO -  at 293.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:57] {2218} INFO - iteration 844, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:57] {2391} INFO -  at 294.0s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:57] {2218} INFO - iteration 845, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:57] {2391} INFO -  at 294.2s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:57] {2218} INFO - iteration 846, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:58] {2391} INFO -  at 294.4s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:58] {2218} INFO - iteration 847, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:05:58] {2391} INFO -  at 294.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:58] {2218} INFO - iteration 848, current learner rf\n",
            "[flaml.automl.logger: 12-17 20:05:58] {2391} INFO -  at 295.2s,\testimator rf's best error=0.0840,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:58] {2218} INFO - iteration 849, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:05:59] {2391} INFO -  at 295.4s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:59] {2218} INFO - iteration 850, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:59] {2391} INFO -  at 295.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:59] {2218} INFO - iteration 851, current learner xgboost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:05:59] {2391} INFO -  at 295.8s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:59] {2218} INFO - iteration 852, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:05:59] {2391} INFO -  at 296.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:59] {2218} INFO - iteration 853, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:05:59] {2391} INFO -  at 296.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:05:59] {2218} INFO - iteration 854, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2391} INFO -  at 296.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2218} INFO - iteration 855, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2391} INFO -  at 296.6s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2218} INFO - iteration 856, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2391} INFO -  at 296.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2218} INFO - iteration 857, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:06:00] {2391} INFO -  at 297.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2218} INFO - iteration 858, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2391} INFO -  at 297.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2218} INFO - iteration 859, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2391} INFO -  at 297.3s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:00] {2218} INFO - iteration 860, current learner xgboost\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2391} INFO -  at 297.5s,\testimator xgboost's best error=0.0688,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2218} INFO - iteration 861, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2391} INFO -  at 297.6s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2218} INFO - iteration 862, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:06:01] {2391} INFO -  at 297.8s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2218} INFO - iteration 863, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:06:01] {2391} INFO -  at 297.9s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2218} INFO - iteration 864, current learner lgbm\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2391} INFO -  at 298.2s,\testimator lgbm's best error=0.0771,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2218} INFO - iteration 865, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2391} INFO -  at 298.4s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:01] {2218} INFO - iteration 866, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:06:02] {2391} INFO -  at 298.7s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:02] {2218} INFO - iteration 867, current learner extra_tree\n",
            "[flaml.automl.logger: 12-17 20:06:02] {2391} INFO -  at 299.0s,\testimator extra_tree's best error=0.0774,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:02] {2218} INFO - iteration 868, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:06:02] {2391} INFO -  at 299.1s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:02] {2218} INFO - iteration 869, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 12-17 20:06:02] {2391} INFO -  at 299.3s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:02] {2218} INFO - iteration 870, current learner lrl1\n",
            "[flaml.automl.logger: 12-17 20:06:03] {2391} INFO -  at 299.5s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:03] {2218} INFO - iteration 871, current learner lrl1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:06:03] {2391} INFO -  at 299.7s,\testimator lrl1's best error=0.6243,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:03] {2218} INFO - iteration 872, current learner xgb_limitdepth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 12-17 20:06:03] {2391} INFO -  at 300.0s,\testimator xgb_limitdepth's best error=0.0633,\tbest estimator xgb_limitdepth's best error=0.0633\n",
            "[flaml.automl.logger: 12-17 20:06:03] {2525} INFO - [('xgb_limitdepth', {'n_jobs': -1, 'n_estimators': 11, 'max_depth': 6, 'min_child_weight': 0.024162635916970876, 'learning_rate': 1.0, 'subsample': 0.9978568217362944, 'colsample_bylevel': 0.5086933112492915, 'colsample_bytree': 0.6306120069350191, 'reg_alpha': 0.005488592959841232, 'reg_lambda': 0.9621287550295926, 'verbosity': 0}), ('xgboost', {'n_jobs': -1, 'n_estimators': 12, 'max_leaves': 31, 'min_child_weight': 0.0017578372752433818, 'learning_rate': 0.3827075432580604, 'subsample': 0.6260403742716466, 'colsample_bylevel': 0.2568586486266523, 'colsample_bytree': 0.6729064199376791, 'reg_alpha': 0.007951446252367175, 'reg_lambda': 0.0202618559735843, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('lgbm', {'n_jobs': -1, 'n_estimators': 106, 'num_leaves': 10, 'min_child_samples': 11, 'learning_rate': 0.5838680129312924, 'colsample_bytree': 0.8680053236582577, 'reg_alpha': 0.0021324490639427463, 'reg_lambda': 0.02606987907557536, 'max_bin': 1023, 'verbose': -1}), ('extra_tree', {'n_jobs': -1, 'n_estimators': 94, 'max_features': 1.0, 'criterion': 'gini', 'max_leaf_nodes': 38, 'random_state': 12032022, 'verbose': 0}), ('rf', {'n_jobs': -1, 'n_estimators': 39, 'max_features': 0.3781617504800403, 'criterion': 'entropy', 'max_leaf_nodes': 10, 'random_state': 12032022, 'verbose': 0})]\n",
            "[flaml.automl.logger: 12-17 20:06:03] {2568} INFO - Building ensemble with tuned estimators\n",
            "[flaml.automl.logger: 12-17 20:06:08] {2574} INFO - ensemble: StackingClassifier(estimators=[('xgb_limitdepth',\n",
            "                                <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7cd404061a20>),\n",
            "                               ('xgboost',\n",
            "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x7cd33ef82d10>),\n",
            "                               ('lgbm',\n",
            "                                <flaml.automl.model.LGBMEstimator object at 0x7cd33dea2200>),\n",
            "                               ('extra_tree',\n",
            "                                <flaml.automl.model.ExtraTreesEstimator object at 0x7cd33dea30d0>),\n",
            "                               ('rf',\n",
            "                                <flaml.automl.model.RandomForestEstimator object at 0x7cd33dea38b0>)],\n",
            "                   n_jobs=1, passthrough=True)\n",
            "[flaml.automl.logger: 12-17 20:06:08] {1930} INFO - fit succeeded\n",
            "[flaml.automl.logger: 12-17 20:06:08] {1931} INFO - Time taken to find the best model: 67.739009141922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZEKDRcueI_O",
        "outputId": "1fe5cec4-5adf-449b-f948-37ad5e7a80dc"
      },
      "source": [
        "automl.model.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv': None,\n",
              " 'estimators': [('xgb_limitdepth',\n",
              "   <flaml.automl.model.XGBoostLimitDepthEstimator at 0x7cd404061a20>),\n",
              "  ('xgboost', <flaml.automl.model.XGBoostSklearnEstimator at 0x7cd33ef82d10>),\n",
              "  ('lgbm', <flaml.automl.model.LGBMEstimator at 0x7cd33dea2200>),\n",
              "  ('extra_tree', <flaml.automl.model.ExtraTreesEstimator at 0x7cd33dea30d0>),\n",
              "  ('rf', <flaml.automl.model.RandomForestEstimator at 0x7cd33dea38b0>)],\n",
              " 'final_estimator': None,\n",
              " 'n_jobs': 1,\n",
              " 'passthrough': True,\n",
              " 'stack_method': 'auto',\n",
              " 'verbose': 0,\n",
              " 'xgb_limitdepth': <flaml.automl.model.XGBoostLimitDepthEstimator at 0x7cd404061a20>,\n",
              " 'xgboost': <flaml.automl.model.XGBoostSklearnEstimator at 0x7cd33ef82d10>,\n",
              " 'lgbm': <flaml.automl.model.LGBMEstimator at 0x7cd33dea2200>,\n",
              " 'extra_tree': <flaml.automl.model.ExtraTreesEstimator at 0x7cd33dea30d0>,\n",
              " 'rf': <flaml.automl.model.RandomForestEstimator at 0x7cd33dea38b0>,\n",
              " 'xgb_limitdepth__n_jobs': -1,\n",
              " 'xgb_limitdepth__n_estimators': 11,\n",
              " 'xgb_limitdepth__max_depth': 6,\n",
              " 'xgb_limitdepth__min_child_weight': 0.024162635916970876,\n",
              " 'xgb_limitdepth__learning_rate': 1.0,\n",
              " 'xgb_limitdepth__subsample': 0.9978568217362944,\n",
              " 'xgb_limitdepth__colsample_bylevel': 0.5086933112492915,\n",
              " 'xgb_limitdepth__colsample_bytree': 0.6306120069350191,\n",
              " 'xgb_limitdepth__reg_alpha': 0.005488592959841232,\n",
              " 'xgb_limitdepth__reg_lambda': 0.9621287550295926,\n",
              " 'xgb_limitdepth__verbosity': 0,\n",
              " 'xgb_limitdepth__task': <flaml.automl.task.generic_task.GenericTask at 0x7cd34433fb80>,\n",
              " 'xgb_limitdepth___estimator_type': 'classifier',\n",
              " 'xgboost__n_jobs': -1,\n",
              " 'xgboost__n_estimators': 12,\n",
              " 'xgboost__max_leaves': 31,\n",
              " 'xgboost__min_child_weight': 0.0017578372752433818,\n",
              " 'xgboost__learning_rate': 0.3827075432580604,\n",
              " 'xgboost__subsample': 0.6260403742716466,\n",
              " 'xgboost__colsample_bylevel': 0.2568586486266523,\n",
              " 'xgboost__colsample_bytree': 0.6729064199376791,\n",
              " 'xgboost__reg_alpha': 0.007951446252367175,\n",
              " 'xgboost__reg_lambda': 0.0202618559735843,\n",
              " 'xgboost__max_depth': 0,\n",
              " 'xgboost__grow_policy': 'lossguide',\n",
              " 'xgboost__tree_method': 'hist',\n",
              " 'xgboost__verbosity': 0,\n",
              " 'xgboost__task': <flaml.automl.task.generic_task.GenericTask at 0x7cd34433fb80>,\n",
              " 'xgboost___estimator_type': 'classifier',\n",
              " 'lgbm__n_jobs': -1,\n",
              " 'lgbm__n_estimators': 106,\n",
              " 'lgbm__num_leaves': 10,\n",
              " 'lgbm__min_child_samples': 11,\n",
              " 'lgbm__learning_rate': 0.5838680129312924,\n",
              " 'lgbm__colsample_bytree': 0.8680053236582577,\n",
              " 'lgbm__reg_alpha': 0.0021324490639427463,\n",
              " 'lgbm__reg_lambda': 0.02606987907557536,\n",
              " 'lgbm__max_bin': 1023,\n",
              " 'lgbm__verbose': -1,\n",
              " 'lgbm__task': <flaml.automl.task.generic_task.GenericTask at 0x7cd34433fb80>,\n",
              " 'lgbm___estimator_type': 'classifier',\n",
              " 'extra_tree__n_jobs': -1,\n",
              " 'extra_tree__n_estimators': 94,\n",
              " 'extra_tree__max_features': 1.0,\n",
              " 'extra_tree__criterion': 'gini',\n",
              " 'extra_tree__max_leaf_nodes': 38,\n",
              " 'extra_tree__random_state': 12032022,\n",
              " 'extra_tree__verbose': 0,\n",
              " 'extra_tree__task': <flaml.automl.task.generic_task.GenericTask at 0x7cd34433fb80>,\n",
              " 'extra_tree___estimator_type': 'classifier',\n",
              " 'rf__n_jobs': -1,\n",
              " 'rf__n_estimators': 39,\n",
              " 'rf__max_features': 0.3781617504800403,\n",
              " 'rf__criterion': 'entropy',\n",
              " 'rf__max_leaf_nodes': 10,\n",
              " 'rf__random_state': 12032022,\n",
              " 'rf__verbose': 0,\n",
              " 'rf__task': <flaml.automl.task.generic_task.GenericTask at 0x7cd34433fb80>,\n",
              " 'rf___estimator_type': 'classifier'}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "QGpxgzrZeQVD",
        "outputId": "dd19f1c6-c358-4c0c-c23d-82b2ceec6b14"
      },
      "source": [
        "predictions = automl.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n",
        "cf = confusion_matrix(y_test, predictions)\n",
        "sns.heatmap(cf, annot=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97        91\n",
            "           1       0.80      0.73      0.76        11\n",
            "\n",
            "    accuracy                           0.95       102\n",
            "   macro avg       0.88      0.85      0.87       102\n",
            "weighted avg       0.95      0.95      0.95       102\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
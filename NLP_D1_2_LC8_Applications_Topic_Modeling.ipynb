{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astrapi69/DroidBallet/blob/master/NLP_D1_2_LC8_Applications_Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_inCSqYZUh_g"
      },
      "source": [
        "<center><a target=\"_blank\" href=\"https://learning.constructor.org/\"><img src=\"https://drive.google.com/uc?id=1RNy-ds7KWXFs7YheGo9OQwO3OnpvRSU1\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "\n",
        "_____\n",
        "\n",
        "<center>Constructor Academy, 2024</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iKMVCis12aq"
      },
      "source": [
        "# Topic Modeling on Research Papers\n",
        "\n",
        "We will do an interesting exercise here—build topic models on past research papers\n",
        "from the very popular NIPS conference (now known as the NeurIPS conference). The\n",
        "late professor Sam Roweis compiled an excellent collection of NIPS Conference Papers\n",
        "from Volume 1 – 12, which you can find at https://cs.nyu.edu/~roweis/data.html.\n",
        "An interesting fact is that he obtained this by massaging the OCR’d data from NIPS\n",
        "1-12, which was actually the pre-electronic submission era. Yann LeCun made the data\n",
        "available. There is an even more updated dataset available up to NIPS 17 at http://\n",
        "ai.stanford.edu/~gal/data.html. However, that dataset is in the form of a MAT file, so\n",
        "you might need to do some additional preprocessing before working on it in Python.\n",
        "\n",
        "\n",
        "## The Main Objective\n",
        "\n",
        "Considering our discussion so far, our main objective is pretty simple. Given a whole\n",
        "bunch of conference research papers, can we identify some key themes or topics from\n",
        "these papers by leveraging unsupervised learning? We do not have the liberty of labeled\n",
        "categories telling us what the major themes of every research paper are. Besides that, we\n",
        "are dealing with text data extracted using OCR (optical character recognition). Hence,\n",
        "you can expect misspelled words, words with characters missing, and so on, which\n",
        "makes our problem even more challenging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsTqya546U6q"
      },
      "source": [
        "## Download Data and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJaNFsqQ6KGt",
        "outputId": "1541723b-bd29-426f-8208-568473900f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-23 20:10:25--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
            "Resolving cs.nyu.edu (cs.nyu.edu)... 216.165.22.203\n",
            "Connecting to cs.nyu.edu (cs.nyu.edu)|216.165.22.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12851423 (12M) [application/x-gzip]\n",
            "Saving to: ‘nips12raw_str602.tgz’\n",
            "\n",
            "nips12raw_str602.tg 100%[===================>]  12.26M  23.3MB/s    in 0.5s    \n",
            "\n",
            "2024-03-23 20:10:26 (23.3 MB/s) - ‘nips12raw_str602.tgz’ saved [12851423/12851423]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
        "!tar -xzf nips12raw_str602.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C36S18zo8w3b",
        "outputId": "2740450e-ac79-47c5-b11b-713905939265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHpf-YxR6XuW",
        "outputId": "52160411-b619-4c77-a710-92b72c2c3d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['nips11', 'nips09', 'idx', 'nips02', 'nips05', 'nips10', 'README_yann', 'nips12', 'nips06', 'MATLAB_NOTES', 'nips01', 'orig', 'nips07', 'nips00', 'nips04', 'nips03', 'RAW_DATA_NOTES', 'nips08']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = 'nipstxt/'\n",
        "print(os.listdir(DATA_PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y20UiwtA6pAg"
      },
      "source": [
        "## Load NIPS Research Papers Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3G8nUsJ6h7V",
        "outputId": "2361002b-6bf4-4f41-8725-553382070dd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1740"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
        "# Read all texts into a list.\n",
        "papers = []\n",
        "for folder in folders:\n",
        "    file_names = os.listdir(DATA_PATH + folder)\n",
        "    for file_name in file_names:\n",
        "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
        "            data = f.read()\n",
        "        papers.append(data)\n",
        "len(papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaTh1Jll6kx9",
        "outputId": "2f4994d2-3030-4da0-f008-6b401f5184ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "674 \n",
            "PATYEP CLASS DEGENERACY IN AN UNRESTRICTED STORAGE \n",
            "DENSITY MEMORY \n",
            "Christopher L. Scofield, Douglas L. Reilly, \n",
            "Charles Elbaum, Leon N. Cooper \n",
            "Nestor, Inc., 1 Richmond Square, Providence, Rhode Island, \n",
            "02906. \n",
            "ABSTRACT \n",
            "The study of distributed memory systems has produced a \n",
            "number of models which work well in limited domains. \n",
            "However, until recently, the application of such systems to real- \n",
            "world problems has been difficult because of storage limitations, \n",
            "and their inherent architectural (and for serial simulation, \n",
            "computational) complexity. Recent development of memories \n",
            "with unrestricted storage capacity and economical feedforward \n",
            "architectures has opened the way to the application of such \n",
            "systems to complex pattern recognition problems. However, \n",
            "such problems are sometimes underspecified by the features \n",
            "which describe the environment, and thus a significant portion \n",
            "of the pattern environment is often non-separable. We will \n",
            "review current work on high density memo\n"
          ]
        }
      ],
      "source": [
        "print(papers[3][:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNqkh2nb8qpe"
      },
      "source": [
        "## Basic Text Pre-processing\n",
        "\n",
        "We perform some basic text wrangling or preprocessing before diving into topic\n",
        "modeling. We keep things simple here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhsbee7g8lwa",
        "outputId": "075402a2-ae23-4ecf-852d-b13087d943a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1740/1740 [00:56<00:00, 31.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1740\n",
            "CPU times: user 44.6 s, sys: 586 ms, total: 45.2 s\n",
            "Wall time: 56.1 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import nltk\n",
        "import tqdm\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+') # can also use nltk.word_tokenize to get word tokens for each paper\n",
        "wnl = nltk.stem.wordnet.WordNetLemmatizer() # can use spacy lemmatization also\n",
        "\n",
        "def normalize_corpus(papers):\n",
        "    norm_papers = []\n",
        "    for paper in tqdm.tqdm(papers):\n",
        "        paper = paper.lower()\n",
        "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
        "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
        "        paper_tokens = [token for token in paper_tokens if len(token) > 1] # removing any single character words \\ numbers \\ symbols\n",
        "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
        "        paper_tokens = list(filter(None, paper_tokens))\n",
        "        if paper_tokens:\n",
        "            norm_papers.append(paper_tokens)\n",
        "\n",
        "    return norm_papers\n",
        "\n",
        "norm_papers = normalize_corpus(papers)\n",
        "print(len(norm_papers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq4EhTwP-I_U",
        "outputId": "5e1a7039-e9dd-49d8-e7f5-7e30bbea482b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['patyep', 'class', 'degeneracy', 'unrestricted', 'storage', 'density', 'memory', 'christopher', 'scofield', 'douglas', 'reilly', 'charles', 'elbaum', 'leon', 'cooper', 'nestor', 'inc', 'richmond', 'square', 'providence', 'rhode', 'island', 'abstract', 'study', 'distributed', 'memory', 'system', 'ha', 'produced', 'number', 'model', 'work', 'well', 'limited', 'domain', 'however', 'recently', 'application', 'system', 'real', 'world', 'problem', 'ha', 'difficult', 'storage', 'limitation', 'inherent', 'architectural', 'serial', 'simulation']\n"
          ]
        }
      ],
      "source": [
        "print(norm_papers[3][:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFubckun_IYp"
      },
      "source": [
        "## Build a Bi-gram Phrase Model\n",
        "\n",
        "Before feature engineering and vectorization, we want to extract some useful bi-gram\n",
        "based phrases from our research papers and remove some unnecessary terms. We\n",
        "leverage the very useful gensim.models.Phrases class for this. This capability helps us\n",
        "automatically detect common phrases from a stream of sentences, which are typically\n",
        "multi-word expressions/word n-grams.\n",
        "\n",
        "This implementation draws inspiration\n",
        "from the famous paper by Mikolov, et al., “Distributed Representations of Words and\n",
        "Phrases and their Compositionality,” which you can check out at https://arxiv.org/\n",
        "abs/1310.4546. We start by extracting and generating words and bi-grams as phrases for\n",
        "each tokenized research paper.\n",
        "\n",
        "We leverage the `min_count` parameter, which tells us that our model ignores all words and bi-grams with total\n",
        "collected count lower than 20 across the corpus (of the input paper as a list of tokenized\n",
        "sentences). We also use a `threshold` of 20, which tells us that the model accepts specific\n",
        "phrases based on this threshold value so that a phrase of words a followed by b is\n",
        "accepted if the score of the phrase is greater than the threshold of 20. This threshold is\n",
        "dependent on the scoring parameter, which helps us understand how these phrases are\n",
        "scored to understand their influence.\n",
        "Typically the default scorer is used and it’s pretty straightforward to understand.\n",
        "You can check out further details in the documentation at https://radimrehurek.com/gensim/models/phrases.html#gensim.models.phrases.original_scorer and in the\n",
        "previously mentioned research paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RWq3XtcEf21F",
        "outputId": "9196f6a4-a3b8-4817-8630-29bcc7ceb1fd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.3.2'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gensim\n",
        "gensim.__version__ # >= 4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IX3-ZbQ-fXp",
        "outputId": "bb31f580-4797-43cc-bbdf-861aa3736884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['patyep', 'class', 'degeneracy', 'unrestricted', 'storage', 'density', 'memory', 'christopher', 'scofield', 'douglas', 'reilly', 'charles', 'elbaum', 'leon', 'cooper', 'nestor', 'inc', 'richmond', 'square', 'providence', 'rhode', 'island', 'abstract', 'study', 'distributed', 'memory', 'system', 'ha', 'produced', 'number', 'model', 'work', 'well', 'limited', 'domain', 'however', 'recently', 'application', 'system', 'real_world', 'problem', 'ha', 'difficult', 'storage', 'limitation', 'inherent', 'architectural', 'serial', 'simulation', 'computational_complexity']\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "\n",
        "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter='_') # higher threshold -> fewer phrases.\n",
        "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
        "\n",
        "print(bigram_model[norm_papers[3]][:50]) # very similar to using ngram_range=(1,2) in count vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaGCzYSU-jx1",
        "outputId": "62a97df5-4712-49db-aa59-c5c6b0d0ce42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample word to number mappings: [(0, '1vs'), (1, '21ogn'), (2, '2elogn'), (3, '2logn'), (4, '2m'), (5, '4e'), (6, '4logn'), (7, '81ogn'), (8, '_0'), (9, '_5'), (10, 'a2'), (11, 'a2k'), (12, 'ability'), (13, 'able'), (14, 'abstract')]\n",
            "Total Vocabulary Size: 78892\n"
          ]
        }
      ],
      "source": [
        "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
        "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
        "print('Total Vocabulary Size:', len(dictionary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x47ztNpD12bC"
      },
      "source": [
        "Looks like we have a lot of unique phrases in our corpus of research papers,\n",
        "based on the preceding output. Several of these terms are not very useful since they are\n",
        "specific to a paper or even a paragraph in a research paper. Hence, it is time to prune\n",
        "our vocabulary and start removing terms. Leveraging document frequency is a great way\n",
        "to achieve this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTiZ2Bxe-tNK",
        "outputId": "f4fa916f-af17-45ca-ca70-fddd18fabeff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Vocabulary Size: 7756\n"
          ]
        }
      ],
      "source": [
        "# Filter out words that occur less than 20 documents, or more than 60% of the documents.\n",
        "dictionary.filter_extremes(no_below=20, no_above=0.6) # similar to min_df and max_df in count vectorizer\n",
        "print('Total Vocabulary Size:', len(dictionary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKMDWQ6W12bF"
      },
      "source": [
        "We removed all terms that occur fewer than 20 times across all documents and all\n",
        "terms that occur in more than 60% of all the documents. We are interested in finding\n",
        "different themes and topics and not recurring themes. Hence, this suits our scenario\n",
        "perfectly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj2lB4_b_eFO"
      },
      "source": [
        "## Transforming corpus into bag of words vectors\n",
        "\n",
        "We can now perform feature engineering by leveraging a simple Bag of Words\n",
        "model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp_fhm91-3R-",
        "outputId": "838fcf46-4d75-4d9d-f46d-65dd14b7c740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(3, 1), (4, 1), (6, 2), (17, 1), (21, 2), (26, 1), (29, 1), (30, 1), (31, 1), (35, 1), (40, 3), (41, 1), (43, 1), (46, 1), (51, 5), (52, 1), (59, 1), (61, 3), (64, 1), (68, 6), (78, 1), (79, 1), (80, 1), (82, 1), (85, 9), (93, 3), (95, 2), (100, 1), (107, 1), (108, 10), (121, 2), (123, 1), (126, 2), (127, 2), (131, 2), (135, 4), (137, 1), (147, 1), (148, 1), (155, 2), (165, 1), (170, 2), (171, 2), (174, 2), (181, 14), (186, 2), (191, 2), (194, 6), (197, 1), (213, 2)]\n"
          ]
        }
      ],
      "source": [
        "# Transforming corpus into bag of words vectors\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
        "print(bow_corpus[1][:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oOA652d-6sI",
        "outputId": "72e6b6e3-2bcf-45a8-9f5f-12754f306b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('able', 1), ('abstract', 1), ('acad_sci', 2), ('addition', 1), ('advantage', 2), ('allowed', 1), ('american_institute', 1), ('amir', 1), ('analog', 1), ('analyzed', 1), ('application', 3), ('appropriate', 1), ('approximation', 1), ('around', 1), ('associative_memory', 5), ('assume', 1), ('basin_attraction', 1), ('becomes', 3), ('behavior', 1), ('binary', 6), ('call', 1), ('called', 1), ('cannot', 1), ('capacity', 1), ('cell', 9), ('class', 3), ('clearly', 2), ('collective', 1), ('complete', 1), ('complex', 10), ('conference', 2), ('consider', 1), ('consists', 2), ('constant', 2), ('continuous', 2), ('corresponding', 4), ('could', 1), ('define', 1), ('defined', 1), ('depends', 2), ('developed', 1), ('direction', 2), ('directly', 2), ('discrete_time', 2), ('dynamic', 14), ('easily', 2), ('element', 2), ('energy', 6), ('equal', 1), ('exists', 2)]\n"
          ]
        }
      ],
      "source": [
        "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAjuxxdH--fn",
        "outputId": "206eb819-f7fa-4ea9-b319-e0adc034188d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of papers: 1740\n"
          ]
        }
      ],
      "source": [
        "print('Total number of papers:', len(bow_corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUb8ZKJXJI-4"
      },
      "source": [
        "## Topic Models with Latent Dirichlet Allocation (LDA)\n",
        "\n",
        "The Latent Dirichlet Allocation (LDA) technique is a generative probabilistic model in\n",
        "which each document is assumed to have a combination of topics similar to a probabilistic\n",
        "Latent Semantic Indexing model. In this case, the latent topics contain a Dirichlet\n",
        "prior over them. The math behind in this technique is pretty involved, so we will try to\n",
        "summarize it since going it specific details is out of the current scope.\n",
        "\n",
        "![](https://i.imgur.com/l23JAvE.png)\n",
        "\n",
        "Simplyfying the LDA model process:\n",
        "\n",
        "![](https://i.imgur.com/0BXCaUi.png)\n",
        "\n",
        "![](https://i.imgur.com/ioiUAxX.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "083_UQPlJZy_",
        "outputId": "f522e2b0-fc8e-4e13-db96-95d3c6b5a44e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 54s, sys: 2.4 s, total: 1min 57s\n",
            "Wall time: 2min 2s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "TOTAL_TOPICS = 10\n",
        "lda_model = gensim.models.LdaModel(corpus=bow_corpus,\n",
        "                                   id2word=dictionary,\n",
        "                                   chunksize=1740,\n",
        "                                   alpha='auto',\n",
        "                                   eta='auto',\n",
        "                                   random_state=42,\n",
        "                                   iterations=500,\n",
        "                                   num_topics=TOTAL_TOPICS,\n",
        "                                   passes=20,\n",
        "                                   eval_every=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF9KX9UARO1r",
        "outputId": "68a18ffb-96fd-46db-ed98-0230a7e5d76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "0.023*\"neuron\" + 0.015*\"cell\" + 0.009*\"activity\" + 0.008*\"pattern\" + 0.008*\"response\" + 0.007*\"stimulus\" + 0.006*\"synaptic\" + 0.006*\"spike\" + 0.005*\"unit\" + 0.005*\"connection\" + 0.005*\"cortical\" + 0.004*\"layer\" + 0.004*\"firing\" + 0.004*\"neural\" + 0.004*\"effect\" + 0.004*\"simulation\" + 0.004*\"et_al\" + 0.004*\"cortex\" + 0.003*\"map\" + 0.003*\"synapsis\"\n",
            "\n",
            "Topic #2:\n",
            "0.013*\"circuit\" + 0.011*\"chip\" + 0.010*\"cell\" + 0.009*\"neuron\" + 0.009*\"motion\" + 0.008*\"current\" + 0.007*\"voltage\" + 0.006*\"analog\" + 0.006*\"signal\" + 0.005*\"response\" + 0.005*\"direction\" + 0.005*\"image\" + 0.004*\"neural\" + 0.004*\"visual\" + 0.004*\"velocity\" + 0.004*\"filter\" + 0.003*\"field\" + 0.003*\"implementation\" + 0.003*\"array\" + 0.003*\"edge\"\n",
            "\n",
            "Topic #3:\n",
            "0.031*\"image\" + 0.015*\"feature\" + 0.014*\"object\" + 0.007*\"representation\" + 0.006*\"task\" + 0.005*\"view\" + 0.005*\"training\" + 0.005*\"pixel\" + 0.004*\"position\" + 0.004*\"location\" + 0.004*\"map\" + 0.004*\"visual\" + 0.004*\"region\" + 0.004*\"distance\" + 0.004*\"vector\" + 0.004*\"transformation\" + 0.003*\"surface\" + 0.003*\"local\" + 0.003*\"unit\" + 0.003*\"structure\"\n",
            "\n",
            "Topic #4:\n",
            "0.012*\"training\" + 0.009*\"class\" + 0.007*\"classifier\" + 0.006*\"classification\" + 0.005*\"sample\" + 0.005*\"distribution\" + 0.005*\"prediction\" + 0.004*\"vector\" + 0.004*\"training_set\" + 0.004*\"estimate\" + 0.004*\"test\" + 0.004*\"probability\" + 0.004*\"linear\" + 0.004*\"kernel\" + 0.004*\"approximation\" + 0.003*\"regression\" + 0.003*\"size\" + 0.003*\"bound\" + 0.003*\"feature\" + 0.003*\"pattern\"\n",
            "\n",
            "Topic #5:\n",
            "0.017*\"state\" + 0.010*\"probability\" + 0.008*\"variable\" + 0.006*\"mixture\" + 0.006*\"hmm\" + 0.006*\"structure\" + 0.006*\"distribution\" + 0.005*\"sequence\" + 0.005*\"cluster\" + 0.005*\"word\" + 0.005*\"step\" + 0.004*\"clustering\" + 0.004*\"context\" + 0.004*\"likelihood\" + 0.004*\"training\" + 0.004*\"prior\" + 0.004*\"node\" + 0.004*\"level\" + 0.003*\"component\" + 0.003*\"tree\"\n",
            "\n",
            "Topic #6:\n",
            "0.016*\"control\" + 0.010*\"training\" + 0.009*\"word\" + 0.008*\"trajectory\" + 0.007*\"recognition\" + 0.006*\"character\" + 0.006*\"task\" + 0.006*\"position\" + 0.006*\"architecture\" + 0.006*\"controller\" + 0.005*\"state\" + 0.005*\"trained\" + 0.005*\"movement\" + 0.005*\"dynamic\" + 0.005*\"hand\" + 0.005*\"speech\" + 0.005*\"robot\" + 0.005*\"module\" + 0.004*\"motor\" + 0.004*\"field\"\n",
            "\n",
            "Topic #7:\n",
            "0.010*\"unit\" + 0.008*\"state\" + 0.008*\"node\" + 0.008*\"rule\" + 0.008*\"pattern\" + 0.007*\"memory\" + 0.006*\"vector\" + 0.006*\"sequence\" + 0.006*\"net\" + 0.005*\"neuron\" + 0.005*\"activation\" + 0.004*\"layer\" + 0.004*\"bit\" + 0.004*\"recurrent\" + 0.004*\"threshold\" + 0.004*\"size\" + 0.004*\"structure\" + 0.003*\"representation\" + 0.003*\"training\" + 0.003*\"theorem\"\n",
            "\n",
            "Topic #8:\n",
            "0.009*\"noise\" + 0.009*\"equation\" + 0.008*\"matrix\" + 0.008*\"vector\" + 0.006*\"distribution\" + 0.006*\"linear\" + 0.005*\"solution\" + 0.005*\"dynamic\" + 0.005*\"signal\" + 0.005*\"gaussian\" + 0.005*\"nonlinear\" + 0.004*\"state\" + 0.004*\"eq\" + 0.004*\"density\" + 0.004*\"source\" + 0.004*\"component\" + 0.004*\"optimal\" + 0.004*\"rate\" + 0.003*\"estimate\" + 0.003*\"rule\"\n",
            "\n",
            "Topic #9:\n",
            "0.013*\"state\" + 0.013*\"unit\" + 0.008*\"action\" + 0.006*\"step\" + 0.006*\"training\" + 0.005*\"hidden_unit\" + 0.005*\"control\" + 0.005*\"policy\" + 0.005*\"task\" + 0.005*\"optimal\" + 0.004*\"rate\" + 0.004*\"reinforcement_learning\" + 0.004*\"gradient\" + 0.004*\"convergence\" + 0.004*\"vector\" + 0.003*\"update\" + 0.003*\"solution\" + 0.003*\"back_propagation\" + 0.003*\"adaptive\" + 0.003*\"architecture\"\n",
            "\n",
            "Topic #10:\n",
            "0.009*\"signal\" + 0.007*\"unit\" + 0.007*\"pattern\" + 0.006*\"training\" + 0.006*\"classification\" + 0.005*\"stimulus\" + 0.005*\"feature\" + 0.005*\"layer\" + 0.005*\"frequency\" + 0.005*\"response\" + 0.005*\"representation\" + 0.005*\"recognition\" + 0.004*\"task\" + 0.004*\"speech\" + 0.004*\"trained\" + 0.004*\"speaker\" + 0.004*\"face\" + 0.004*\"sound\" + 0.004*\"subject\" + 0.004*\"detection\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
        "    print('Topic #'+str(topic_id+1)+':')\n",
        "    print(topic)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jExj9SYRRyE",
        "outputId": "2ba2787b-725b-4edc-eef9-3fcfae48f7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score: -1.0803260583515713\n"
          ]
        }
      ],
      "source": [
        "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
        "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
        "print('Avg. Coherence Score:', avg_coherence_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtPTIGeQ12by"
      },
      "source": [
        "Topic coherence is a complex topic in its own and it can be used to measure the\n",
        "quality of topic models to some extent. Typically, a set of statements is said to be\n",
        "coherent if they support each other. Topic models are unsupervised learning based\n",
        "models that are trained on unstructured text data, making it difficult to measure the\n",
        "quality of outputs.\n",
        "\n",
        "Refer to Text Analytics with Python 2nd Edition for more detail on this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azEdB08qRX4z",
        "outputId": "a9ef137a-315d-44cd-81a7-2e5cda553951"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LDA Topics with Weights\n",
            "==================================================\n",
            "Topic #1:\n",
            "[('training', 0.012), ('class', 0.009), ('classifier', 0.007), ('classification', 0.006), ('sample', 0.005), ('distribution', 0.005), ('prediction', 0.005), ('vector', 0.004), ('training_set', 0.004), ('estimate', 0.004), ('test', 0.004), ('probability', 0.004), ('linear', 0.004), ('kernel', 0.004), ('approximation', 0.004), ('regression', 0.003), ('size', 0.003), ('bound', 0.003), ('feature', 0.003), ('pattern', 0.003)]\n",
            "\n",
            "Topic #2:\n",
            "[('image', 0.031), ('feature', 0.015), ('object', 0.014), ('representation', 0.007), ('task', 0.006), ('view', 0.005), ('training', 0.005), ('pixel', 0.005), ('position', 0.004), ('location', 0.004), ('map', 0.004), ('visual', 0.004), ('region', 0.004), ('distance', 0.004), ('vector', 0.004), ('transformation', 0.004), ('surface', 0.003), ('local', 0.003), ('unit', 0.003), ('structure', 0.003)]\n",
            "\n",
            "Topic #3:\n",
            "[('noise', 0.009), ('equation', 0.009), ('matrix', 0.008), ('vector', 0.008), ('distribution', 0.006), ('linear', 0.006), ('solution', 0.005), ('dynamic', 0.005), ('signal', 0.005), ('gaussian', 0.005), ('nonlinear', 0.005), ('state', 0.004), ('eq', 0.004), ('density', 0.004), ('source', 0.004), ('component', 0.004), ('optimal', 0.004), ('rate', 0.004), ('estimate', 0.003), ('rule', 0.003)]\n",
            "\n",
            "Topic #4:\n",
            "[('neuron', 0.023), ('cell', 0.015), ('activity', 0.009), ('pattern', 0.008), ('response', 0.008), ('stimulus', 0.007), ('synaptic', 0.006), ('spike', 0.006), ('unit', 0.005), ('connection', 0.005), ('cortical', 0.005), ('layer', 0.004), ('firing', 0.004), ('neural', 0.004), ('effect', 0.004), ('simulation', 0.004), ('et_al', 0.004), ('cortex', 0.004), ('map', 0.003), ('synapsis', 0.003)]\n",
            "\n",
            "Topic #5:\n",
            "[('unit', 0.01), ('state', 0.008), ('node', 0.008), ('rule', 0.008), ('pattern', 0.008), ('memory', 0.007), ('vector', 0.006), ('sequence', 0.006), ('net', 0.006), ('neuron', 0.005), ('activation', 0.005), ('layer', 0.004), ('bit', 0.004), ('recurrent', 0.004), ('threshold', 0.004), ('size', 0.004), ('structure', 0.004), ('representation', 0.003), ('training', 0.003), ('theorem', 0.003)]\n",
            "\n",
            "Topic #6:\n",
            "[('state', 0.013), ('unit', 0.013), ('action', 0.008), ('step', 0.006), ('training', 0.006), ('hidden_unit', 0.005), ('control', 0.005), ('policy', 0.005), ('task', 0.005), ('optimal', 0.005), ('rate', 0.004), ('reinforcement_learning', 0.004), ('gradient', 0.004), ('convergence', 0.004), ('vector', 0.004), ('update', 0.003), ('solution', 0.003), ('back_propagation', 0.003), ('adaptive', 0.003), ('architecture', 0.003)]\n",
            "\n",
            "Topic #7:\n",
            "[('circuit', 0.013), ('chip', 0.011), ('cell', 0.01), ('neuron', 0.009), ('motion', 0.009), ('current', 0.008), ('voltage', 0.007), ('analog', 0.006), ('signal', 0.006), ('response', 0.005), ('direction', 0.005), ('image', 0.005), ('neural', 0.004), ('visual', 0.004), ('velocity', 0.004), ('filter', 0.004), ('field', 0.003), ('implementation', 0.003), ('array', 0.003), ('edge', 0.003)]\n",
            "\n",
            "Topic #8:\n",
            "[('state', 0.017), ('probability', 0.01), ('variable', 0.008), ('mixture', 0.006), ('hmm', 0.006), ('structure', 0.006), ('distribution', 0.006), ('sequence', 0.005), ('cluster', 0.005), ('word', 0.005), ('step', 0.005), ('clustering', 0.004), ('context', 0.004), ('likelihood', 0.004), ('training', 0.004), ('prior', 0.004), ('node', 0.004), ('level', 0.004), ('component', 0.003), ('tree', 0.003)]\n",
            "\n",
            "Topic #9:\n",
            "[('signal', 0.009), ('unit', 0.007), ('pattern', 0.007), ('training', 0.006), ('classification', 0.006), ('stimulus', 0.005), ('feature', 0.005), ('layer', 0.005), ('frequency', 0.005), ('response', 0.005), ('representation', 0.005), ('recognition', 0.005), ('task', 0.004), ('speech', 0.004), ('trained', 0.004), ('speaker', 0.004), ('face', 0.004), ('sound', 0.004), ('subject', 0.004), ('detection', 0.004)]\n",
            "\n",
            "Topic #10:\n",
            "[('control', 0.016), ('training', 0.01), ('word', 0.009), ('trajectory', 0.008), ('recognition', 0.007), ('character', 0.006), ('task', 0.006), ('position', 0.006), ('architecture', 0.006), ('controller', 0.006), ('state', 0.005), ('trained', 0.005), ('movement', 0.005), ('dynamic', 0.005), ('hand', 0.005), ('speech', 0.005), ('robot', 0.005), ('module', 0.005), ('motor', 0.004), ('field', 0.004)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "topics_with_wts = [item[0] for item in topics_coherences]\n",
        "print('LDA Topics with Weights')\n",
        "print('='*50)\n",
        "for idx, topic in enumerate(topics_with_wts):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([(term, round(wt, 3)) for wt, term in topic])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAkgJa3XRZ3m",
        "outputId": "b878d8f3-9edc-4a22-a0f2-88337c233707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LDA Topics without Weights\n",
            "==================================================\n",
            "Topic #1:\n",
            "['training', 'class', 'classifier', 'classification', 'sample', 'distribution', 'prediction', 'vector', 'training_set', 'estimate', 'test', 'probability', 'linear', 'kernel', 'approximation', 'regression', 'size', 'bound', 'feature', 'pattern']\n",
            "\n",
            "Topic #2:\n",
            "['image', 'feature', 'object', 'representation', 'task', 'view', 'training', 'pixel', 'position', 'location', 'map', 'visual', 'region', 'distance', 'vector', 'transformation', 'surface', 'local', 'unit', 'structure']\n",
            "\n",
            "Topic #3:\n",
            "['noise', 'equation', 'matrix', 'vector', 'distribution', 'linear', 'solution', 'dynamic', 'signal', 'gaussian', 'nonlinear', 'state', 'eq', 'density', 'source', 'component', 'optimal', 'rate', 'estimate', 'rule']\n",
            "\n",
            "Topic #4:\n",
            "['neuron', 'cell', 'activity', 'pattern', 'response', 'stimulus', 'synaptic', 'spike', 'unit', 'connection', 'cortical', 'layer', 'firing', 'neural', 'effect', 'simulation', 'et_al', 'cortex', 'map', 'synapsis']\n",
            "\n",
            "Topic #5:\n",
            "['unit', 'state', 'node', 'rule', 'pattern', 'memory', 'vector', 'sequence', 'net', 'neuron', 'activation', 'layer', 'bit', 'recurrent', 'threshold', 'size', 'structure', 'representation', 'training', 'theorem']\n",
            "\n",
            "Topic #6:\n",
            "['state', 'unit', 'action', 'step', 'training', 'hidden_unit', 'control', 'policy', 'task', 'optimal', 'rate', 'reinforcement_learning', 'gradient', 'convergence', 'vector', 'update', 'solution', 'back_propagation', 'adaptive', 'architecture']\n",
            "\n",
            "Topic #7:\n",
            "['circuit', 'chip', 'cell', 'neuron', 'motion', 'current', 'voltage', 'analog', 'signal', 'response', 'direction', 'image', 'neural', 'visual', 'velocity', 'filter', 'field', 'implementation', 'array', 'edge']\n",
            "\n",
            "Topic #8:\n",
            "['state', 'probability', 'variable', 'mixture', 'hmm', 'structure', 'distribution', 'sequence', 'cluster', 'word', 'step', 'clustering', 'context', 'likelihood', 'training', 'prior', 'node', 'level', 'component', 'tree']\n",
            "\n",
            "Topic #9:\n",
            "['signal', 'unit', 'pattern', 'training', 'classification', 'stimulus', 'feature', 'layer', 'frequency', 'response', 'representation', 'recognition', 'task', 'speech', 'trained', 'speaker', 'face', 'sound', 'subject', 'detection']\n",
            "\n",
            "Topic #10:\n",
            "['control', 'training', 'word', 'trajectory', 'recognition', 'character', 'task', 'position', 'architecture', 'controller', 'state', 'trained', 'movement', 'dynamic', 'hand', 'speech', 'robot', 'module', 'motor', 'field']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('LDA Topics without Weights')\n",
        "print('='*50)\n",
        "for idx, topic in enumerate(topics_with_wts):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for wt, term in topic])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0GmIZME8kmo"
      },
      "source": [
        "### View Topics in a neat DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNi4_yoT6siE"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_colwidth = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "1csjJBdn8kAg",
        "outputId": "68d003c7-a07e-4a0b-e852-fe8ae97ef78f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"topics_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Terms per Topic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"state, unit, action, step, training, hidden_unit, control, policy, task, optimal, rate, reinforcement_learning, gradient, convergence, vector\",\n          \"circuit, chip, cell, neuron, motion, current, voltage, analog, signal, response, direction, image, neural, visual, velocity\",\n          \"control, training, word, trajectory, recognition, character, task, position, architecture, controller, state, trained, movement, dynamic, hand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "topics_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-aee9edf2-5b49-463a-932a-51854f54f7c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Terms per Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic1</th>\n",
              "      <td>neuron, cell, activity, pattern, response, stimulus, synaptic, spike, unit, connection, cortical, layer, firing, neural, effect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic2</th>\n",
              "      <td>circuit, chip, cell, neuron, motion, current, voltage, analog, signal, response, direction, image, neural, visual, velocity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic3</th>\n",
              "      <td>image, feature, object, representation, task, view, training, pixel, position, location, map, visual, region, distance, vector</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic4</th>\n",
              "      <td>training, class, classifier, classification, sample, distribution, prediction, vector, training_set, estimate, test, probability, linear, kernel, approximation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic5</th>\n",
              "      <td>state, probability, variable, mixture, hmm, structure, distribution, sequence, cluster, word, step, clustering, context, likelihood, training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic6</th>\n",
              "      <td>control, training, word, trajectory, recognition, character, task, position, architecture, controller, state, trained, movement, dynamic, hand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic7</th>\n",
              "      <td>unit, state, node, rule, pattern, memory, vector, sequence, net, neuron, activation, layer, bit, recurrent, threshold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic8</th>\n",
              "      <td>noise, equation, matrix, vector, distribution, linear, solution, dynamic, signal, gaussian, nonlinear, state, eq, density, source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic9</th>\n",
              "      <td>state, unit, action, step, training, hidden_unit, control, policy, task, optimal, rate, reinforcement_learning, gradient, convergence, vector</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic10</th>\n",
              "      <td>signal, unit, pattern, training, classification, stimulus, feature, layer, frequency, response, representation, recognition, task, speech, trained</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aee9edf2-5b49-463a-932a-51854f54f7c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aee9edf2-5b49-463a-932a-51854f54f7c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aee9edf2-5b49-463a-932a-51854f54f7c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cefb9a10-af81-4bfc-b084-67fa1c1aea35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cefb9a10-af81-4bfc-b084-67fa1c1aea35')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cefb9a10-af81-4bfc-b084-67fa1c1aea35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                                                                                                                         Terms per Topic\n",
              "Topic1                                   neuron, cell, activity, pattern, response, stimulus, synaptic, spike, unit, connection, cortical, layer, firing, neural, effect\n",
              "Topic2                                       circuit, chip, cell, neuron, motion, current, voltage, analog, signal, response, direction, image, neural, visual, velocity\n",
              "Topic3                                    image, feature, object, representation, task, view, training, pixel, position, location, map, visual, region, distance, vector\n",
              "Topic4   training, class, classifier, classification, sample, distribution, prediction, vector, training_set, estimate, test, probability, linear, kernel, approximation\n",
              "Topic5                     state, probability, variable, mixture, hmm, structure, distribution, sequence, cluster, word, step, clustering, context, likelihood, training\n",
              "Topic6                    control, training, word, trajectory, recognition, character, task, position, architecture, controller, state, trained, movement, dynamic, hand\n",
              "Topic7                                             unit, state, node, rule, pattern, memory, vector, sequence, net, neuron, activation, layer, bit, recurrent, threshold\n",
              "Topic8                                 noise, equation, matrix, vector, distribution, linear, solution, dynamic, signal, gaussian, nonlinear, state, eq, density, source\n",
              "Topic9                     state, unit, action, step, training, hidden_unit, control, policy, task, optimal, rate, reinforcement_learning, gradient, convergence, vector\n",
              "Topic10               signal, unit, pattern, training, classification, stimulus, feature, layer, frequency, response, representation, recognition, task, speech, trained"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topics = [[(term, round(wt, 3))\n",
        "               for term, wt in lda_model.show_topic(n, topn=15)]\n",
        "                   for n in range(0, lda_model.num_topics)]\n",
        "\n",
        "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])\n",
        "                              for topic in topics],\n",
        "                         columns = ['Terms per Topic'],\n",
        "                         index=['Topic'+str(t) for t in range(1, lda_model.num_topics+1)]\n",
        "                         )\n",
        "topics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abiy8_Cg12b5"
      },
      "source": [
        "## Evaluating topic model quality\n",
        "\n",
        "We can use perplexity and coherence scores as measures to evaluate the topic\n",
        "model. Typically, lower the perplexity, the better the model. Similarly, the lower the\n",
        "UMass score and the higher the Cv score in coherence, the better the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkOZQdZERbzG",
        "outputId": "f2637fa0-dd81-46fa-ba79-f091de17d442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score (Cv): 0.4371627940012983\n",
            "Avg. Coherence Score (UMass): -1.0803260583515713\n",
            "Model Perplexity: -7.800330274358723\n"
          ]
        }
      ],
      "source": [
        "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus,\n",
        "                                                      texts=norm_corpus_bigrams,\n",
        "                                                      dictionary=dictionary,\n",
        "                                                      coherence='c_v')\n",
        "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
        "\n",
        "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus,\n",
        "                                                         texts=norm_corpus_bigrams,\n",
        "                                                         dictionary=dictionary,\n",
        "                                                         coherence='u_mass')\n",
        "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
        "\n",
        "perplexity = lda_model.log_perplexity(bow_corpus)\n",
        "\n",
        "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
        "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
        "print('Model Perplexity:', perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvn6Xx9N12cA"
      },
      "source": [
        "## LDA Tuning: Finding the optimal number of topics\n",
        "\n",
        "Finding the optimal number of topics in a topic model is tough, given that it is like a\n",
        "model hyperparameter that you always have to set before training the model. We can\n",
        "use an iterative approach and build several models with differing numbers of topics and\n",
        "select the one that has the highest coherence score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnw7FB6O7IbP"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYeyeNmRWy4m"
      },
      "outputs": [],
      "source": [
        "def topic_model_coherence_generator(corpus, texts, dictionary,\n",
        "                                    start_topic_count=2, end_topic_count=10, step=1):\n",
        "\n",
        "    models = []\n",
        "    coherence_scores = []\n",
        "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
        "        lda_model = gensim.models.LdaModel(corpus=bow_corpus,\n",
        "                                   id2word=dictionary,\n",
        "                                   chunksize=1740,\n",
        "                                   alpha='auto',\n",
        "                                   eta='auto',\n",
        "                                   random_state=42,\n",
        "                                   iterations=500,\n",
        "                                   num_topics=topic_nums,\n",
        "                                   passes=20,\n",
        "                                   eval_every=None)\n",
        "        cv_coherence_lda = gensim.models.CoherenceModel(model=lda_model, corpus=corpus,\n",
        "                                                                     texts=texts, dictionary=dictionary,\n",
        "                                                                     coherence='c_v')\n",
        "        coherence_score = cv_coherence_lda.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "        models.append(lda_model)\n",
        "\n",
        "    return models, coherence_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ce2eaebbfbba490a8b19974dc5981c5b",
            "5140520504464fb38f6c954218a29c17",
            "00ae0fa94baf4399971b42b224b8f9f6",
            "9cf319012c6643dfabcf8f4352c12642",
            "e224fdf17d474f938337b4b1ed4f69b8",
            "19a121811c8a470eba4660f5de9f26b6",
            "6ab3316259be453f8f46fed383ce69d7",
            "0ba03c641bc947fdaca69d60089ad285",
            "938123b52c2c487db4ee8358db476e62",
            "a1bab031da724b86bb95c705efd62a4d",
            "e9112acabcec4745af8515f10425b625"
          ]
        },
        "id": "8vgKu5RCXHrv",
        "outputId": "84d62626-4ff0-493e-e453-e8a24d034f56"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce2eaebbfbba490a8b19974dc5981c5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/29 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# !!! this is a time-consuming step\n",
        "# might take anywhere between 60-90mins depending upon your setup\n",
        "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus,\n",
        "                                                               texts=norm_corpus_bigrams,\n",
        "                                                               dictionary=dictionary,\n",
        "                                                               start_topic_count=2,\n",
        "                                                               end_topic_count=30,\n",
        "                                                               step=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EeQIjHsOXPvY",
        "outputId": "7c533b58-75e0-4bd2-d195-d366fe1e203a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"coherence_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Number of Topics\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 5,\n        \"max\": 21,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5,\n          15,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coherence Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006241340667944141,\n        \"min\": 0.4719,\n        \"max\": 0.4915,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.4745,\n          0.4903,\n          0.4815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2adc0592-66da-4ce0-887e-322030f97b58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number of Topics</th>\n",
              "      <th>Coherence Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>18</td>\n",
              "      <td>0.4915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15</td>\n",
              "      <td>0.4903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>21</td>\n",
              "      <td>0.4854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>16</td>\n",
              "      <td>0.4849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>14</td>\n",
              "      <td>0.4838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20</td>\n",
              "      <td>0.4815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>17</td>\n",
              "      <td>0.4814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>19</td>\n",
              "      <td>0.4787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.4745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>13</td>\n",
              "      <td>0.4719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2adc0592-66da-4ce0-887e-322030f97b58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2adc0592-66da-4ce0-887e-322030f97b58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2adc0592-66da-4ce0-887e-322030f97b58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b6612dbb-dd02-420e-927e-4273f4b30db1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6612dbb-dd02-420e-927e-4273f4b30db1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b6612dbb-dd02-420e-927e-4273f4b30db1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Number of Topics  Coherence Score\n",
              "16                18           0.4915\n",
              "13                15           0.4903\n",
              "19                21           0.4854\n",
              "14                16           0.4849\n",
              "12                14           0.4838\n",
              "18                20           0.4815\n",
              "15                17           0.4814\n",
              "17                19           0.4787\n",
              "3                  5           0.4745\n",
              "11                13           0.4719"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
        "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
        "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UBSRO_VqYjif",
        "outputId": "15b4d347-9555-4658-f60e-0276e915a921"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "\n",
        "x_ax = range(2, 31, 1)\n",
        "y_ax = coherence_scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_ax, y_ax, c='r')\n",
        "plt.axhline(y=0.5, c='k', linestyle='--', linewidth=2)\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "xl = plt.xlabel('Number of Topics')\n",
        "yl = plt.ylabel('Coherence Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7PlAhgx12cI"
      },
      "source": [
        "We choose the optimal number of topics as 15, based on our intuition and to see if we can get more new topics \\ trends.\n",
        "\n",
        "However you can experiment here and look at the models with lesser topics between 8 - 10.\n",
        "\n",
        "Remember the scores are heuristics and not absolute like accuracy so try to look at the topics themselves instead of just relying blindly on the score (same as other unsupervised learning methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YtPwVFdrYlxO",
        "outputId": "5db4f8da-c609-47fe-8179-8fedae5cd9a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 15].index[0]\n",
        "best_lda_model = lda_models[best_model_idx]\n",
        "best_lda_model.num_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HFHT-ezdHQeq"
      },
      "outputs": [],
      "source": [
        "# you can also run your own model with 15 topics if needed\n",
        "# although if you have already trained it earlier in the for loop\n",
        "# just reuse it as shown in the code in the previous cell\n",
        "# best_lda_model = gensim.models.LdaModel(corpus=bow_corpus,\n",
        "#                                    id2word=dictionary,\n",
        "#                                    chunksize=1740,\n",
        "#                                    alpha='auto',\n",
        "#                                    eta='auto',\n",
        "#                                    random_state=42,\n",
        "#                                    iterations=500,\n",
        "#                                    num_topics=15,\n",
        "#                                    passes=20,\n",
        "#                                    eval_every=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V0F6Lqx4Wtx"
      },
      "source": [
        "### Topics from Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y80sxSSy4fOx",
        "outputId": "a8ec7bad-68c2-4eb5-b00c-39186a70b2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic #1:\n",
            "['neuron', 'cell', 'activity', 'response', 'spike', 'synaptic', 'pattern', 'stimulus', 'firing', 'connection', 'neural', 'synapsis', 'cortical', 'simulation', 'dynamic', 'effect', 'et_al', 'signal', 'frequency', 'phase']\n",
            "\n",
            "Topic #2:\n",
            "['circuit', 'chip', 'neuron', 'current', 'voltage', 'cell', 'motion', 'analog', 'signal', 'velocity', 'neural', 'implementation', 'response', 'design', 'array', 'synapse', 'device', 'bit', 'transistor', 'digital']\n",
            "\n",
            "Topic #3:\n",
            "['word', 'task', 'training', 'feature', 'object', 'view', 'user', 'human', 'representation', 'experiment', 'image', 'recognition', 'target', 'trained', 'position', 'prediction', 'similarity', 'sequence', 'frame', 'test']\n",
            "\n",
            "Topic #4:\n",
            "['training', 'class', 'classifier', 'classification', 'feature', 'test', 'training_set', 'pattern', 'prediction', 'vector', 'sample', 'experiment', 'kernel', 'machine', 'tree', 'estimate', 'linear', 'size', 'probability', 'regression']\n",
            "\n",
            "Topic #5:\n",
            "['probability', 'state', 'variable', 'mixture', 'hmm', 'structure', 'cluster', 'distribution', 'likelihood', 'sequence', 'prior', 'clustering', 'step', 'node', 'component', 'tree', 'em', 'bayesian', 'graph', 'estimate']\n",
            "\n",
            "Topic #6:\n",
            "['control', 'trajectory', 'controller', 'movement', 'robot', 'position', 'motor', 'dynamic', 'state', 'arm', 'task', 'hand', 'forward', 'training', 'change', 'target', 'feedback', 'mapping', 'force', 'joint']\n",
            "\n",
            "Topic #7:\n",
            "['state', 'rule', 'node', 'memory', 'unit', 'vector', 'sequence', 'pattern', 'neuron', 'recurrent', 'net', 'matrix', 'bit', 'threshold', 'activation', 'size', 'dynamic', 'symbol', 'attractor', 'string']\n",
            "\n",
            "Topic #8:\n",
            "['matrix', 'signal', 'vector', 'noise', 'source', 'state', 'linear', 'component', 'nonlinear', 'ica', 'equation', 'rule', 'dynamic', 'density', 'filter', 'eq', 'pca', 'estimate', 'solution', 'estimation']\n",
            "\n",
            "Topic #9:\n",
            "['unit', 'training', 'hidden_unit', 'rate', 'vector', 'pattern', 'node', 'back_propagation', 'layer', 'gradient', 'activation', 'solution', 'architecture', 'simulation', 'step', 'equation', 'task', 'update', 'average', 'convergence']\n",
            "\n",
            "Topic #10:\n",
            "['signal', 'speech', 'face', 'frequency', 'image', 'speaker', 'sound', 'detection', 'feature', 'representation', 'channel', 'auditory', 'rate', 'subject', 'classification', 'training', 'recognition', 'frame', 'experiment', 'human']\n",
            "\n",
            "Topic #11:\n",
            "['gaussian', 'distribution', 'noise', 'vector', 'variance', 'prior', 'linear', 'approximation', 'image', 'transformation', 'distance', 'equation', 'dimensional', 'local', 'bayesian', 'matrix', 'solution', 'estimate', 'constraint', 'surface']\n",
            "\n",
            "Topic #12:\n",
            "['image', 'unit', 'layer', 'recognition', 'training', 'feature', 'character', 'net', 'pattern', 'architecture', 'trained', 'module', 'structure', 'digit', 'hidden_unit', 'object', 'representation', 'level', 'pixel', 'task']\n",
            "\n",
            "Topic #13:\n",
            "['state', 'action', 'policy', 'reinforcement_learning', 'step', 'control', 'optimal', 'reward', 'environment', 'agent', 'goal', 'cost', 'rl', 'task', 'rate', 'trial', 'td', 'iteration', 'current', 'sutton']\n",
            "\n",
            "Topic #14:\n",
            "['let', 'bound', 'distribution', 'approximation', 'theory', 'theorem', 'class', 'probability', 'xi', 'optimal', 'defined', 'equation', 'consider', 'sample', 'loss', 'estimate', 'linear', 'complexity', 'solution', 'entropy']\n",
            "\n",
            "Topic #15:\n",
            "['image', 'visual', 'unit', 'map', 'object', 'pattern', 'feature', 'cell', 'stimulus', 'layer', 'response', 'region', 'orientation', 'representation', 'spatial', 'activity', 'receptive_field', 'location', 'local', 'direction']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "topics = [[(term, round(wt, 3))\n",
        "               for term, wt in best_lda_model.show_topic(n, topn=20)]\n",
        "                   for n in range(0, best_lda_model.num_topics)]\n",
        "\n",
        "for idx, topic in enumerate(topics):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for term, wt in topic])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxtpl5Co12cL"
      },
      "source": [
        "## Viewing LDA Model topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K3yf_xhqN0tH",
        "outputId": "ce9ae838-e173-43a2-9754-ad004a12323b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"topics_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Topic 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"neuron\",\n          \"signal\",\n          \"effect\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"circuit\",\n          \"bit\",\n          \"synapse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"word\",\n          \"sequence\",\n          \"prediction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 4\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"training\",\n          \"size\",\n          \"estimate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"probability\",\n          \"bayesian\",\n          \"tree\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 6\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"control\",\n          \"mapping\",\n          \"target\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 7\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"state\",\n          \"symbol\",\n          \"size\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 8\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"matrix\",\n          \"estimate\",\n          \"eq\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 9\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"unit\",\n          \"update\",\n          \"equation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 10\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"signal\",\n          \"frame\",\n          \"training\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 11\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"gaussian\",\n          \"estimate\",\n          \"matrix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 12\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"image\",\n          \"level\",\n          \"object\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 13\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"state\",\n          \"iteration\",\n          \"trial\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 14\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"let\",\n          \"complexity\",\n          \"estimate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topic 15\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"image\",\n          \"location\",\n          \"activity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "topics_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f7a76e85-b2d3-4b74-98ce-51cb33dd245d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>Topic 3</th>\n",
              "      <th>Topic 4</th>\n",
              "      <th>Topic 5</th>\n",
              "      <th>Topic 6</th>\n",
              "      <th>Topic 7</th>\n",
              "      <th>Topic 8</th>\n",
              "      <th>Topic 9</th>\n",
              "      <th>Topic 10</th>\n",
              "      <th>Topic 11</th>\n",
              "      <th>Topic 12</th>\n",
              "      <th>Topic 13</th>\n",
              "      <th>Topic 14</th>\n",
              "      <th>Topic 15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Term1</th>\n",
              "      <td>neuron</td>\n",
              "      <td>circuit</td>\n",
              "      <td>word</td>\n",
              "      <td>training</td>\n",
              "      <td>probability</td>\n",
              "      <td>control</td>\n",
              "      <td>state</td>\n",
              "      <td>matrix</td>\n",
              "      <td>unit</td>\n",
              "      <td>signal</td>\n",
              "      <td>gaussian</td>\n",
              "      <td>image</td>\n",
              "      <td>state</td>\n",
              "      <td>let</td>\n",
              "      <td>image</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term2</th>\n",
              "      <td>cell</td>\n",
              "      <td>chip</td>\n",
              "      <td>task</td>\n",
              "      <td>class</td>\n",
              "      <td>state</td>\n",
              "      <td>trajectory</td>\n",
              "      <td>rule</td>\n",
              "      <td>signal</td>\n",
              "      <td>training</td>\n",
              "      <td>speech</td>\n",
              "      <td>distribution</td>\n",
              "      <td>unit</td>\n",
              "      <td>action</td>\n",
              "      <td>bound</td>\n",
              "      <td>visual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term3</th>\n",
              "      <td>activity</td>\n",
              "      <td>neuron</td>\n",
              "      <td>training</td>\n",
              "      <td>classifier</td>\n",
              "      <td>variable</td>\n",
              "      <td>controller</td>\n",
              "      <td>node</td>\n",
              "      <td>vector</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>face</td>\n",
              "      <td>noise</td>\n",
              "      <td>layer</td>\n",
              "      <td>policy</td>\n",
              "      <td>distribution</td>\n",
              "      <td>unit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term4</th>\n",
              "      <td>response</td>\n",
              "      <td>current</td>\n",
              "      <td>feature</td>\n",
              "      <td>classification</td>\n",
              "      <td>mixture</td>\n",
              "      <td>movement</td>\n",
              "      <td>memory</td>\n",
              "      <td>noise</td>\n",
              "      <td>rate</td>\n",
              "      <td>frequency</td>\n",
              "      <td>vector</td>\n",
              "      <td>recognition</td>\n",
              "      <td>reinforcement_learning</td>\n",
              "      <td>approximation</td>\n",
              "      <td>map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term5</th>\n",
              "      <td>spike</td>\n",
              "      <td>voltage</td>\n",
              "      <td>object</td>\n",
              "      <td>feature</td>\n",
              "      <td>hmm</td>\n",
              "      <td>robot</td>\n",
              "      <td>unit</td>\n",
              "      <td>source</td>\n",
              "      <td>vector</td>\n",
              "      <td>image</td>\n",
              "      <td>variance</td>\n",
              "      <td>training</td>\n",
              "      <td>step</td>\n",
              "      <td>theory</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term6</th>\n",
              "      <td>synaptic</td>\n",
              "      <td>cell</td>\n",
              "      <td>view</td>\n",
              "      <td>test</td>\n",
              "      <td>structure</td>\n",
              "      <td>position</td>\n",
              "      <td>vector</td>\n",
              "      <td>state</td>\n",
              "      <td>pattern</td>\n",
              "      <td>speaker</td>\n",
              "      <td>prior</td>\n",
              "      <td>feature</td>\n",
              "      <td>control</td>\n",
              "      <td>theorem</td>\n",
              "      <td>pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term7</th>\n",
              "      <td>pattern</td>\n",
              "      <td>motion</td>\n",
              "      <td>user</td>\n",
              "      <td>training_set</td>\n",
              "      <td>cluster</td>\n",
              "      <td>motor</td>\n",
              "      <td>sequence</td>\n",
              "      <td>linear</td>\n",
              "      <td>node</td>\n",
              "      <td>sound</td>\n",
              "      <td>linear</td>\n",
              "      <td>character</td>\n",
              "      <td>optimal</td>\n",
              "      <td>class</td>\n",
              "      <td>feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term8</th>\n",
              "      <td>stimulus</td>\n",
              "      <td>analog</td>\n",
              "      <td>human</td>\n",
              "      <td>pattern</td>\n",
              "      <td>distribution</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>pattern</td>\n",
              "      <td>component</td>\n",
              "      <td>back_propagation</td>\n",
              "      <td>detection</td>\n",
              "      <td>approximation</td>\n",
              "      <td>net</td>\n",
              "      <td>reward</td>\n",
              "      <td>probability</td>\n",
              "      <td>cell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term9</th>\n",
              "      <td>firing</td>\n",
              "      <td>signal</td>\n",
              "      <td>representation</td>\n",
              "      <td>prediction</td>\n",
              "      <td>likelihood</td>\n",
              "      <td>state</td>\n",
              "      <td>neuron</td>\n",
              "      <td>nonlinear</td>\n",
              "      <td>layer</td>\n",
              "      <td>feature</td>\n",
              "      <td>image</td>\n",
              "      <td>pattern</td>\n",
              "      <td>environment</td>\n",
              "      <td>xi</td>\n",
              "      <td>stimulus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term10</th>\n",
              "      <td>connection</td>\n",
              "      <td>velocity</td>\n",
              "      <td>experiment</td>\n",
              "      <td>vector</td>\n",
              "      <td>sequence</td>\n",
              "      <td>arm</td>\n",
              "      <td>recurrent</td>\n",
              "      <td>ica</td>\n",
              "      <td>gradient</td>\n",
              "      <td>representation</td>\n",
              "      <td>transformation</td>\n",
              "      <td>architecture</td>\n",
              "      <td>agent</td>\n",
              "      <td>optimal</td>\n",
              "      <td>layer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term11</th>\n",
              "      <td>neural</td>\n",
              "      <td>neural</td>\n",
              "      <td>image</td>\n",
              "      <td>sample</td>\n",
              "      <td>prior</td>\n",
              "      <td>task</td>\n",
              "      <td>net</td>\n",
              "      <td>equation</td>\n",
              "      <td>activation</td>\n",
              "      <td>channel</td>\n",
              "      <td>distance</td>\n",
              "      <td>trained</td>\n",
              "      <td>goal</td>\n",
              "      <td>defined</td>\n",
              "      <td>response</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term12</th>\n",
              "      <td>synapsis</td>\n",
              "      <td>implementation</td>\n",
              "      <td>recognition</td>\n",
              "      <td>experiment</td>\n",
              "      <td>clustering</td>\n",
              "      <td>hand</td>\n",
              "      <td>matrix</td>\n",
              "      <td>rule</td>\n",
              "      <td>solution</td>\n",
              "      <td>auditory</td>\n",
              "      <td>equation</td>\n",
              "      <td>module</td>\n",
              "      <td>cost</td>\n",
              "      <td>equation</td>\n",
              "      <td>region</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term13</th>\n",
              "      <td>cortical</td>\n",
              "      <td>response</td>\n",
              "      <td>target</td>\n",
              "      <td>kernel</td>\n",
              "      <td>step</td>\n",
              "      <td>forward</td>\n",
              "      <td>bit</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>architecture</td>\n",
              "      <td>rate</td>\n",
              "      <td>dimensional</td>\n",
              "      <td>structure</td>\n",
              "      <td>rl</td>\n",
              "      <td>consider</td>\n",
              "      <td>orientation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term14</th>\n",
              "      <td>simulation</td>\n",
              "      <td>design</td>\n",
              "      <td>trained</td>\n",
              "      <td>machine</td>\n",
              "      <td>node</td>\n",
              "      <td>training</td>\n",
              "      <td>threshold</td>\n",
              "      <td>density</td>\n",
              "      <td>simulation</td>\n",
              "      <td>subject</td>\n",
              "      <td>local</td>\n",
              "      <td>digit</td>\n",
              "      <td>task</td>\n",
              "      <td>sample</td>\n",
              "      <td>representation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term15</th>\n",
              "      <td>dynamic</td>\n",
              "      <td>array</td>\n",
              "      <td>position</td>\n",
              "      <td>tree</td>\n",
              "      <td>component</td>\n",
              "      <td>change</td>\n",
              "      <td>activation</td>\n",
              "      <td>filter</td>\n",
              "      <td>step</td>\n",
              "      <td>classification</td>\n",
              "      <td>bayesian</td>\n",
              "      <td>hidden_unit</td>\n",
              "      <td>rate</td>\n",
              "      <td>loss</td>\n",
              "      <td>spatial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term16</th>\n",
              "      <td>effect</td>\n",
              "      <td>synapse</td>\n",
              "      <td>prediction</td>\n",
              "      <td>estimate</td>\n",
              "      <td>tree</td>\n",
              "      <td>target</td>\n",
              "      <td>size</td>\n",
              "      <td>eq</td>\n",
              "      <td>equation</td>\n",
              "      <td>training</td>\n",
              "      <td>matrix</td>\n",
              "      <td>object</td>\n",
              "      <td>trial</td>\n",
              "      <td>estimate</td>\n",
              "      <td>activity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term17</th>\n",
              "      <td>et_al</td>\n",
              "      <td>device</td>\n",
              "      <td>similarity</td>\n",
              "      <td>linear</td>\n",
              "      <td>em</td>\n",
              "      <td>feedback</td>\n",
              "      <td>dynamic</td>\n",
              "      <td>pca</td>\n",
              "      <td>task</td>\n",
              "      <td>recognition</td>\n",
              "      <td>solution</td>\n",
              "      <td>representation</td>\n",
              "      <td>td</td>\n",
              "      <td>linear</td>\n",
              "      <td>receptive_field</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term18</th>\n",
              "      <td>signal</td>\n",
              "      <td>bit</td>\n",
              "      <td>sequence</td>\n",
              "      <td>size</td>\n",
              "      <td>bayesian</td>\n",
              "      <td>mapping</td>\n",
              "      <td>symbol</td>\n",
              "      <td>estimate</td>\n",
              "      <td>update</td>\n",
              "      <td>frame</td>\n",
              "      <td>estimate</td>\n",
              "      <td>level</td>\n",
              "      <td>iteration</td>\n",
              "      <td>complexity</td>\n",
              "      <td>location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term19</th>\n",
              "      <td>frequency</td>\n",
              "      <td>transistor</td>\n",
              "      <td>frame</td>\n",
              "      <td>probability</td>\n",
              "      <td>graph</td>\n",
              "      <td>force</td>\n",
              "      <td>attractor</td>\n",
              "      <td>solution</td>\n",
              "      <td>average</td>\n",
              "      <td>experiment</td>\n",
              "      <td>constraint</td>\n",
              "      <td>pixel</td>\n",
              "      <td>current</td>\n",
              "      <td>solution</td>\n",
              "      <td>local</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Term20</th>\n",
              "      <td>phase</td>\n",
              "      <td>digital</td>\n",
              "      <td>test</td>\n",
              "      <td>regression</td>\n",
              "      <td>estimate</td>\n",
              "      <td>joint</td>\n",
              "      <td>string</td>\n",
              "      <td>estimation</td>\n",
              "      <td>convergence</td>\n",
              "      <td>human</td>\n",
              "      <td>surface</td>\n",
              "      <td>task</td>\n",
              "      <td>sutton</td>\n",
              "      <td>entropy</td>\n",
              "      <td>direction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7a76e85-b2d3-4b74-98ce-51cb33dd245d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7a76e85-b2d3-4b74-98ce-51cb33dd245d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7a76e85-b2d3-4b74-98ce-51cb33dd245d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ada1a74-52ab-41cb-ae3e-950051481b16\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ada1a74-52ab-41cb-ae3e-950051481b16')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ada1a74-52ab-41cb-ae3e-950051481b16 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Topic 1         Topic 2         Topic 3         Topic 4  \\\n",
              "Term1       neuron         circuit            word        training   \n",
              "Term2         cell            chip            task           class   \n",
              "Term3     activity          neuron        training      classifier   \n",
              "Term4     response         current         feature  classification   \n",
              "Term5        spike         voltage          object         feature   \n",
              "Term6     synaptic            cell            view            test   \n",
              "Term7      pattern          motion            user    training_set   \n",
              "Term8     stimulus          analog           human         pattern   \n",
              "Term9       firing          signal  representation      prediction   \n",
              "Term10  connection        velocity      experiment          vector   \n",
              "Term11      neural          neural           image          sample   \n",
              "Term12    synapsis  implementation     recognition      experiment   \n",
              "Term13    cortical        response          target          kernel   \n",
              "Term14  simulation          design         trained         machine   \n",
              "Term15     dynamic           array        position            tree   \n",
              "Term16      effect         synapse      prediction        estimate   \n",
              "Term17       et_al          device      similarity          linear   \n",
              "Term18      signal             bit        sequence            size   \n",
              "Term19   frequency      transistor           frame     probability   \n",
              "Term20       phase         digital            test      regression   \n",
              "\n",
              "             Topic 5     Topic 6     Topic 7     Topic 8           Topic 9  \\\n",
              "Term1    probability     control       state      matrix              unit   \n",
              "Term2          state  trajectory        rule      signal          training   \n",
              "Term3       variable  controller        node      vector       hidden_unit   \n",
              "Term4        mixture    movement      memory       noise              rate   \n",
              "Term5            hmm       robot        unit      source            vector   \n",
              "Term6      structure    position      vector       state           pattern   \n",
              "Term7        cluster       motor    sequence      linear              node   \n",
              "Term8   distribution     dynamic     pattern   component  back_propagation   \n",
              "Term9     likelihood       state      neuron   nonlinear             layer   \n",
              "Term10      sequence         arm   recurrent         ica          gradient   \n",
              "Term11         prior        task         net    equation        activation   \n",
              "Term12    clustering        hand      matrix        rule          solution   \n",
              "Term13          step     forward         bit     dynamic      architecture   \n",
              "Term14          node    training   threshold     density        simulation   \n",
              "Term15     component      change  activation      filter              step   \n",
              "Term16          tree      target        size          eq          equation   \n",
              "Term17            em    feedback     dynamic         pca              task   \n",
              "Term18      bayesian     mapping      symbol    estimate            update   \n",
              "Term19         graph       force   attractor    solution           average   \n",
              "Term20      estimate       joint      string  estimation       convergence   \n",
              "\n",
              "              Topic 10        Topic 11        Topic 12  \\\n",
              "Term1           signal        gaussian           image   \n",
              "Term2           speech    distribution            unit   \n",
              "Term3             face           noise           layer   \n",
              "Term4        frequency          vector     recognition   \n",
              "Term5            image        variance        training   \n",
              "Term6          speaker           prior         feature   \n",
              "Term7            sound          linear       character   \n",
              "Term8        detection   approximation             net   \n",
              "Term9          feature           image         pattern   \n",
              "Term10  representation  transformation    architecture   \n",
              "Term11         channel        distance         trained   \n",
              "Term12        auditory        equation          module   \n",
              "Term13            rate     dimensional       structure   \n",
              "Term14         subject           local           digit   \n",
              "Term15  classification        bayesian     hidden_unit   \n",
              "Term16        training          matrix          object   \n",
              "Term17     recognition        solution  representation   \n",
              "Term18           frame        estimate           level   \n",
              "Term19      experiment      constraint           pixel   \n",
              "Term20           human         surface            task   \n",
              "\n",
              "                      Topic 13       Topic 14         Topic 15  \n",
              "Term1                    state            let            image  \n",
              "Term2                   action          bound           visual  \n",
              "Term3                   policy   distribution             unit  \n",
              "Term4   reinforcement_learning  approximation              map  \n",
              "Term5                     step         theory           object  \n",
              "Term6                  control        theorem          pattern  \n",
              "Term7                  optimal          class          feature  \n",
              "Term8                   reward    probability             cell  \n",
              "Term9              environment             xi         stimulus  \n",
              "Term10                   agent        optimal            layer  \n",
              "Term11                    goal        defined         response  \n",
              "Term12                    cost       equation           region  \n",
              "Term13                      rl       consider      orientation  \n",
              "Term14                    task         sample   representation  \n",
              "Term15                    rate           loss          spatial  \n",
              "Term16                   trial       estimate         activity  \n",
              "Term17                      td         linear  receptive_field  \n",
              "Term18               iteration     complexity         location  \n",
              "Term19                 current       solution            local  \n",
              "Term20                  sutton        entropy        direction  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topics_df = pd.DataFrame([[term for term, wt in topic]\n",
        "                              for topic in topics],\n",
        "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
        "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
        "topics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MvyOKlu4p7UG",
        "outputId": "d0c08c9d-0391-4088-8f95-742f200ddeaf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"topics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Terms per Topic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"signal, speech, face, frequency, image, speaker, sound, detection, feature, representation, channel, auditory, rate, subject, classification, training, recognition, frame, experiment, human\",\n          \"image, unit, layer, recognition, training, feature, character, net, pattern, architecture, trained, module, structure, digit, hidden_unit, object, representation, level, pixel, task\",\n          \"neuron, cell, activity, response, spike, synaptic, pattern, stimulus, firing, connection, neural, synapsis, cortical, simulation, dynamic, effect, et_al, signal, frequency, phase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "topics_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9f63576a-3a2c-46d6-a191-8093da76765d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Terms per Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic1</th>\n",
              "      <td>neuron, cell, activity, response, spike, synaptic, pattern, stimulus, firing, connection, neural, synapsis, cortical, simulation, dynamic, effect, et_al, signal, frequency, phase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic2</th>\n",
              "      <td>circuit, chip, neuron, current, voltage, cell, motion, analog, signal, velocity, neural, implementation, response, design, array, synapse, device, bit, transistor, digital</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic3</th>\n",
              "      <td>word, task, training, feature, object, view, user, human, representation, experiment, image, recognition, target, trained, position, prediction, similarity, sequence, frame, test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic4</th>\n",
              "      <td>training, class, classifier, classification, feature, test, training_set, pattern, prediction, vector, sample, experiment, kernel, machine, tree, estimate, linear, size, probability, regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic5</th>\n",
              "      <td>probability, state, variable, mixture, hmm, structure, cluster, distribution, likelihood, sequence, prior, clustering, step, node, component, tree, em, bayesian, graph, estimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic6</th>\n",
              "      <td>control, trajectory, controller, movement, robot, position, motor, dynamic, state, arm, task, hand, forward, training, change, target, feedback, mapping, force, joint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic7</th>\n",
              "      <td>state, rule, node, memory, unit, vector, sequence, pattern, neuron, recurrent, net, matrix, bit, threshold, activation, size, dynamic, symbol, attractor, string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic8</th>\n",
              "      <td>matrix, signal, vector, noise, source, state, linear, component, nonlinear, ica, equation, rule, dynamic, density, filter, eq, pca, estimate, solution, estimation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic9</th>\n",
              "      <td>unit, training, hidden_unit, rate, vector, pattern, node, back_propagation, layer, gradient, activation, solution, architecture, simulation, step, equation, task, update, average, convergence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic10</th>\n",
              "      <td>signal, speech, face, frequency, image, speaker, sound, detection, feature, representation, channel, auditory, rate, subject, classification, training, recognition, frame, experiment, human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic11</th>\n",
              "      <td>gaussian, distribution, noise, vector, variance, prior, linear, approximation, image, transformation, distance, equation, dimensional, local, bayesian, matrix, solution, estimate, constraint, surface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic12</th>\n",
              "      <td>image, unit, layer, recognition, training, feature, character, net, pattern, architecture, trained, module, structure, digit, hidden_unit, object, representation, level, pixel, task</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic13</th>\n",
              "      <td>state, action, policy, reinforcement_learning, step, control, optimal, reward, environment, agent, goal, cost, rl, task, rate, trial, td, iteration, current, sutton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic14</th>\n",
              "      <td>let, bound, distribution, approximation, theory, theorem, class, probability, xi, optimal, defined, equation, consider, sample, loss, estimate, linear, complexity, solution, entropy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic15</th>\n",
              "      <td>image, visual, unit, map, object, pattern, feature, cell, stimulus, layer, response, region, orientation, representation, spatial, activity, receptive_field, location, local, direction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f63576a-3a2c-46d6-a191-8093da76765d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f63576a-3a2c-46d6-a191-8093da76765d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f63576a-3a2c-46d6-a191-8093da76765d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-32e68f16-4d68-4f69-ad77-f938bd00b8c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32e68f16-4d68-4f69-ad77-f938bd00b8c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-32e68f16-4d68-4f69-ad77-f938bd00b8c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                                                                                                                                                                 Terms per Topic\n",
              "Topic1                        neuron, cell, activity, response, spike, synaptic, pattern, stimulus, firing, connection, neural, synapsis, cortical, simulation, dynamic, effect, et_al, signal, frequency, phase\n",
              "Topic2                               circuit, chip, neuron, current, voltage, cell, motion, analog, signal, velocity, neural, implementation, response, design, array, synapse, device, bit, transistor, digital\n",
              "Topic3                        word, task, training, feature, object, view, user, human, representation, experiment, image, recognition, target, trained, position, prediction, similarity, sequence, frame, test\n",
              "Topic4         training, class, classifier, classification, feature, test, training_set, pattern, prediction, vector, sample, experiment, kernel, machine, tree, estimate, linear, size, probability, regression\n",
              "Topic5                         probability, state, variable, mixture, hmm, structure, cluster, distribution, likelihood, sequence, prior, clustering, step, node, component, tree, em, bayesian, graph, estimate\n",
              "Topic6                                    control, trajectory, controller, movement, robot, position, motor, dynamic, state, arm, task, hand, forward, training, change, target, feedback, mapping, force, joint\n",
              "Topic7                                          state, rule, node, memory, unit, vector, sequence, pattern, neuron, recurrent, net, matrix, bit, threshold, activation, size, dynamic, symbol, attractor, string\n",
              "Topic8                                        matrix, signal, vector, noise, source, state, linear, component, nonlinear, ica, equation, rule, dynamic, density, filter, eq, pca, estimate, solution, estimation\n",
              "Topic9           unit, training, hidden_unit, rate, vector, pattern, node, back_propagation, layer, gradient, activation, solution, architecture, simulation, step, equation, task, update, average, convergence\n",
              "Topic10            signal, speech, face, frequency, image, speaker, sound, detection, feature, representation, channel, auditory, rate, subject, classification, training, recognition, frame, experiment, human\n",
              "Topic11  gaussian, distribution, noise, vector, variance, prior, linear, approximation, image, transformation, distance, equation, dimensional, local, bayesian, matrix, solution, estimate, constraint, surface\n",
              "Topic12                    image, unit, layer, recognition, training, feature, character, net, pattern, architecture, trained, module, structure, digit, hidden_unit, object, representation, level, pixel, task\n",
              "Topic13                                     state, action, policy, reinforcement_learning, step, control, optimal, reward, environment, agent, goal, cost, rl, task, rate, trial, td, iteration, current, sutton\n",
              "Topic14                    let, bound, distribution, approximation, theory, theorem, class, probability, xi, optimal, defined, equation, consider, sample, loss, estimate, linear, complexity, solution, entropy\n",
              "Topic15                 image, visual, unit, map, object, pattern, feature, cell, stimulus, layer, response, region, orientation, representation, spatial, activity, receptive_field, location, local, direction"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])\n",
        "                              for topic in topics],\n",
        "                         columns = ['Terms per Topic'],\n",
        "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
        "                         )\n",
        "topics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrveLQ5e12cP"
      },
      "source": [
        "## Interpreting Topic Model Results\n",
        "\n",
        "An interesting point to remember is, given a corpus of documents (in the form of\n",
        "features, e.g., Bag of Words) and a trained topic model, you can predict the distribution of\n",
        "topics in each document (research paper in this case).\n",
        "\n",
        "We can now get the most dominant topic per research paper with some intelligent\n",
        "sorting and indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CGXN83yDJQo8",
        "outputId": "7a3d887d-84b6-4746-ce6c-824caee3aa8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "674 \n",
            "PATYEP CLASS DEGENERACY IN AN UNRESTRICTED STORAGE \n",
            "DENSITY MEMORY \n",
            "Christopher L. Scofield, Douglas L. Reilly, \n",
            "Charles Elbaum, Leon N. Cooper \n",
            "Nestor, Inc., 1 Richmond Square, Providence, Rhode Island, \n",
            "02906. \n",
            "ABSTRACT \n",
            "The study of distributed memory systems has produced a \n",
            "number of models which work well in limited domains. \n",
            "However, until recently, the application of such systems to real- \n",
            "world problems has been difficult because of storage limitations, \n",
            "and their inherent architectural (and for serial simulation, \n",
            "computational) complexity. Recent development of memories \n",
            "with unrestricted storage capacity and economical feedforward \n",
            "architectures has opened the way to the application of such \n",
            "systems to complex pattern recognition problems. However, \n",
            "such problems are sometimes underspecified by the features \n",
            "which describe the environment, and thus a significant portion \n",
            "of the pattern environment is often non-separable. We will \n",
            "review current work on high density memo\n"
          ]
        }
      ],
      "source": [
        "# Sample paper -> paper 3\n",
        "print(papers[3][:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xYz9Pf4UN_VJ",
        "outputId": "7356ddd6-5dcb-48f3-bd47-c05368cc86a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(2, 1), (3, 3), (4, 1), (6, 3), (12, 5), (17, 4), (26, 1), (29, 1), (37, 1), (40, 8), (42, 1), (51, 1), (59, 2), (79, 2), (85, 8), (86, 1), (87, 1), (91, 1), (93, 11), (100, 2), (106, 1), (108, 2), (112, 1), (113, 1), (118, 2), (126, 1), (127, 3), (131, 1), (137, 2), (147, 2)]\n"
          ]
        }
      ],
      "source": [
        "print(bow_corpus[3][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ojE7cAX7ORuS",
        "outputId": "791e3763-8872-4cbd-f1b7-1d11e897cdb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ability', 1), ('able', 3), ('abstract', 1), ('acad_sci', 3), ('activity', 5), ('addition', 4), ('allowed', 1), ('american_institute', 1), ('another', 1), ('application', 8), ('approximate', 1), ('associative_memory', 1), ('basin_attraction', 2), ('called', 2), ('cell', 8), ('certain', 1), ('change', 1), ('chosen', 1), ('class', 11), ('collective', 2), ('compare', 1), ('complex', 2), ('composed', 1), ('computational', 1), ('condition', 2), ('consists', 1), ('constant', 3), ('continuous', 1), ('could', 2), ('define', 2)]\n"
          ]
        }
      ],
      "source": [
        "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[3][:30]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bXv0NRCXum-I"
      },
      "outputs": [],
      "source": [
        "# predict topic distribution for each paper\n",
        "tm_results = best_lda_model[bow_corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WjEHWhVGuuG5",
        "outputId": "c3304139-fe1a-4baa-9cbf-7bb9372bde83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(6, 0.64343506),\n",
              " (6, 0.45883563),\n",
              " (8, 0.9343698),\n",
              " (6, 0.4633554),\n",
              " (6, 0.47384953)]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get top most relevant topic for each paper\n",
        "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0]\n",
        "                     for topics in tm_results]\n",
        "corpus_topics[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1euv2t4dJwDl",
        "outputId": "4df17825-0a93-458c-c720-be5e03d27bf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11, 0.29105332)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check topic for paper 3 from above\n",
        "corpus_topics[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXwEpGcNKAPJ",
        "outputId": "3d2bcf4d-e3ca-4287-a71c-8f8eebccb365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Terms per Topic    memory, layer, vector, bit, node, noise, signal, training, code, pattern, processor, application, architecture, back_propagation, feature, net, matrix, solution, connection, capacity\n",
              "Name: Topic12, dtype: object"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# most relevant topic for paper 3\n",
        "topics_df.iloc[corpus_topics[3][0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFmddPmQuyXS"
      },
      "outputs": [],
      "source": [
        "corpus_topic_df = pd.DataFrame()\n",
        "corpus_topic_df['Document'] = range(0, len(papers))\n",
        "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
        "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
        "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
        "corpus_topic_df['Paper'] = [paper[:500] for paper in papers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_nNj9_t12cb"
      },
      "source": [
        "## Dominant Topics in Each Research Paper\n",
        "\n",
        "Another interesting perspective is to select any paper, view the most dominant topic in each of those papers, and see if that makes sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "pN45exiiu5sx",
        "outputId": "ffc36ecb-d0fc-4c2f-b4c4-96d3d9fa354f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bec95bfd-542a-43e4-a24a-651e9c060d4b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Topic Desc</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>72.57</td>\n",
              "      <td>unit, pattern, representation, rule, hidden_unit, word, net, activation, layer, training, character, structure, sequence, vector, task, connectionist, recognition, trained, architecture, level</td>\n",
              "      <td>5O5 \\nCONNECTING TO THE PAST \\nBruce A. MacDonald, Assistant Professor \\nKnowledge Sciences Laboratory, Computer Science Department \\nThe University of Calgary, 2500 University Drive NW \\nCalgary,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51.39</td>\n",
              "      <td>unit, pattern, representation, rule, hidden_unit, word, net, activation, layer, training, character, structure, sequence, vector, task, connectionist, recognition, trained, architecture, level</td>\n",
              "      <td>72 \\nANALYSIS AND COMPARISON OF DIFFERENT LEARNING \\nALGORITHMS FOR PATTERN ASSOCIATION PROBLEMS \\nJ. Bernasconi \\nBrown Boveri Research Center \\nCH-5405 Baden, Switzerland \\nABSTRACT \\nWe investi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>25.20</td>\n",
              "      <td>unit, pattern, representation, rule, hidden_unit, word, net, activation, layer, training, character, structure, sequence, vector, task, connectionist, recognition, trained, architecture, level</td>\n",
              "      <td>310 \\nPROBABILISTIC CHARACTERIZATION OF \\nNEURAL MODEL COMPUTATIONS \\nRichard M. Golden ' \\nUniversity of Pittsburgh, Pittsburgh, Pa. 15260 \\nABSTRACT \\nInformation retrieval in a neural network ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>29.11</td>\n",
              "      <td>memory, layer, vector, bit, node, noise, signal, training, code, pattern, processor, application, architecture, back_propagation, feature, net, matrix, solution, connection, capacity</td>\n",
              "      <td>52 \\nSupervised Learning of Probability Distributions \\nby Neural Networks \\nEric B. Baum \\nJet Propulsion Laboratory, Pasadena CA 91109 \\nFrank Wilczek \\nDepartment of Physics,Harvard University...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>37.06</td>\n",
              "      <td>memory, layer, vector, bit, node, noise, signal, training, code, pattern, processor, application, architecture, back_propagation, feature, net, matrix, solution, connection, capacity</td>\n",
              "      <td>397 \\nAN OPTIMIZATION NETWORK FOR MATRIX INVERSION \\nJu-Seog Jang, Soo-Young Lee, and Sang-Yung Shin \\nKorea Advanced Institute of Science and Technology, \\nP.O. Box 150, Cheongryang, Seoul, Korea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>49.12</td>\n",
              "      <td>neuron, spike, response, cell, signal, stimulus, frequency, firing, channel, neural, synaptic, rate, noise, activity, effect, pattern, temporal, threshold, firing_rate, et_al</td>\n",
              "      <td>402 \\nHOW THE CATFISH TRACKS ITS PREY: AN INTERACTIVE \"PIPELINED\" \\nPROCESSING SYSTEM MAY DIRECT FORAGING VIA RETICULOSPINAL NEURONS. \\nJagmeet S. Kanwal \\nDept. of Cellular &amp; Structural Biology, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>83.33</td>\n",
              "      <td>memory, layer, vector, bit, node, noise, signal, training, code, pattern, processor, application, architecture, back_propagation, feature, net, matrix, solution, connection, capacity</td>\n",
              "      <td>814 \\nNEU1OMO1PHIC NETWORKS BASED \\nON SPARSE OPTICAL ORTHOGONAL CODES \\nMario P. Vecchi and Jawad A. Salehl \\nBell Communications Research \\n435 South Street \\nMorristown, NJ 07960-1961 \\nAbstr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>65.48</td>\n",
              "      <td>neuron, spike, response, cell, signal, stimulus, frequency, firing, channel, neural, synaptic, rate, noise, activity, effect, pattern, temporal, threshold, firing_rate, et_al</td>\n",
              "      <td>715 \\nA COMPUTER SIMULATION OF CEREBRAL NEOCORTEX: \\nCOMPUTATIONAL CAPABILITIES OF NONLINEAR NEURAL NETWORKS \\nAlexander Singer* and John P. Donoghue** \\n*Department of Biophysics, Johns Hopkins U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>29.37</td>\n",
              "      <td>state, action, control, policy, step, reinforcement_learning, controller, environment, optimal, task, robot, goal, reward, agent, trajectory, td, current, reinforcement, cost, trial</td>\n",
              "      <td>249 \\nHIERARCHICAL LEARNING CONTROL - \\nAN APPROACH WITH NEURON-LIKE ASSOCIATIVE MEMORIES \\nE. Ers \\nISRA Systemtechnik GmbH, Sch6fferstr. 15, D-6100 Darmstadt, FRG \\nH. Tolle \\nTH Darmstadt, Ins...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>83.71</td>\n",
              "      <td>state, action, control, policy, step, reinforcement_learning, controller, environment, optimal, task, robot, goal, reward, agent, trajectory, td, current, reinforcement, cost, trial</td>\n",
              "      <td>642 \\nLEARNING BY STATE RECURRENCE DETECFION \\nBruce E. Rosen, James M. Goodwin*, and Jacques J. Vidal \\nUniversity of California, Los Angeles, Ca. 90024 \\nABSTRACT \\nThis research investigates a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bec95bfd-542a-43e4-a24a-651e9c060d4b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bec95bfd-542a-43e4-a24a-651e9c060d4b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bec95bfd-542a-43e4-a24a-651e9c060d4b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5482a4d5-569f-4108-9fc2-15f9680d80c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5482a4d5-569f-4108-9fc2-15f9680d80c7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5482a4d5-569f-4108-9fc2-15f9680d80c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Document  Dominant Topic  Contribution %  \\\n",
              "0         0               1           72.57   \n",
              "1         1               1           51.39   \n",
              "2         2               1           25.20   \n",
              "3         3              12           29.11   \n",
              "4         4              12           37.06   \n",
              "5         5               8           49.12   \n",
              "6         6              12           83.33   \n",
              "7         7               8           65.48   \n",
              "8         8               4           29.37   \n",
              "9         9               4           83.71   \n",
              "\n",
              "                                                                                                                                                                                         Topic Desc  \\\n",
              "0  unit, pattern, representation, rule, hidden_unit, word, net, activation, layer, training, character, structure, sequence, vector, task, connectionist, recognition, trained, architecture, level   \n",
              "1  unit, pattern, representation, rule, hidden_unit, word, net, activation, layer, training, character, structure, sequence, vector, task, connectionist, recognition, trained, architecture, level   \n",
              "2  unit, pattern, representation, rule, hidden_unit, word, net, activation, layer, training, character, structure, sequence, vector, task, connectionist, recognition, trained, architecture, level   \n",
              "3            memory, layer, vector, bit, node, noise, signal, training, code, pattern, processor, application, architecture, back_propagation, feature, net, matrix, solution, connection, capacity   \n",
              "4            memory, layer, vector, bit, node, noise, signal, training, code, pattern, processor, application, architecture, back_propagation, feature, net, matrix, solution, connection, capacity   \n",
              "5                    neuron, spike, response, cell, signal, stimulus, frequency, firing, channel, neural, synaptic, rate, noise, activity, effect, pattern, temporal, threshold, firing_rate, et_al   \n",
              "6            memory, layer, vector, bit, node, noise, signal, training, code, pattern, processor, application, architecture, back_propagation, feature, net, matrix, solution, connection, capacity   \n",
              "7                    neuron, spike, response, cell, signal, stimulus, frequency, firing, channel, neural, synaptic, rate, noise, activity, effect, pattern, temporal, threshold, firing_rate, et_al   \n",
              "8             state, action, control, policy, step, reinforcement_learning, controller, environment, optimal, task, robot, goal, reward, agent, trajectory, td, current, reinforcement, cost, trial   \n",
              "9             state, action, control, policy, step, reinforcement_learning, controller, environment, optimal, task, robot, goal, reward, agent, trajectory, td, current, reinforcement, cost, trial   \n",
              "\n",
              "                                                                                                                                                                                                     Paper  \n",
              "0  5O5 \\nCONNECTING TO THE PAST \\nBruce A. MacDonald, Assistant Professor \\nKnowledge Sciences Laboratory, Computer Science Department \\nThe University of Calgary, 2500 University Drive NW \\nCalgary,...  \n",
              "1  72 \\nANALYSIS AND COMPARISON OF DIFFERENT LEARNING \\nALGORITHMS FOR PATTERN ASSOCIATION PROBLEMS \\nJ. Bernasconi \\nBrown Boveri Research Center \\nCH-5405 Baden, Switzerland \\nABSTRACT \\nWe investi...  \n",
              "2  310 \\nPROBABILISTIC CHARACTERIZATION OF \\nNEURAL MODEL COMPUTATIONS \\nRichard M. Golden ' \\nUniversity of Pittsburgh, Pittsburgh, Pa. 15260 \\nABSTRACT \\nInformation retrieval in a neural network ...  \n",
              "3  52 \\nSupervised Learning of Probability Distributions \\nby Neural Networks \\nEric B. Baum \\nJet Propulsion Laboratory, Pasadena CA 91109 \\nFrank Wilczek \\nDepartment of Physics,Harvard University...  \n",
              "4  397 \\nAN OPTIMIZATION NETWORK FOR MATRIX INVERSION \\nJu-Seog Jang, Soo-Young Lee, and Sang-Yung Shin \\nKorea Advanced Institute of Science and Technology, \\nP.O. Box 150, Cheongryang, Seoul, Korea...  \n",
              "5  402 \\nHOW THE CATFISH TRACKS ITS PREY: AN INTERACTIVE \"PIPELINED\" \\nPROCESSING SYSTEM MAY DIRECT FORAGING VIA RETICULOSPINAL NEURONS. \\nJagmeet S. Kanwal \\nDept. of Cellular & Structural Biology, ...  \n",
              "6  814 \\nNEU1OMO1PHIC NETWORKS BASED \\nON SPARSE OPTICAL ORTHOGONAL CODES \\nMario P. Vecchi and Jawad A. Salehl \\nBell Communications Research \\n435 South Street \\nMorristown, NJ 07960-1961 \\nAbstr...  \n",
              "7  715 \\nA COMPUTER SIMULATION OF CEREBRAL NEOCORTEX: \\nCOMPUTATIONAL CAPABILITIES OF NONLINEAR NEURAL NETWORKS \\nAlexander Singer* and John P. Donoghue** \\n*Department of Biophysics, Johns Hopkins U...  \n",
              "8  249 \\nHIERARCHICAL LEARNING CONTROL - \\nAN APPROACH WITH NEURON-LIKE ASSOCIATIVE MEMORIES \\nE. Ers \\nISRA Systemtechnik GmbH, Sch6fferstr. 15, D-6100 Darmstadt, FRG \\nH. Tolle \\nTH Darmstadt, Ins...  \n",
              "9  642 \\nLEARNING BY STATE RECURRENCE DETECFION \\nBruce E. Rosen, James M. Goodwin*, and Jacques J. Vidal \\nUniversity of California, Los Angeles, Ca. 90024 \\nABSTRACT \\nThis research investigates a ...  "
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_topic_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqQRtvzsRSrs"
      },
      "source": [
        "## Inference on existing papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0QF6K53v4zN",
        "outputId": "d32cca04-4e91-410e-9daa-b6e39e928e5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[665, 790, 532]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_paper_patterns = ['Feudal Reinforcement Learning \\nPeter', 'Illumination-Invariant Face Recognition with a', 'Improved Hidden Markov Model Speech Recognition']\n",
        "sample_paper_idxs = [idx for pattern in sample_paper_patterns\n",
        "                            for idx, content in enumerate(papers)\n",
        "                                if pattern in content]\n",
        "sample_paper_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "d7JrXUbsw0bt",
        "outputId": "92985392-ae85-4bd4-a21e-e54fac69b91e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-48d1c495-1f96-441c-9c09-9dfa983f88e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Dominant Topic</th>\n",
              "      <th>Contribution %</th>\n",
              "      <th>Topic Desc</th>\n",
              "      <th>Paper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>532</td>\n",
              "      <td>7</td>\n",
              "      <td>79.48</td>\n",
              "      <td>training, unit, speech, trained, word, feature, recognition, task, architecture, experiment, test, classification, table, speaker, node, class, mlp, hidden_unit, training_set, prediction</td>\n",
              "      <td>Improved Hidden Markov Model \\nSpeech Recognition Using \\nRadial Basis Function Networks \\nElliot Singer and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nLexington, MA 02173-9108, USA \\nAbstrac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>665</td>\n",
              "      <td>4</td>\n",
              "      <td>86.31</td>\n",
              "      <td>state, action, control, policy, step, reinforcement_learning, controller, environment, optimal, task, robot, goal, reward, agent, trajectory, td, current, reinforcement, cost, trial</td>\n",
              "      <td>Feudal Reinforcement Learning \\nPeter Dayan \\nCNL \\nThe Salk Institute \\nPO Box 85800 \\nSan Diego CA 92186-5800, USA \\ndayanhelmholtz. sdsc. edu \\nGeoffrey E Hinton \\nDepartment of Computer Scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>790</td>\n",
              "      <td>2</td>\n",
              "      <td>66.40</td>\n",
              "      <td>image, object, feature, pixel, face, view, visual, representation, recognition, region, task, surface, location, local, position, shape, training, filter, scene, motion</td>\n",
              "      <td>Illumination-Invariant Face Recognition with a \\nContrast Sensitive Silicon Retina \\nJoachim M. Buhmann \\nRheinische Friedrich-Wilhelms-Universitfit \\nInstitut ftir Informatik II, R6merstrage 164 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48d1c495-1f96-441c-9c09-9dfa983f88e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48d1c495-1f96-441c-9c09-9dfa983f88e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48d1c495-1f96-441c-9c09-9dfa983f88e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78d26db3-3e84-4cdb-8a21-5fcf1ed15927\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78d26db3-3e84-4cdb-8a21-5fcf1ed15927')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78d26db3-3e84-4cdb-8a21-5fcf1ed15927 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Document  Dominant Topic  Contribution %  \\\n",
              "532       532               7           79.48   \n",
              "665       665               4           86.31   \n",
              "790       790               2           66.40   \n",
              "\n",
              "                                                                                                                                                                                     Topic Desc  \\\n",
              "532  training, unit, speech, trained, word, feature, recognition, task, architecture, experiment, test, classification, table, speaker, node, class, mlp, hidden_unit, training_set, prediction   \n",
              "665       state, action, control, policy, step, reinforcement_learning, controller, environment, optimal, task, robot, goal, reward, agent, trajectory, td, current, reinforcement, cost, trial   \n",
              "790                    image, object, feature, pixel, face, view, visual, representation, recognition, region, task, surface, location, local, position, shape, training, filter, scene, motion   \n",
              "\n",
              "                                                                                                                                                                                                       Paper  \n",
              "532  Improved Hidden Markov Model \\nSpeech Recognition Using \\nRadial Basis Function Networks \\nElliot Singer and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nLexington, MA 02173-9108, USA \\nAbstrac...  \n",
              "665  Feudal Reinforcement Learning \\nPeter Dayan \\nCNL \\nThe Salk Institute \\nPO Box 85800 \\nSan Diego CA 92186-5800, USA \\ndayanhelmholtz. sdsc. edu \\nGeoffrey E Hinton \\nDepartment of Computer Scien...  \n",
              "790  Illumination-Invariant Face Recognition with a \\nContrast Sensitive Silicon Retina \\nJoachim M. Buhmann \\nRheinische Friedrich-Wilhelms-Universitfit \\nInstitut ftir Informatik II, R6merstrage 164 ...  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "(corpus_topic_df[corpus_topic_df['Document']\n",
        "                 .isin(sample_paper_idxs)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S84f-T7RVED"
      },
      "source": [
        "## Topic Inference on New Papers (Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "50rVOoraO48k",
        "outputId": "88a2fb17-f0c2-42d8-cc58-f0537b0cdab1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nEfficient Visual Recognition with Deep Neural Networks: A Survey on Recent Advances and New Directions\\nYang Wu, Dingheng Wang, Xiaotong Lu, Fan Yang, Guoqi Li, Weisheng Dong, Jianbo Shi\\nVisual recognition is currently one of the most important and active research areas in computer vision, \\npattern recognition, and even the general field of artificial intelligence. \\nIt has great fundamental importance and strong industrial needs. \\nDeep neural networks (DNNs) have largely boosted their performances on many concrete tasks, \\nwith the help of large amounts of training data and new powerful computation resources. \\nThough recognition accuracy is usually the first concern for new progresses, \\nefficiency is actually rather important and sometimes critical for both academic research \\nand industrial applications. Moreover, insightful views on the opportunities and challenges \\nof efficiency are also highly required for the entire community. \\nWhile general surveys on the efficiency issue of DNNs have been done from various perspectives, \\nas far as we are aware, scarcely any of them focused on visual recognition systematically, \\nand thus it is unclear which progresses are applicable to it and what else should be concerned. \\nIn this paper, we present the review of the recent advances with our suggestions on the new \\npossible directions towards improving the efficiency of DNN-related visual recognition approaches. \\nWe investigate not only from the model but also the data point of view \\n(which is not the case in existing surveys), and focus on three most studied \\ndata types (images, videos and points). This paper attempts to provide a systematic summary \\nvia a comprehensive survey which can serve as a valuable reference and inspire both researchers \\nand practitioners who work on visual recognition problems.\\n'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_paper = \"\"\"\n",
        "Efficient Visual Recognition with Deep Neural Networks: A Survey on Recent Advances and New Directions\n",
        "Yang Wu, Dingheng Wang, Xiaotong Lu, Fan Yang, Guoqi Li, Weisheng Dong, Jianbo Shi\n",
        "Visual recognition is currently one of the most important and active research areas in computer vision,\n",
        "pattern recognition, and even the general field of artificial intelligence.\n",
        "It has great fundamental importance and strong industrial needs.\n",
        "Deep neural networks (DNNs) have largely boosted their performances on many concrete tasks,\n",
        "with the help of large amounts of training data and new powerful computation resources.\n",
        "Though recognition accuracy is usually the first concern for new progresses,\n",
        "efficiency is actually rather important and sometimes critical for both academic research\n",
        "and industrial applications. Moreover, insightful views on the opportunities and challenges\n",
        "of efficiency are also highly required for the entire community.\n",
        "While general surveys on the efficiency issue of DNNs have been done from various perspectives,\n",
        "as far as we are aware, scarcely any of them focused on visual recognition systematically,\n",
        "and thus it is unclear which progresses are applicable to it and what else should be concerned.\n",
        "In this paper, we present the review of the recent advances with our suggestions on the new\n",
        "possible directions towards improving the efficiency of DNN-related visual recognition approaches.\n",
        "We investigate not only from the model but also the data point of view\n",
        "(which is not the case in existing surveys), and focus on three most studied\n",
        "data types (images, videos and points). This paper attempts to provide a systematic summary\n",
        "via a comprehensive survey which can serve as a valuable reference and inspire both researchers\n",
        "and practitioners who work on visual recognition problems.\n",
        "\"\"\"\n",
        "\n",
        "new_paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOY_6U8zRYkb"
      },
      "source": [
        "## Pre-process Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SFMQOnvYdE4"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0I7hWMGPQ_q",
        "outputId": "fc05751a-27ef-40ba-e4e5-388ed2fe13fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 143.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['efficient', 'visual', 'recognition', 'deep', 'neural', 'network', 'survey', 'recent', 'advance', 'new', 'direction', 'yang', 'wu', 'dingheng', 'wang', 'xiaotong', 'lu', 'fan', 'yang', 'guoqi', 'li', 'weisheng', 'dong', 'jianbo', 'shi', 'visual', 'recognition', 'currently', 'one', 'important']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "preprocessed_papers = normalize_corpus([new_paper])\n",
        "print(preprocessed_papers[0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkf7nKhURaYX"
      },
      "source": [
        "## Generate Influential Bi-grams if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUzIztYHPYeU",
        "outputId": "8a8a810d-c8fc-406c-85ec-732764b1fd50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['efficient', 'visual', 'recognition', 'deep', 'neural_network', 'survey', 'recent', 'advance', 'new', 'direction', 'yang', 'wu', 'dingheng', 'wang', 'xiaotong', 'lu', 'fan', 'yang', 'guoqi', 'li', 'weisheng', 'dong', 'jianbo', 'shi', 'visual', 'recognition', 'currently', 'one', 'important', 'active']\n"
          ]
        }
      ],
      "source": [
        "bigrams_corpus = [bigram_model[doc] for doc in preprocessed_papers]\n",
        "print(bigrams_corpus[0][0:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NWsbx_cRep7"
      },
      "source": [
        "## Generate BOW Vectors from Training Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypm5UXrZPtC6",
        "outputId": "1a90e8c7-61d8-4d2f-9cf8-bccb00412586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(19, 1), (40, 1), (44, 1), (46, 1), (91, 1), (117, 1), (237, 1), (279, 1), (295, 2), (316, 1), (387, 1), (417, 1), (473, 2), (492, 2), (512, 1), (515, 2), (579, 1), (586, 1), (595, 1), (602, 1), (612, 1), (617, 1), (634, 1), (637, 2), (663, 1), (739, 1), (758, 1), (766, 1), (843, 1), (892, 1)]\n"
          ]
        }
      ],
      "source": [
        "bow_corpus = [dictionary.doc2bow(text) for text in bigrams_corpus]\n",
        "print(bow_corpus[0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqXuFNw3RiLg"
      },
      "source": [
        "## Use trained topic model to predict topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWSAMumoQGTB",
        "outputId": "4936a3cc-1587-46af-9b76-a2a3d95bc960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('active', 1), ('application', 1), ('area', 1), ('artificial_intelligence', 1), ('challenge', 1), ('computation', 1), ('far', 1), ('highly', 1), ('important', 2), ('investigate', 1), ('need', 1), ('paper_present', 1), ('progress', 2), ('recent', 2), ('required', 1), ('research', 2), ('strong', 1), ('suggestion', 1), ('task', 1), ('though', 1), ('training', 1), ('type', 1), ('various', 1), ('view', 2), ('actually', 1), ('critical', 1), ('else', 1), ('even', 1), ('moreover', 1), ('rather', 1)]\n"
          ]
        }
      ],
      "source": [
        "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[0][:30]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQlCfP2Rmpp"
      },
      "source": [
        "## Show most relevant topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ly1ZQkzQLhW",
        "outputId": "bd7573b1-db70-4487-cec6-22859660863e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 0.5862816), (6, 0.272409), (11, 0.1375469)]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_topics = best_lda_model[bow_corpus][0]\n",
        "predicted_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTYgVVlRQUU4",
        "outputId": "52fdf17a-690e-4a51-845f-dc9ee59a396d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 0.5862816)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_topic = max(predicted_topics, key=lambda x: x[1])\n",
        "top_topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MypZEfwQbrl",
        "outputId": "7875ea69-f5e9-4f52-c35d-ef0ef66f7908"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_topic_idx = top_topic[0]\n",
        "top_topic_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "sI3XLFfkQrPo",
        "outputId": "72812727-7022-4c02-c991-fa0fce93d961"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-21088a53-ee41-4ef9-8824-3345bbfec13f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Terms per Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic2</th>\n",
              "      <td>image, object, feature, pixel, face, view, visual, representation, recognition, region, task, surface, location, local, position, shape, training, filter, scene, motion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21088a53-ee41-4ef9-8824-3345bbfec13f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21088a53-ee41-4ef9-8824-3345bbfec13f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21088a53-ee41-4ef9-8824-3345bbfec13f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                                                                                                                                 Terms per Topic\n",
              "Topic2  image, object, feature, pixel, face, view, visual, representation, recognition, region, task, surface, location, local, position, shape, training, filter, scene, motion"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topics_df.iloc[[top_topic_idx]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYZc82hoLhMn"
      },
      "source": [
        "Looking at the paper abstract our topic model did pretty well in predicting a very relevant topic for the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1VYw5guQ01h",
        "outputId": "db4621ac-a02a-4c49-b718-e53e93ec5776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Efficient Visual Recognition with Deep Neural Networks: A Survey on Recent Advances and New Directions\n",
            "Yang Wu, Dingheng Wang, Xiaotong Lu, Fan Yang, Guoqi Li, Weisheng Dong, Jianbo Shi\n",
            "Visual recognition is currently one of the most important and active research areas in computer vision, \n",
            "pattern recognition, and even the general field of artificial intelligence. \n",
            "It has great fundamental importance and strong industrial needs. \n",
            "Deep neural networks (DNNs) have largely boosted their performances on many concrete tasks, \n",
            "with the help of large amounts of training data and new powerful computation resources. \n",
            "Though recognition accuracy is usually the first concern for new progresses, \n",
            "efficiency is actually rather important and sometimes critical for both academic research \n",
            "and industrial applications. Moreover, insightful views on the opportunities and challenges \n",
            "of efficiency are also highly required for the entire community. \n",
            "While general surveys on the efficiency issue of DNNs have been done from various perspectives, \n",
            "as far as we are aware, scarcely any of them focused on visual recognition systematically, \n",
            "and thus it is unclear which progresses are applicable to it and what else should be concerned. \n",
            "In this paper, we present the review of the recent advances with our suggestions on the new \n",
            "possible directions towards improving the efficiency of DNN-related visual recognition approaches. \n",
            "We investigate not only from the model but also the data point of view \n",
            "(which is not the case in existing surveys), and focus on three most studied \n",
            "data types (images, videos and points). This paper attempts to provide a systematic summary \n",
            "via a comprehensive survey which can serve as a valuable reference and inspire both researchers \n",
            "and practitioners who work on visual recognition problems.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(new_paper)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ae0fa94baf4399971b42b224b8f9f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba03c641bc947fdaca69d60089ad285",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_938123b52c2c487db4ee8358db476e62",
            "value": 0
          }
        },
        "0ba03c641bc947fdaca69d60089ad285": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a121811c8a470eba4660f5de9f26b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5140520504464fb38f6c954218a29c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a121811c8a470eba4660f5de9f26b6",
            "placeholder": "​",
            "style": "IPY_MODEL_6ab3316259be453f8f46fed383ce69d7",
            "value": "  0%"
          }
        },
        "6ab3316259be453f8f46fed383ce69d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "938123b52c2c487db4ee8358db476e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cf319012c6643dfabcf8f4352c12642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1bab031da724b86bb95c705efd62a4d",
            "placeholder": "​",
            "style": "IPY_MODEL_e9112acabcec4745af8515f10425b625",
            "value": " 0/29 [00:00&lt;?, ?it/s]"
          }
        },
        "a1bab031da724b86bb95c705efd62a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce2eaebbfbba490a8b19974dc5981c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5140520504464fb38f6c954218a29c17",
              "IPY_MODEL_00ae0fa94baf4399971b42b224b8f9f6",
              "IPY_MODEL_9cf319012c6643dfabcf8f4352c12642"
            ],
            "layout": "IPY_MODEL_e224fdf17d474f938337b4b1ed4f69b8"
          }
        },
        "e224fdf17d474f938337b4b1ed4f69b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9112acabcec4745af8515f10425b625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
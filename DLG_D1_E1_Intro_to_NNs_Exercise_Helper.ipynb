{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astrapi69/DroidBallet/blob/master/DLG_D1_E1_Intro_to_NNs_Exercise_Helper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='Q0'></a>\n",
        "<center><a target=\"_blank\" href=\"https://learning.constructor.org/\"><img src=\"https://drive.google.com/uc?id=1wxkbM60NlBlkbGK1JqUypKL24RrTiiYk\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "\n",
        "_____\n",
        "\n",
        "<center>Constructor Learning, 2023</center>"
      ],
      "metadata": {
        "id": "tK6EgIeChktu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj-RvpTPhkiJ"
      },
      "source": [
        "# Exercise: Feed-forward NNs for Structured Data Classification - Day 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2RsfhsdhkiN"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "The idea of this exercise is to learn how to do structured data classification using neural networks, starting from a raw\n",
        "CSV file. Our data includes both numerical and categorical features.\n",
        "\n",
        "### The dataset\n",
        "\n",
        "[Our dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease) is provided by the\n",
        "Cleveland Clinic Foundation for Heart Disease.\n",
        "It's a CSV file with 303 rows. Each row contains information about a patient (a\n",
        "**sample**), and each column describes an attribute of the patient (a **feature**). We\n",
        "use the features to predict whether a patient has a heart disease (**binary\n",
        "classification**).\n",
        "\n",
        "Here's the description of each feature:\n",
        "\n",
        "Column| Description| Feature Type\n",
        "------------|--------------------|----------------------\n",
        "Age | Age in years | Numerical\n",
        "Sex | (1 = male; 0 = female) | Categorical\n",
        "CP | Chest pain type (0, 1, 2, 3, 4) | Categorical\n",
        "Trestbpd | Resting blood pressure (in mm Hg on admission) | Numerical\n",
        "Chol | Serum cholesterol in mg/dl | Numerical\n",
        "FBS | fasting blood sugar in 120 mg/dl (1 = true; 0 = false) | Categorical\n",
        "RestECG | Resting electrocardiogram results (0, 1, 2) | Categorical\n",
        "Thalach | Maximum heart rate achieved | Numerical\n",
        "Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical\n",
        "Oldpeak | ST depression induced by exercise relative to rest | Numerical\n",
        "Slope | Slope of the peak exercise ST segment | Numerical\n",
        "CA | Number of major vessels (0-3) colored by fluoroscopy | Both numerical & categorical\n",
        "Thal | 3 = normal; 6 = fixed defect; 7 = reversible defect | Categorical\n",
        "Target | Diagnosis of heart disease (1 = true; 0 = false) | Target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Objectives - Day 1\n",
        "\n",
        "\n",
        "1. Your key task is to perform a binary classification problem to predict heart disease based on the given data by splitting it into train-valid-test datasets\n",
        "\n",
        "2. You will build a variety of dense neural network models starting from simple 1-layer NNs to 2 and 3 layer dense NNs\n",
        "\n",
        "3. You will also plot learning curves to visualize training performance over epochs\n",
        "\n",
        "4. You will also evaluate the performance of the models on the test dataset\n",
        "\n",
        "5. You will also build a model using class weights to tackle class imbalance\n",
        "\n"
      ],
      "metadata": {
        "id": "4mHe52Xki94Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlZAiMhyhkiO"
      },
      "source": [
        "## Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOKS_8sPhkiP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(3) # reproducibility"
      ],
      "metadata": {
        "id": "djYfDqpaoOgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMmJ6lLVhkiQ"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "Let's download the data and load it into a Pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcWRKqt7hkiR"
      },
      "outputs": [],
      "source": [
        "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
        "df = pd.read_csv(file_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPeGuic2hkiS"
      },
      "source": [
        "The dataset includes 303 samples with 14 columns per sample (13 features, plus the target\n",
        "label):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY53Y7TOhkiT",
        "outputId": "a24dd39b-a105-44ae-9c62-c5aece681179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blfCV3iHhkiT"
      },
      "source": [
        "Here's a preview of a few samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epBGUQzWhkiU"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHQ2UgoIhkiV"
      },
      "source": [
        "The last column, \"target\", indicates whether the patient has a heart disease (1) or not\n",
        "(0)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the distribution of the target column"
      ],
      "metadata": {
        "id": "qWKu1GeQjpkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.target.value_counts()"
      ],
      "metadata": {
        "id": "Ybl3flDXjvoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Split Dataset into Train, Validation and Test Datasets\n",
        "\n",
        "Use stratified sampling to ensure similar `target` class distribution in the dataset splits when using `train_test_split()`\n",
        "\n",
        "Use a split of 60:20:20 for train-valid-test splits\n",
        "For reproducibility set the `random_state` to `42`"
      ],
      "metadata": {
        "id": "xTyctJAqkcJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5C8ZehhEkwPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sWdcIRnHRAHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Data Pre-processing\n",
        "\n",
        "Recall the data pre-processing you had learnt during the ML week! Perform the following tasks to have clean and pre-processed datasets for your training, validation and test datasets.\n",
        "\n",
        "Key Steps:\n",
        "\n",
        "1. One-hot encode categorical data\n",
        "2. Standard Scaling numerical data\n",
        "3. Combine categorical and numeric data together into a single dataframe \\ numpy array\n",
        "\n",
        "Hints: Leverage code from [here](https://colab.research.google.com/drive/1ISCLIEkrLhtNo0r-hAmA6fYA6nkB1o59) [pre-processing parts only]"
      ],
      "metadata": {
        "id": "N9eSMUg3HCF5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXnWGXRj7T4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Lfk0DC47VdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Training simple 1-layer Neural Networks\n",
        "\n",
        "Run the following experiments separately to train 1-layer neural networks, evaluate the performance by looking at learning curve plots and finally check the performance of each of the following models on the test dataset.\n",
        "\n",
        "Key workflow:\n",
        "\n",
        "- Build model using architecture specification based on experiment\n",
        "- Plot learning curves from model training to visualize performance over epochs on training and validation data\n",
        "- Use trained model to predict and evaluate performance on test data\n",
        "- Build separate models for each experiment\n",
        "\n",
        "\n",
        "### Experiment 1 - Basic NN:\n",
        "- 1-Dense Hidden Layer, 32 units, `relu` activation function\n",
        "- 1-Dense Output Layer, 1 unit, `sigmoid` activation function\n",
        "- learning rate: 0.001\n",
        "- optimizer is SGD\n",
        "- metrics: 'accuracy', [precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision), [recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall)\n",
        "- loss: [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
        "- epochs: 500\n",
        "- batch size: 32\n",
        "- use training data and validation data in `fit()` function\n",
        "- use `predict()` on test data and show confusion matrix and classification reports\n",
        "\n",
        "<br>\n",
        "\n",
        "### Experiment 2 - NN with Adam Optimizer:\n",
        "- 1-Dense Hidden Layer, 32 units, `relu` activation function\n",
        "- 1-Dense Output Layer, 1 unit, `sigmoid` activation function\n",
        "- learning rate: 0.001\n",
        "- __optimizer is Adam__\n",
        "- metrics: 'accuracy', [precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision), [recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall)\n",
        "- loss: [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
        "- epochs: 500\n",
        "- batch size: 32\n",
        "- use training data and validation data in `fit()` function\n",
        "- use `predict()` on test data and show confusion matrix and classification reports\n",
        "\n",
        "<br>\n",
        "\n",
        "### Experiment 3 - Experiment with lower Learning Rate:\n",
        "- 1-Dense Hidden Layer, 32 units, `relu` activation function\n",
        "- 1-Dense Output Layer, 1 unit, `sigmoid` activation function\n",
        "- __learning rate: 0.0001__\n",
        "- __optimizer is Adam__\n",
        "- metrics: 'accuracy', [precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision), [recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall)\n",
        "- loss: [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
        "- epochs: 500\n",
        "- batch size: 32\n",
        "- use training data and validation data in `fit()` function\n",
        "- use `predict()` on test data and show confusion matrix and classification reports\n",
        "\n",
        "<br>\n",
        "\n",
        "### Experiment 4 - Experiment with Early Stopping:\n",
        "- 1-Dense Hidden Layer, 32 units, `relu` activation function\n",
        "- 1-Dense Output Layer, 1 unit, `sigmoid` activation function\n",
        "- __learning rate: 0.0001__\n",
        "- __optimizer is Adam__\n",
        "- metrics: 'accuracy', [precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision), [recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall)\n",
        "- loss: [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
        "- __epochs: 10000__\n",
        "- __Use the [early stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) callback to stop training as soon as the validation loss doesn't decrease after 10 epochs i.e. `patience=10` and `monitor='val_loss'`__\n",
        "- batch size: 32\n",
        "- use training data and validation data in `fit()` function\n",
        "- use `predict()` on test data and show confusion matrix and classification reports\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AOOGNduXHzEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hint: Utility function for plotting learning curves\n",
        "\n",
        "You can use the following function to plot the learning curves after training.\n",
        "\n",
        "Remember to do the following during training:\n",
        "\n",
        "```\n",
        "history = model.fit(.......)\n",
        "\n",
        "# to plot the curves\n",
        "plot_metrics(history)\n",
        "```"
      ],
      "metadata": {
        "id": "eUpTfVH_LR17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_metrics(history):\n",
        "\n",
        "  keys = history.history.keys()\n",
        "  metrics = ['loss', 'accuracy', 'precision', 'recall']\n",
        "  plt.figure(figsize=(12, 10))\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.capitalize()\n",
        "    metric_name = [item for item in keys if metric in item and 'val_'+metric not in item][0]\n",
        "    val_metric_name = [item for item in keys if 'val_'+metric in item][0]\n",
        "\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history.epoch, history.history[metric_name], color='b', label='Train')\n",
        "    plt.plot(history.epoch, history.history[val_metric_name], color='r',\n",
        "             linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "ckAw8WMMQxkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Task 3 Below"
      ],
      "metadata": {
        "id": "G-4MUCM7LqsK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dx-AXcJuLzYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBxgIW6eMWpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Training deep multi-layer Neural Networks\n",
        "\n",
        "Run the following experiments separately to train multi-layer neural networks, evaluate the performance by looking at learning curve plots and finally check the performance of each of the following models on the test dataset.\n",
        "\n",
        "Key workflow:\n",
        "\n",
        "- Build model using architecture specification based on experiment\n",
        "- Plot learning curves from model training to visualize performance over epochs on training and validation data\n",
        "- Use trained model to predict and evaluate performance on test data\n",
        "- Build separate models for each experiment\n",
        "\n",
        "\n",
        "### Experiment 1 -  2-layer NN:  \n",
        "- __2-Dense Hidden Layer, 32 units, `relu` activation function__\n",
        "- 1-Dense Output Layer, 1 unit, `sigmoid` activation function\n",
        "- __learning rate: 0.0001__\n",
        "- __optimizer is Adam__\n",
        "- metrics: 'accuracy', [precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision), [recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall)\n",
        "- loss: [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
        "- __epochs: 10000__\n",
        "- __Use the [early stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) callback to stop training as soon as the validation loss doesn't decrease after 10 epochs i.e. `patience=10` and `monitor='val_loss'`__\n",
        "- batch size: 32\n",
        "- use training data and validation data in `fit()` function\n",
        "- use `predict()` on test data and show confusion matrix and classification reports\n",
        "\n",
        "<br>\n",
        "\n",
        "### Experiment 2 -  3-layer NN:  \n",
        "- __3-Dense Hidden Layer, 32 units, `relu` activation function__\n",
        "- 1-Dense Output Layer, 1 unit, `sigmoid` activation function\n",
        "- __learning rate: 0.0001__\n",
        "- __optimizer is Adam__\n",
        "- metrics: 'accuracy', [precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision), [recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall)\n",
        "- loss: [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
        "- __epochs: 10000__\n",
        "- __Use the [early stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) callback to stop training as soon as the validation loss doesn't decrease after 10 epochs i.e. `patience=10` and `monitor='val_loss'`__\n",
        "- batch size: 32\n",
        "- use training data and validation data in `fit()` function\n",
        "- use `predict()` on test data and show confusion matrix and classification reports\n"
      ],
      "metadata": {
        "id": "OKJJmM_sMyti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Task 4 Below"
      ],
      "metadata": {
        "id": "-P0edFr4N9Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7r_R5DosdW6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xDUUzpD4dvgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5: Training deep multi-layer Neural Networks with Class Weights to tackle Class Imbalance\n",
        "\n",
        "We know that our dataset is heavily imbalanced between the two classes, feel free to leverage the`class_weight` parameter in the `model.fit()` function and experiment with your own weights or use [compute class weight](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html) from `sklearn`\n",
        "\n",
        "\n",
        "Run the following experiment to train multi-layer neural networks, evaluate the performance by looking at learning curve plots and finally check the performance of each of the following models on the test dataset.\n",
        "\n",
        "Key workflow:\n",
        "\n",
        "- Build model using architecture specification based on experiment\n",
        "- Plot learning curves from model training to visualize performance over epochs on training and validation data\n",
        "- Use trained model to predict and evaluate performance on test data\n",
        "- Play around with the `class_weight` parameter when training\n",
        "\n",
        "\n",
        "### Experiment 1 -  3-layer NN:  \n",
        "- __3-Dense Hidden Layer, 32 units, `relu` activation function__\n",
        "- 1-Dense Output Layer, 1 unit, `sigmoid` activation function\n",
        "- __learning rate: 0.0001__\n",
        "- __optimizer is Adam__\n",
        "- metrics: 'accuracy', [precision](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision), [recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall)\n",
        "- loss: [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy)\n",
        "- __epochs: 10000__\n",
        "- __Use the [early stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) callback to stop training as soon as the validation loss doesn't decrease after 10 epochs i.e. `patience=10` and `monitor='val_loss'`__\n",
        "- __Modify `class_weight` in `model.fit()`__\n",
        "- batch size: 32\n",
        "- use training data and validation data in `fit()` function\n",
        "- use `predict()` on test data and show confusion matrix and classification reports\n"
      ],
      "metadata": {
        "id": "9QYroD4aOoqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Task 5 Below"
      ],
      "metadata": {
        "id": "tZz3en-lPfwo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dg_VrQQTkjnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_vydrVH0fnhX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
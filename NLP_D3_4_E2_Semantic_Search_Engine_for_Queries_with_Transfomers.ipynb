{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astrapi69/DroidBallet/blob/master/NLP_D3_4_E2_Semantic_Search_Engine_for_Queries_with_Transfomers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><a target=\"_blank\" href=\"https://learning.constructor.org/\"><img src=\"https://drive.google.com/uc?id=1wxkbM60NlBlkbGK1JqUypKL24RrTiiYk\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "\n",
        "_____\n",
        "\n",
        "<center>Constructor Learning, 2023</center>"
      ],
      "metadata": {
        "id": "jwaIu7nhuCMY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w2MPbHppeO0"
      },
      "source": [
        "# Building a Semantic Search Engine to Search for Queries with Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb75SQP5pro_"
      },
      "source": [
        "# Semantic Search\n",
        "Semantic search seeks to improve search accuracy by understanding the content of the search query. In contrast to traditional search engines, that only finds documents based on lexical matches, semantic search can also find synonyms.\n",
        "\n",
        "\n",
        "## Background\n",
        "The idea behind semantic search is to embedd all entries in your corpus, which can be sentences, paragraphs, or documents, into a vector space.\n",
        "\n",
        "At search time, the query is embedded into the same vector space and the closest embedding from your corpus are found. These entries should have a high semantic overlap with the query.\n",
        "\n",
        "![SemanticSearch](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/SemanticSearch.png)\n",
        "\n",
        "\n",
        "## Python\n",
        "\n",
        "For small corpora (up to about 100k entries) we can compute the cosine-similarity between the query and all entries in the corpus.\n",
        "\n",
        "For small corpora with few example sentences we compute the embeddings for the corpus as well as for our query.\n",
        "\n",
        "We then use the [util.pytorch_cos_sim()](../../../docs/usage/semantic_textual_similarity.md) function to compute the cosine similarity between the query and all corpus entries.\n",
        "\n",
        "For large corpora, sorting all scores would take too much time. Hence, we can use [torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html) to only get the top k entries.\n",
        "\n",
        "[Reference](https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search)\n",
        "\n",
        "\n",
        "## Objective\n",
        "\n",
        "For today's objective we will create a corpus of around 50000 question titles asked on Quora from an open dataset. Your task will be to compute sentence embeddings and then try to retrieve top 5 similar questions from the corpus for a few example queries mentioned below.\n",
        "\n",
        "Use [Sentence Transformers](https://github.com/UKPLab/sentence-transformers) which provides a scalable way to generate document embeddings using transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "637DLY-vqofj"
      },
      "source": [
        "## Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G6XYAOjKfoe"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4Gb28zvKmfb"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZbso1ipKa2S"
      },
      "source": [
        "import transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRSgF-ITKWL6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd9fnlmlqqxh"
      },
      "source": [
        "## Download and Load Corpus of Questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O37SmvVPK4Q_"
      },
      "source": [
        "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz3j4m13KtaR"
      },
      "source": [
        "df = pd.read_csv('quora_duplicate_questions.tsv', sep='\\t').head(25000)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3AfKmnGLCFg"
      },
      "source": [
        "corpus = df['question1'].tolist() + df['question2'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKfVgMPELMvT"
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v-WQjCAqvd9"
      },
      "source": [
        "## Use Sentence Transformers and Generate Corpus Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuwhkFevq1rm"
      },
      "source": [
        "__Hint:__ You can use this tutorial as a reference\n",
        "\n",
        "[Semantic Search Tutorial](https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/semantic-search/semantic_search.py)\n",
        "\n",
        "Also use the __`roberta-large-nli-stsb-mean-tokens`__ model to generate document embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf8Q7vV4LP3A"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJIxH70vL3L1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G27sHdxRPPri"
      },
      "source": [
        "corpus_embeddings = ??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NVNIPeRP0Uj"
      },
      "source": [
        "corpus_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJS9cPFkrJO_"
      },
      "source": [
        "## Create a function to return top K similar sentences for a given query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz4J-WCdP7uz"
      },
      "source": [
        "\n",
        "\n",
        "def return_similar_sentences(query, model_embedder, corpus_embeddings, top_k):\n",
        "  <FILL THIS UP>\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT9-eXFiQqAK"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW53grWprO73"
      },
      "source": [
        "## Perform Semantic Search on Sample Questions to get Similar Queries from the Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGbnncfyQsC8"
      },
      "source": [
        "s = 'What is the step by step guide to invest'\n",
        "return_similar_sentences(query=s,\n",
        "                         model_embedder=?,\n",
        "                         corpus_embeddings=?,\n",
        "                         top_k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFlPlIERQ9xy"
      },
      "source": [
        "s = 'What is Data Science?'\n",
        "return_similar_sentences(query=s,\n",
        "                         model_embedder=?,\n",
        "                         corpus_embeddings=?,\n",
        "                         top_k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Sse303SloA"
      },
      "source": [
        "s = 'What is natural language processing?'\n",
        "return_similar_sentences(query=s,\n",
        "                         model_embedder=?,\n",
        "                         corpus_embeddings=?,\n",
        "                         top_k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTaLBUMpS7lc"
      },
      "source": [
        "s = 'Best Harry Potter Movie?'\n",
        "return_similar_sentences(query=s,\n",
        "                         model_embedder=?,\n",
        "                         corpus_embeddings=?,\n",
        "                         top_k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Vs1PWCTGJA"
      },
      "source": [
        "s = 'What is the best smartphone?'\n",
        "return_similar_sentences(query=s,\n",
        "                         model_embedder=?,\n",
        "                         corpus_embeddings=?,\n",
        "                         top_k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9MxlFbsTaeT"
      },
      "source": [
        "s = 'What is the best starter pokemon?'\n",
        "return_similar_sentences(query=s,\n",
        "                         model_embedder=?,\n",
        "                         corpus_embeddings=?,\n",
        "                         top_k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5wrOme0Tqrg"
      },
      "source": [
        "s = 'Batman or Superman?'\n",
        "return_similar_sentences(query=s,\n",
        "                         model_embedder=?,\n",
        "                         corpus_embeddings=?,\n",
        "                         top_k=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}